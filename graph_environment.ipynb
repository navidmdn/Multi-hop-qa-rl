{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "198962b1",
   "metadata": {},
   "source": [
    "# initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e22e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from graph_embeddings.data_loader import DataLoader\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from random import choice\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "from enum import Enum\n",
    "from collections import deque\n",
    "import torch.optim as optim\n",
    "from random import random\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from operator import add\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d772d98",
   "metadata": {},
   "source": [
    "# observing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c926e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset='MetaQA', reverse_rel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6c7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_voc, relations_voc = data_loader.load_entity_relations_vocab()\n",
    "entities_inv_voc = {v: k for k, v in entities_voc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971aad3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_language_reverse': 0,\n",
       " 'release_year': 1,\n",
       " 'has_genre': 2,\n",
       " 'has_tags_reverse': 3,\n",
       " 'directed_by_reverse': 4,\n",
       " 'written_by': 5,\n",
       " 'written_by_reverse': 6,\n",
       " 'has_imdb_rating_reverse': 7,\n",
       " 'starred_actors': 8,\n",
       " 'in_language': 9,\n",
       " 'release_year_reverse': 10,\n",
       " 'starred_actors_reverse': 11,\n",
       " 'has_imdb_votes_reverse': 12,\n",
       " 'has_tags': 13,\n",
       " 'directed_by': 14,\n",
       " 'has_genre_reverse': 15,\n",
       " 'has_imdb_votes': 16,\n",
       " 'has_imdb_rating': 17}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_inv_voc = {v: k for k, v in relations_voc.items()}\n",
    "relations_voc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a60f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entities_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df742878",
   "metadata": {},
   "source": [
    "# creating embeddings from KGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc7cd1",
   "metadata": {},
   "source": [
    "## loading trained kge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1ca49a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operating on cpu\n",
      "building tucker model for embedding generation\n"
     ]
    }
   ],
   "source": [
    "from kg_env import load_kge_model\n",
    "import torch\n",
    "\n",
    "model = load_kge_model(\n",
    "    dataset_name='MetaQA',\n",
    "    model_name='TuckER',\n",
    "    ent_vec_dim=200,\n",
    "    rel_vec_dim=200,\n",
    "    loss_type='CE',\n",
    "    device=('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    path='TuckER_MetaQA',\n",
    "    input_dropout=0.3,\n",
    "    hidden_dropout1=0.4,\n",
    "    hidden_dropout2=0.5,\n",
    "    l3_reg=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0149c52e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 200])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Adrian Moat': 970,\n",
    "#'Adrian Pasdar': 971,\n",
    "# 'Adrian Rawlins': 972,\n",
    "# 'Adrian Shergold': 973\n",
    "\n",
    "model.E(torch.Tensor([970, 971, 972]).long()).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c51b33",
   "metadata": {},
   "source": [
    "## generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ffcdce7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kg_env import generate_entity_embeddings\n",
    "import pickle\n",
    "\n",
    "ent_emb_dict = generate_entity_embeddings(model, entities_voc)\n",
    "rel_emb_dict = generate_entity_embeddings(model, relations_voc)\n",
    "\n",
    "with open('data/MetaQA/entity_emb.pickle', 'wb') as f:\n",
    "    pickle.dump(ent_emb_dict, f)\n",
    "    \n",
    "\n",
    "with open('data/MetaQA/relation_emb.pickle', 'wb') as f:\n",
    "    pickle.dump(rel_emb_dict, f)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50babfd",
   "metadata": {},
   "source": [
    "## load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c05beb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/MetaQA/entity_emb.pickle', 'rb') as f:\n",
    "    ent_emb_dict = pickle.load(f)\n",
    "    \n",
    "\n",
    "with open('data/MetaQA/relation_emb.pickle', 'rb') as f:\n",
    "    rel_emb_dict = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "787f8506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_emb_dict[list(ent_emb_dict.keys())[0]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4d073",
   "metadata": {},
   "source": [
    "## generating question embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d679af",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## analyze qa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2112536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_qa(path, mode='train_1hop'):\n",
    "    with open(os.path.join(path, f'qa_{mode}.txt'), 'r') as f:\n",
    "        text = f.read().strip().split('\\n')\n",
    "    return text\n",
    "\n",
    "qa_train_raw = load_raw_qa('./data/QA_data/MetaQA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf3fb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_question_entity_target(raw_questions):\n",
    "    all_questions = []\n",
    "    all_entities = []\n",
    "    all_targets = []\n",
    "\n",
    "    for raw_q in raw_questions:\n",
    "        question, targets = raw_q.split('\\t')\n",
    "        entity = re.findall('\\[.*?\\]', question)[0] \\\n",
    "            .replace('[', '') \\\n",
    "            .replace(']', '')\n",
    "\n",
    "        # todo: should I replace entity with some special token?\n",
    "        question = question.replace(']', '').replace('[', '')\n",
    "        targets = targets.strip().split('|')\n",
    "        all_questions.append(question)\n",
    "        all_targets.append(targets)\n",
    "        all_entities.append(entity)\n",
    "\n",
    "    return all_questions, all_entities, all_targets\n",
    "\n",
    "\n",
    "qa_train_raw = load_raw_qa('./data/QA_data/MetaQA/', mode='train_3hop')\n",
    "questions, _, _ = extract_question_entity_target(qa_train_raw)\n",
    "print(max([len(s) for s in questions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "481e3ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MODELS_CACHE_PATH = '/projects/academic/kjoseph/navid/models/cache'\n",
    "\n",
    "\n",
    "def tokenize_sentences(sentences: List[str], tokenizer_path=MODELS_CACHE_PATH, max_len=160, batch_size=128):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', cache_dir=MODELS_CACHE_PATH)\n",
    "    tokenizer_results = []\n",
    "    pbar = tqdm(total=len(sentences)//batch_size)\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        tokenizer_res = tokenizer(\n",
    "            batch, return_tensors='pt', max_length=max_len, truncation=True, padding='max_length')\n",
    "        tokenizer_results.append(tokenizer_res)\n",
    "        i += batch_size\n",
    "        pbar.update(1)\n",
    "    return tokenizer_results\n",
    "\n",
    "def get_batch_embeddings(tokenizer_results):\n",
    "    i = 0\n",
    "    embeddings = []\n",
    "    bert = BertModel.from_pretrained('bert-base-uncased', cache_dir=MODELS_CACHE_PATH).to(device)\n",
    "    bert.eval()\n",
    "    \n",
    "    for tokenizer_dict in tqdm(tokenizer_results):\n",
    "        for key in tokenizer_dict:\n",
    "            tokenizer_dict[key] = tokenizer_dict[key].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = bert(**tokenizer_dict)\n",
    "        embeddings.append(outputs.pooler_output.detach().cpu().numpy())\n",
    "    \n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd21def",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_res = tokenize_sentences(questions)\n",
    "print(tokenizer_res['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58a95464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                             | 0/14274 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                   | 1/14274 [00:00<2:56:23,  1.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0486,  0.0761, -0.0288,  ..., -0.1312, -0.0418, -0.0443],\n",
      "         [ 0.0131, -0.1777, -0.0614,  ..., -0.3306,  0.1801,  0.0568],\n",
      "         [ 0.0847,  0.1649,  0.0865,  ...,  0.2064, -0.0259, -0.0863],\n",
      "         ...,\n",
      "         [ 0.0565,  0.0920,  0.0201,  ..., -0.1220, -0.0156, -0.0208],\n",
      "         [ 0.0565,  0.0920,  0.0201,  ..., -0.1220, -0.0156, -0.0208],\n",
      "         [ 0.0565,  0.0920,  0.0201,  ..., -0.1220, -0.0156, -0.0208]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-1.1188e-02, -2.0919e-01, -2.2745e-01, -1.1578e-01,  1.6160e-01,\n",
      "          1.9390e-01,  2.5668e-01, -7.2665e-02, -5.9200e-02, -1.7820e-01,\n",
      "          2.3287e-01, -1.2546e-03, -8.6979e-02,  8.9313e-02, -1.3310e-01,\n",
      "          5.0997e-01,  2.2478e-01, -4.6840e-01,  7.0964e-03, -3.6931e-02,\n",
      "         -2.4895e-01,  5.7112e-02,  4.6074e-01,  2.9635e-01,  1.3442e-01,\n",
      "          7.6506e-02, -1.2433e-01, -3.5329e-02,  1.8925e-01,  2.2929e-01,\n",
      "          2.6687e-01,  5.3384e-02,  1.1271e-01,  2.6096e-01, -2.4925e-01,\n",
      "          4.0644e-02, -3.0925e-01,  2.8859e-02,  2.4695e-01, -1.9093e-01,\n",
      "         -8.1733e-02,  1.6844e-01,  1.8241e-01, -1.3373e-01, -1.2038e-01,\n",
      "          3.9230e-01,  2.4602e-01,  6.2669e-02, -1.1978e-01, -9.9425e-02,\n",
      "         -3.6967e-01,  3.7862e-01,  2.9659e-01,  2.1889e-01, -3.6361e-02,\n",
      "          1.6310e-02, -1.2171e-01,  2.4879e-01, -6.3768e-02, -9.3117e-02,\n",
      "         -1.2315e-01, -2.2095e-01, -2.0968e-02, -4.6416e-02, -5.4636e-03,\n",
      "         -1.4861e-01,  8.8895e-02, -1.5646e-01, -1.3950e-01,  6.6408e-02,\n",
      "         -9.1845e-02,  1.5884e-01,  1.4340e-01, -2.5681e-01, -2.7499e-01,\n",
      "          6.8022e-02, -5.9804e-01, -1.1069e-01,  2.8616e-01,  4.2135e-01,\n",
      "         -1.2036e-01,  1.9856e-01,  5.3969e-03,  2.1307e-01, -1.5159e-02,\n",
      "         -5.8735e-02, -4.8426e-02, -8.9487e-02,  1.8401e-01,  2.7185e-01,\n",
      "         -2.1071e-01, -3.9132e-01,  6.8983e-02,  2.7503e-02, -8.9308e-02,\n",
      "         -4.4563e-03, -1.2084e-02, -1.2257e-01, -1.7279e-01, -1.6770e-01,\n",
      "          5.8874e-02, -2.6735e-01, -1.1952e-01,  2.5871e-01, -2.2517e-02,\n",
      "         -2.1607e-01, -4.8969e-02,  2.8515e-01,  4.9705e-02, -1.0885e-01,\n",
      "         -1.6721e-01,  4.1988e-01,  3.0605e-01,  3.5891e-02,  1.2066e-02,\n",
      "          1.8398e-01,  1.1072e-01, -2.7404e-01,  4.2434e-01, -3.0238e-01,\n",
      "          1.0596e-02, -8.7341e-02,  1.0814e-01,  1.2790e-01, -1.9897e-01,\n",
      "          2.6877e-01,  1.3323e-01,  2.5240e-01,  1.8176e-01,  9.7297e-02,\n",
      "         -3.1075e-02,  1.1824e-01, -1.1883e-01,  1.4174e-01,  1.9202e-01,\n",
      "          9.8663e-02,  1.9818e-02, -3.1942e-01, -1.8734e-01,  2.4032e-01,\n",
      "          3.3376e-01,  1.3323e-01, -2.1350e-02,  2.0321e-01,  8.6403e-02,\n",
      "          2.2743e-01,  1.3382e-01, -4.0449e-01,  3.2264e-02,  3.3956e-01,\n",
      "          9.3516e-02,  1.6496e-01, -8.1447e-02, -2.7567e-01, -2.4679e-01,\n",
      "         -1.0275e-01,  4.9817e-02, -3.2355e-01, -1.3344e-01,  3.7563e-01,\n",
      "          1.3042e-02,  6.8725e-03, -1.4987e-01, -2.3697e-01, -2.5353e-02,\n",
      "         -1.1643e-01,  2.1004e-02,  1.1027e-01, -7.7165e-02, -4.1245e-01,\n",
      "         -1.0317e-01, -5.3930e-01, -1.3135e-01,  1.9023e-01, -2.8375e-01,\n",
      "          2.3776e-01, -2.7051e-01,  7.1539e-02,  4.1583e-01,  4.4491e-02,\n",
      "         -4.4609e-04, -1.6799e-01, -4.9517e-02,  9.4211e-02,  3.1649e-01,\n",
      "          2.3264e-01, -3.7430e-01,  8.3252e-02,  1.4224e-01,  2.5311e-01,\n",
      "          1.4493e-01, -3.5384e-02, -1.3160e-01,  1.1245e-01, -2.0808e-01,\n",
      "          1.6170e-01, -2.3719e-01,  1.7978e-01, -2.6692e-01, -2.3898e-01,\n",
      "          2.8766e-01, -3.9164e-01, -3.6212e-02,  8.1917e-02,  2.5863e-01,\n",
      "          1.8094e-02, -5.4518e-02, -9.3592e-02,  9.8821e-02,  1.8494e-01,\n",
      "          1.3155e-01, -4.0184e-01,  2.6600e-01, -4.5834e-03, -3.5810e-02,\n",
      "         -1.9091e-02,  1.7912e-01,  2.4393e-01,  1.1064e-01, -3.9554e-01,\n",
      "         -1.5327e-01,  1.0446e-01,  2.6614e-01, -2.5814e-01,  1.6387e-01,\n",
      "         -2.6440e-01, -3.8640e-01, -1.5941e-01,  2.1318e-01,  2.2224e-01,\n",
      "          1.6139e-01, -2.7027e-01,  1.6799e-01, -8.0651e-02, -4.4226e-01,\n",
      "         -3.4625e-01, -8.0286e-02,  2.5599e-01,  1.7042e-01,  1.6646e-01,\n",
      "          2.4002e-01,  5.2622e-02,  8.1711e-02,  1.6431e-01,  1.3258e-01,\n",
      "         -1.7808e-01,  1.5969e-01, -3.7079e-01, -5.6438e-02, -2.6568e-01,\n",
      "         -1.9257e-01, -1.9651e-01,  3.9430e-01, -2.3357e-01,  2.5260e-01,\n",
      "          3.9017e-01, -2.9072e-01, -1.1284e-01,  1.2129e-01,  8.6426e-02,\n",
      "          1.1709e-01, -1.4663e-01,  2.0240e-01,  1.5713e-01, -1.1842e-01,\n",
      "          2.3573e-01,  2.5016e-02,  2.4471e-01,  1.6077e-01,  9.8463e-02,\n",
      "          1.5344e-01,  1.2574e-01, -1.4931e-01,  5.6045e-02,  1.7958e-02,\n",
      "         -2.3391e-02, -2.6058e-01, -1.6683e-01,  2.1879e-01, -3.0872e-02,\n",
      "          3.3287e-02, -1.5824e-01, -1.0101e-01,  5.0377e-03,  4.0324e-01,\n",
      "         -3.6525e-01,  2.4094e-01,  8.2509e-02,  1.5406e-01, -2.6033e-01,\n",
      "         -1.8464e-01,  8.3674e-02,  1.4398e-01, -4.0854e-01,  8.4427e-03,\n",
      "          1.6837e-01,  1.0425e-01,  2.0160e-01,  2.4735e-01, -2.4569e-02,\n",
      "         -1.0804e-01,  4.6905e-01, -1.6608e-01, -1.4172e-01,  2.6076e-01,\n",
      "         -2.7547e-01, -2.9055e-01,  2.4955e-01, -2.8635e-02,  3.0873e-01,\n",
      "          1.2274e-01,  3.0787e-02,  9.9014e-02, -6.1298e-01,  7.7012e-02,\n",
      "         -4.5004e-01, -9.7540e-03, -1.7009e-03, -7.8210e-02, -2.0849e-01,\n",
      "          1.1364e-01,  2.9598e-01, -2.6443e-01, -3.4871e-02,  2.2010e-01,\n",
      "          7.8711e-02, -1.1895e-01,  4.7314e-01, -2.1995e-02,  2.1134e-01,\n",
      "         -7.7447e-02,  2.4071e-01, -2.1173e-01,  2.5045e-01, -2.5404e-01,\n",
      "         -9.8583e-02,  2.6421e-02,  8.5607e-02,  6.6336e-02, -5.0331e-02,\n",
      "         -3.3156e-01,  2.3587e-01, -3.3458e-02, -6.8789e-02, -3.9614e-02,\n",
      "          9.7006e-02, -1.4869e-03,  4.4646e-02,  7.7698e-02,  3.1041e-01,\n",
      "          2.6542e-01, -1.3054e-02, -3.5620e-01, -5.7255e-03, -1.0589e-01,\n",
      "          6.4708e-02, -4.0590e-03, -1.9004e-02,  4.2065e-01, -1.1506e-01,\n",
      "         -1.8892e-02, -1.4197e-01,  2.4754e-01,  2.0611e-01,  1.3794e-01,\n",
      "          1.2080e-01,  5.7478e-02,  1.1916e-01, -6.9815e-02, -2.6834e-02,\n",
      "         -1.6217e-01, -2.1778e-01, -2.9370e-01,  2.2117e-01, -2.2505e-01,\n",
      "         -1.7203e-01,  1.6243e-01,  1.8333e-01, -1.4149e-01,  1.3386e-01,\n",
      "          3.1075e-01,  1.1054e-01, -1.4404e-01,  2.5680e-01, -1.0776e-01,\n",
      "          1.1621e-01,  3.1853e-01, -1.5372e-02,  1.6992e-01,  5.2048e-01,\n",
      "          2.2517e-01, -3.6132e-01, -2.9862e-02, -2.2175e-01,  2.6862e-02,\n",
      "          2.4986e-01, -1.6520e-01,  1.8812e-01,  3.7639e-01,  3.0572e-01,\n",
      "          4.4881e-01,  1.1725e-02, -1.2780e-01,  1.0286e-01,  2.1637e-01,\n",
      "          3.7588e-02, -1.5371e-01, -1.7303e-01,  2.5824e-01,  4.2484e-02,\n",
      "         -1.2665e-01, -1.5781e-02, -1.0052e-01,  4.2760e-02, -1.2713e-01,\n",
      "         -3.7700e-01,  6.0978e-02,  1.9395e-01, -4.6589e-01,  7.4386e-02,\n",
      "         -2.8537e-01,  3.6367e-02, -2.3551e-01,  2.2834e-01, -2.5683e-01,\n",
      "         -1.1240e-01,  3.8967e-01, -5.9668e-02,  5.9608e-02, -1.9760e-01,\n",
      "         -1.3847e-01,  2.3140e-02,  2.7385e-02,  1.1254e-03, -5.5126e-03,\n",
      "          3.3689e-01, -1.2206e-01,  2.0787e-02,  4.3763e-02,  2.1667e-01,\n",
      "         -5.3485e-02,  1.9359e-01,  1.4117e-02, -1.3556e-01, -3.8523e-01,\n",
      "          1.2875e-01, -1.8608e-01, -4.3626e-01, -3.5393e-01,  3.3947e-01,\n",
      "         -1.2275e-01, -2.5499e-01, -2.2255e-01, -2.6307e-01,  6.8029e-02,\n",
      "          1.8523e-01,  4.5094e-01, -4.0172e-01, -5.8062e-02,  4.7992e-01,\n",
      "         -5.6064e-02, -1.8358e-01,  3.0997e-01,  2.1517e-01, -3.1549e-01,\n",
      "          3.3028e-01,  2.6935e-01, -5.1444e-02,  3.8904e-02,  5.1735e-01,\n",
      "          1.1491e-01,  1.9039e-01, -2.1634e-01,  4.5490e-01, -2.1855e-01,\n",
      "          2.8709e-01, -1.8214e-01, -2.1484e-01, -1.8381e-01,  4.6452e-03,\n",
      "          3.0193e-01,  1.8006e-01, -3.9775e-01, -1.0326e-01,  6.1032e-02,\n",
      "          3.2888e-01, -3.6808e-01, -9.5998e-02,  4.2539e-03, -3.3181e-01,\n",
      "          1.0162e-01,  7.6902e-02,  2.3066e-01, -3.6972e-01, -3.0019e-02,\n",
      "          3.9877e-01, -3.1557e-01,  1.2971e-01,  3.0784e-01,  9.0853e-02,\n",
      "          3.5627e-01, -1.6670e-02,  3.2885e-03,  6.2807e-02, -2.3643e-01,\n",
      "         -2.5299e-02,  1.2971e-01,  5.2514e-01,  1.5653e-01, -3.6971e-01,\n",
      "          8.7315e-02,  2.1877e-01, -1.1668e-01,  3.0325e-01, -7.9747e-02,\n",
      "         -9.4750e-02,  2.5346e-01, -5.5457e-02,  1.5617e-01, -8.5734e-02,\n",
      "         -2.1583e-01, -3.3036e-01,  3.4039e-01, -2.3922e-01, -1.2404e-01,\n",
      "         -1.4703e-01, -1.3724e-01, -1.2208e-01,  5.0816e-02, -3.7565e-01,\n",
      "          3.3892e-01,  1.0257e-01, -2.1184e-01, -7.4271e-02, -9.1163e-02,\n",
      "         -1.4743e-01, -2.1390e-01, -2.7186e-01,  4.2361e-01, -1.7262e-01,\n",
      "         -4.5126e-01,  2.3993e-01,  5.7977e-02,  3.3652e-01,  3.1556e-02,\n",
      "          9.9695e-02, -5.1597e-02,  1.1890e-01,  6.7281e-02, -1.1161e-01,\n",
      "          2.6747e-01,  6.2781e-02, -5.5565e-01, -1.2271e-01, -2.3861e-01,\n",
      "          9.7591e-02,  2.0741e-01, -3.3160e-01,  2.8880e-02,  3.6459e-02,\n",
      "          1.4967e-01,  7.0331e-02, -1.1716e-01, -6.2648e-02,  3.9126e-01,\n",
      "          2.1311e-01,  2.5444e-01,  8.4248e-02,  2.5367e-01, -8.8551e-03,\n",
      "         -2.9380e-01,  5.5636e-02,  7.8802e-02, -1.6839e-01,  4.4235e-01,\n",
      "         -9.8178e-02, -3.7649e-01, -7.7330e-02,  4.0899e-01,  1.0421e-01,\n",
      "         -1.8241e-02, -5.9381e-02,  1.9835e-01,  1.5378e-01, -1.2768e-01,\n",
      "          1.7856e-01, -3.4573e-02, -1.4182e-01, -1.2097e-01,  8.7649e-02,\n",
      "         -2.2547e-01,  6.3402e-02, -1.5257e-01, -1.8431e-02, -2.2518e-01,\n",
      "          1.3364e-02, -2.1048e-01,  2.6089e-01, -3.4860e-01,  1.0823e-01,\n",
      "          8.0148e-02,  3.0582e-01, -3.5686e-01, -1.5832e-01, -8.1461e-02,\n",
      "          1.5693e-01,  2.7522e-01,  3.2453e-01,  4.9840e-02,  2.0398e-03,\n",
      "         -1.6572e-01, -2.3365e-01,  8.5096e-02, -2.0885e-01,  1.4073e-01,\n",
      "          8.2835e-02,  2.2332e-01, -3.3486e-01, -1.5829e-01,  2.4842e-01,\n",
      "         -1.0276e-01, -1.1352e-01,  4.1104e-01,  2.4601e-01,  2.3780e-01,\n",
      "          2.9289e-02,  2.4512e-01,  5.5535e-02, -2.1516e-01, -1.3922e-01,\n",
      "         -2.2048e-01,  7.7506e-02, -9.7506e-02, -4.7085e-02, -1.8393e-02,\n",
      "         -1.1245e-01, -1.9330e-01, -1.5900e-01,  1.4603e-01,  1.2054e-01,\n",
      "          4.9536e-03, -4.3481e-02, -2.4076e-02, -2.6384e-01,  3.1992e-01,\n",
      "         -3.7652e-03,  9.1943e-02, -6.2227e-02,  3.6433e-02, -1.5600e-01,\n",
      "          2.3127e-01,  2.1741e-01,  6.3174e-02, -1.7549e-01, -4.9375e-02,\n",
      "         -2.9875e-01, -3.7411e-01,  5.0310e-02,  1.5423e-01,  1.1475e-01,\n",
      "         -7.9982e-02, -2.9252e-01,  9.7424e-03, -1.1580e-01,  1.7734e-01,\n",
      "          1.5810e-02, -1.4982e-01, -7.5721e-02, -5.8512e-02, -4.0495e-02,\n",
      "          7.5904e-02, -2.0747e-01, -1.8747e-01, -1.0897e-01, -9.0045e-02,\n",
      "         -7.4401e-02,  3.7118e-01, -3.2076e-02,  2.6849e-01, -1.6522e-01,\n",
      "          1.0161e-02, -1.5164e-01,  1.1188e-01, -4.4754e-02,  6.1240e-02,\n",
      "          2.6880e-01, -4.5481e-01, -1.6239e-01, -6.8406e-04, -2.2495e-01,\n",
      "         -1.1270e-01, -6.1609e-02, -6.0749e-02,  2.1339e-01, -3.2958e-01,\n",
      "          2.0177e-01, -6.8470e-02,  1.6611e-01, -5.0780e-02, -2.5206e-01,\n",
      "         -1.5280e-01, -9.7897e-04,  2.4954e-01, -3.2134e-01, -2.4031e-01,\n",
      "         -2.6522e-01, -1.1165e-01, -6.1674e-02, -2.6536e-01,  4.1979e-01,\n",
      "         -1.3386e-01, -7.3119e-02,  4.1915e-02,  4.4271e-01,  2.0353e-01,\n",
      "          1.9584e-01,  1.8875e-01,  9.3959e-03,  2.6744e-02,  1.2165e-01,\n",
      "         -4.8035e-01,  2.1368e-01, -2.2242e-01, -1.2983e-01,  4.5349e-02,\n",
      "          7.2326e-02, -2.3445e-02, -2.9127e-04, -1.6284e-01, -9.1300e-02,\n",
      "          2.0786e-01, -3.8508e-01, -1.6360e-02,  2.5471e-01,  1.3238e-01,\n",
      "         -2.5224e-01,  5.5705e-02,  1.3180e-01,  4.0407e-01,  1.1795e-01,\n",
      "         -2.2077e-01,  1.3753e-01, -3.3343e-01, -2.5092e-02, -2.0800e-01,\n",
      "         -2.9913e-01,  1.4438e-01, -7.6070e-02,  8.2675e-02, -7.8103e-02,\n",
      "         -2.8954e-01,  2.2712e-01, -5.5337e-02, -6.4956e-02,  4.1866e-01,\n",
      "          4.0210e-02, -1.0189e-01,  1.3930e-01,  2.2170e-02,  4.4782e-02,\n",
      "         -1.0715e-01,  2.6985e-01,  1.9685e-01, -2.8743e-01,  1.4581e-01,\n",
      "         -1.0827e-01, -5.8784e-02, -1.0703e-01]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                   | 2/14274 [00:01<3:06:13,  1.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0483,  0.0658, -0.0396,  ..., -0.0925, -0.0512, -0.0151],\n",
      "         [ 0.0408, -0.3234, -0.2024,  ..., -0.2671,  0.1068, -0.0395],\n",
      "         [ 0.0705, -0.1757, -0.1514,  ..., -0.5613, -0.1411, -0.0526],\n",
      "         ...,\n",
      "         [ 0.0405, -0.0021,  0.0159,  ..., -0.0421, -0.0428,  0.0964],\n",
      "         [ 0.0405, -0.0021,  0.0159,  ..., -0.0421, -0.0428,  0.0964],\n",
      "         [ 0.0405, -0.0021,  0.0159,  ..., -0.0421, -0.0428,  0.0964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-3.0601e-03, -2.1779e-01, -2.0223e-01, -9.0303e-02,  1.1932e-01,\n",
      "          1.8957e-01,  2.5946e-01, -7.7788e-02, -7.1099e-02, -1.6559e-01,\n",
      "          2.2084e-01, -1.8129e-02, -1.0156e-01,  8.3201e-02, -1.3346e-01,\n",
      "          4.9150e-01,  2.0551e-01, -4.5526e-01,  2.3696e-02, -3.3467e-02,\n",
      "         -2.4801e-01,  6.0791e-02,  4.5524e-01,  3.0210e-01,  1.1699e-01,\n",
      "          7.6753e-02, -1.2701e-01, -1.6016e-02,  1.9760e-01,  2.1011e-01,\n",
      "          2.7757e-01,  5.5025e-02,  9.7133e-02,  2.4107e-01, -2.4190e-01,\n",
      "          5.5581e-02, -3.0928e-01,  1.4506e-02,  2.5347e-01, -1.9439e-01,\n",
      "         -8.5167e-02,  1.6398e-01,  1.8422e-01, -1.1708e-01, -1.1026e-01,\n",
      "          3.9440e-01,  2.3544e-01,  4.3261e-02, -1.2205e-01, -9.3475e-02,\n",
      "         -3.6078e-01,  3.4580e-01,  2.8926e-01,  2.0060e-01, -2.1491e-02,\n",
      "          4.3079e-02, -1.2802e-01,  2.5031e-01, -7.5249e-02, -9.7561e-02,\n",
      "         -1.1553e-01, -2.1751e-01, -1.5028e-03, -4.7819e-02,  1.8180e-02,\n",
      "         -1.3559e-01,  9.1748e-02, -1.3641e-01, -1.4478e-01,  6.0454e-02,\n",
      "         -9.3886e-02,  1.3682e-01,  1.4357e-01, -2.7226e-01, -2.7390e-01,\n",
      "          6.9627e-02, -5.7498e-01, -1.0130e-01,  2.8926e-01,  4.2119e-01,\n",
      "         -1.1912e-01,  1.8745e-01,  3.0970e-02,  2.0457e-01, -3.1848e-02,\n",
      "         -6.6738e-02, -4.1192e-02, -1.0539e-01,  1.9270e-01,  2.6900e-01,\n",
      "         -1.8039e-01, -3.5528e-01,  6.6947e-02,  2.1026e-02, -8.3927e-02,\n",
      "          1.4979e-02, -4.8093e-03, -1.0491e-01, -1.7686e-01, -1.6273e-01,\n",
      "          5.1806e-02, -2.6790e-01, -1.2906e-01,  2.6610e-01, -3.4590e-02,\n",
      "         -1.9781e-01, -4.2674e-02,  2.9447e-01,  7.1568e-02, -1.4029e-01,\n",
      "         -1.7684e-01,  4.1689e-01,  3.0050e-01,  1.4069e-02,  7.4098e-03,\n",
      "          1.8003e-01,  1.2221e-01, -2.8956e-01,  4.2042e-01, -3.1228e-01,\n",
      "         -9.3785e-03, -1.0171e-01,  1.1083e-01,  1.3707e-01, -2.0814e-01,\n",
      "          2.6469e-01,  1.5270e-01,  2.6854e-01,  1.8595e-01,  9.7735e-02,\n",
      "         -3.1212e-02,  1.2858e-01, -1.0604e-01,  1.3670e-01,  2.2017e-01,\n",
      "          1.1082e-01, -7.0050e-04, -3.1272e-01, -2.1101e-01,  2.5782e-01,\n",
      "          3.4068e-01,  1.4170e-01, -5.2969e-02,  1.9704e-01,  8.7842e-02,\n",
      "          2.3961e-01,  1.2800e-01, -4.0030e-01,  2.6277e-02,  3.4316e-01,\n",
      "          1.0063e-01,  1.7360e-01, -8.2813e-02, -2.8094e-01, -2.4633e-01,\n",
      "         -9.7929e-02,  4.2665e-02, -3.2924e-01, -1.2518e-01,  3.5112e-01,\n",
      "          9.9167e-03,  1.6249e-02, -1.3752e-01, -2.3502e-01, -3.0962e-02,\n",
      "         -1.1200e-01,  1.8630e-02,  1.0058e-01, -8.2081e-02, -4.0754e-01,\n",
      "         -9.2631e-02, -5.4853e-01, -1.3161e-01,  1.8866e-01, -3.0952e-01,\n",
      "          2.4771e-01, -2.8458e-01,  9.3974e-02,  4.1577e-01,  2.9710e-02,\n",
      "         -1.3436e-02, -1.5983e-01, -1.5088e-02,  1.0949e-01,  3.0751e-01,\n",
      "          2.4568e-01, -3.8239e-01,  6.5394e-02,  1.4418e-01,  2.4423e-01,\n",
      "          1.5185e-01, -4.1407e-02, -1.3552e-01,  1.1889e-01, -2.0227e-01,\n",
      "          1.5241e-01, -2.3293e-01,  2.0463e-01, -2.3673e-01, -2.1860e-01,\n",
      "          2.8004e-01, -3.9535e-01, -4.0185e-02,  8.0984e-02,  2.4688e-01,\n",
      "          2.4458e-02, -4.1475e-02, -9.5473e-02,  1.1226e-01,  1.8956e-01,\n",
      "          1.4990e-01, -3.9103e-01,  2.5420e-01, -1.9029e-02, -2.5573e-02,\n",
      "         -3.2177e-02,  1.7600e-01,  2.4190e-01,  1.0645e-01, -3.9654e-01,\n",
      "         -1.4353e-01,  1.1139e-01,  2.7145e-01, -2.3824e-01,  1.7330e-01,\n",
      "         -2.6888e-01, -3.8162e-01, -1.5051e-01,  1.9889e-01,  2.1195e-01,\n",
      "          1.8384e-01, -2.6794e-01,  1.6789e-01, -9.6864e-02, -4.1262e-01,\n",
      "         -3.5328e-01, -9.9705e-02,  2.4085e-01,  1.6811e-01,  1.6752e-01,\n",
      "          2.3432e-01,  4.1197e-02,  1.0179e-01,  1.6730e-01,  1.5288e-01,\n",
      "         -1.8803e-01,  1.6893e-01, -3.6545e-01, -5.6911e-02, -2.6087e-01,\n",
      "         -1.9217e-01, -2.0984e-01,  4.0103e-01, -2.3060e-01,  2.3940e-01,\n",
      "          3.8331e-01, -2.8713e-01, -1.2056e-01,  1.3847e-01,  8.2055e-02,\n",
      "          1.1556e-01, -1.2439e-01,  1.9416e-01,  1.7564e-01, -1.0394e-01,\n",
      "          2.2752e-01, -6.5950e-03,  2.6349e-01,  1.6819e-01,  1.0671e-01,\n",
      "          1.4759e-01,  1.1191e-01, -1.7121e-01,  7.4554e-02,  1.4229e-03,\n",
      "         -1.3066e-02, -2.3312e-01, -1.5764e-01,  2.3039e-01, -5.4207e-02,\n",
      "          3.9329e-02, -1.7579e-01, -1.0478e-01,  2.3580e-02,  3.9759e-01,\n",
      "         -3.5167e-01,  2.3927e-01,  6.5736e-02,  1.6434e-01, -2.5006e-01,\n",
      "         -1.9279e-01,  8.2090e-02,  1.7623e-01, -3.9441e-01,  2.8462e-03,\n",
      "          1.6315e-01,  1.0203e-01,  2.0417e-01,  2.6027e-01, -2.8769e-02,\n",
      "         -1.1299e-01,  4.8154e-01, -1.5742e-01, -1.4858e-01,  2.5606e-01,\n",
      "         -2.7235e-01, -2.7897e-01,  2.5478e-01, -2.4917e-02,  3.0605e-01,\n",
      "          1.2037e-01,  4.3891e-02,  7.8140e-02, -6.0726e-01,  8.1094e-02,\n",
      "         -4.4711e-01, -8.4721e-03,  1.1308e-02, -7.4386e-02, -2.0657e-01,\n",
      "          1.2766e-01,  2.8606e-01, -2.5721e-01, -4.3137e-02,  1.9841e-01,\n",
      "          8.0424e-02, -1.2537e-01,  4.6907e-01, -1.2709e-02,  2.1587e-01,\n",
      "         -7.0726e-02,  2.5098e-01, -2.2176e-01,  2.6471e-01, -2.6866e-01,\n",
      "         -1.0608e-01,  1.0730e-02,  7.6712e-02,  5.1296e-02, -8.3217e-02,\n",
      "         -3.2420e-01,  2.3807e-01, -2.6904e-02, -4.4335e-02, -4.0234e-02,\n",
      "          9.3619e-02, -5.1186e-03,  4.5575e-02,  6.4946e-02,  3.2048e-01,\n",
      "          2.4999e-01, -1.7158e-02, -3.4510e-01, -3.7162e-02, -9.2623e-02,\n",
      "          5.4931e-02,  1.7124e-02, -2.6450e-02,  4.2139e-01, -1.0119e-01,\n",
      "         -8.0821e-03, -1.4290e-01,  2.4807e-01,  2.1160e-01,  1.2710e-01,\n",
      "          1.1954e-01,  6.1918e-02,  1.3783e-01, -6.5457e-02, -5.5752e-03,\n",
      "         -1.5287e-01, -2.3073e-01, -3.0667e-01,  2.2690e-01, -2.3967e-01,\n",
      "         -1.6226e-01,  1.6285e-01,  2.1951e-01, -1.4095e-01,  1.2903e-01,\n",
      "          3.0433e-01,  1.0181e-01, -1.3791e-01,  2.5513e-01, -1.0979e-01,\n",
      "          1.2978e-01,  3.1136e-01, -1.5075e-02,  1.8240e-01,  4.9895e-01,\n",
      "          2.1894e-01, -3.6173e-01, -2.0306e-02, -2.2840e-01,  4.9970e-03,\n",
      "          2.4581e-01, -1.5546e-01,  1.8161e-01,  3.9772e-01,  3.1507e-01,\n",
      "          4.5299e-01,  1.2639e-02, -1.2024e-01,  9.3994e-02,  2.0586e-01,\n",
      "          5.0800e-02, -1.5255e-01, -1.5874e-01,  2.5461e-01,  3.3626e-02,\n",
      "         -1.4861e-01, -1.1760e-02, -9.6517e-02,  3.1845e-02, -1.1813e-01,\n",
      "         -3.6619e-01,  4.4250e-02,  1.9922e-01, -4.6507e-01,  8.0135e-02,\n",
      "         -2.8399e-01,  3.9860e-02, -2.3901e-01,  2.1757e-01, -2.1145e-01,\n",
      "         -1.0534e-01,  3.7825e-01, -6.8760e-02,  6.2266e-02, -1.8236e-01,\n",
      "         -1.2979e-01,  1.8273e-02,  2.4656e-02, -8.7346e-03, -2.9849e-02,\n",
      "          3.4852e-01, -1.1857e-01,  2.1669e-02,  2.4936e-02,  2.0730e-01,\n",
      "         -4.8361e-02,  1.8664e-01,  1.7074e-02, -1.2091e-01, -3.8130e-01,\n",
      "          1.2289e-01, -1.9271e-01, -4.2068e-01, -3.6108e-01,  3.4398e-01,\n",
      "         -1.3151e-01, -2.3929e-01, -2.1586e-01, -2.5452e-01,  7.3397e-02,\n",
      "          1.8503e-01,  4.5226e-01, -4.0655e-01, -6.7058e-02,  4.7751e-01,\n",
      "         -5.0228e-02, -1.7430e-01,  2.9249e-01,  1.9614e-01, -3.1385e-01,\n",
      "          3.3794e-01,  2.7531e-01, -4.5551e-02,  3.1835e-02,  5.2041e-01,\n",
      "          1.2562e-01,  1.8065e-01, -2.1673e-01,  4.5743e-01, -2.2429e-01,\n",
      "          2.9028e-01, -1.5583e-01, -2.0935e-01, -2.1202e-01,  1.1541e-02,\n",
      "          3.2800e-01,  1.8344e-01, -4.0559e-01, -1.1322e-01,  4.9813e-02,\n",
      "          3.3198e-01, -3.8208e-01, -8.4951e-02,  2.2124e-02, -3.2916e-01,\n",
      "          1.0805e-01,  9.7858e-02,  2.4040e-01, -3.6722e-01, -1.3647e-02,\n",
      "          3.8937e-01, -3.0528e-01,  1.2540e-01,  3.0389e-01,  8.3512e-02,\n",
      "          3.4700e-01, -3.3692e-02,  3.9840e-03,  3.6900e-02, -2.1936e-01,\n",
      "         -4.1298e-02,  1.2701e-01,  5.4103e-01,  1.4645e-01, -3.7344e-01,\n",
      "          8.1148e-02,  2.5586e-01, -1.4711e-01,  2.8330e-01, -9.0373e-02,\n",
      "         -6.7602e-02,  2.5595e-01, -5.8437e-02,  1.5861e-01, -1.0880e-01,\n",
      "         -2.4224e-01, -2.9305e-01,  3.5354e-01, -2.2613e-01, -1.0867e-01,\n",
      "         -1.4397e-01, -1.0677e-01, -1.3374e-01,  5.6418e-02, -3.7041e-01,\n",
      "          3.3515e-01,  1.1836e-01, -2.1869e-01, -1.0226e-01, -9.0284e-02,\n",
      "         -1.4779e-01, -2.2256e-01, -2.7501e-01,  4.3499e-01, -1.6491e-01,\n",
      "         -4.4743e-01,  2.5660e-01,  4.2545e-02,  3.4421e-01,  2.7343e-02,\n",
      "          1.0848e-01, -7.1130e-02,  1.2831e-01,  8.1952e-02, -1.2328e-01,\n",
      "          2.6946e-01,  3.7461e-02, -5.5642e-01, -1.4360e-01, -2.3667e-01,\n",
      "          8.0499e-02,  1.7508e-01, -3.3601e-01,  2.5789e-02,  2.8759e-02,\n",
      "          1.2633e-01,  3.8216e-02, -1.2685e-01, -7.1871e-02,  3.8713e-01,\n",
      "          2.2802e-01,  2.5932e-01,  1.0437e-01,  2.4057e-01, -1.1051e-03,\n",
      "         -3.0478e-01,  5.0219e-02,  8.5841e-02, -2.0906e-01,  4.3533e-01,\n",
      "         -9.9659e-02, -3.8525e-01, -9.5374e-02,  4.0527e-01,  1.1484e-01,\n",
      "         -3.9019e-02, -5.4144e-02,  1.9547e-01,  1.6235e-01, -1.3801e-01,\n",
      "          1.7618e-01, -3.5161e-02, -1.2998e-01, -1.2797e-01,  8.2593e-02,\n",
      "         -2.1275e-01,  5.2536e-02, -1.6832e-01, -1.4315e-02, -2.0441e-01,\n",
      "          9.6758e-04, -1.9324e-01,  2.5768e-01, -3.3573e-01,  1.0550e-01,\n",
      "          9.0135e-02,  3.1484e-01, -3.4254e-01, -1.5708e-01, -7.0237e-02,\n",
      "          1.7199e-01,  2.7194e-01,  3.4243e-01,  3.8340e-02, -1.0878e-02,\n",
      "         -1.5716e-01, -2.3823e-01,  9.6925e-02, -2.0422e-01,  1.4161e-01,\n",
      "          6.5201e-02,  2.1608e-01, -3.2298e-01, -1.8314e-01,  2.3119e-01,\n",
      "         -8.8526e-02, -1.4665e-01,  4.0070e-01,  2.3950e-01,  2.0998e-01,\n",
      "          4.0708e-02,  2.3718e-01,  4.2710e-02, -1.9939e-01, -1.3970e-01,\n",
      "         -2.4073e-01,  6.5729e-02, -9.2609e-02, -5.6419e-02, -3.3000e-02,\n",
      "         -1.2400e-01, -1.9894e-01, -1.6315e-01,  1.4078e-01,  1.2637e-01,\n",
      "          2.5591e-02, -4.6280e-02, -3.1523e-02, -2.7837e-01,  3.0409e-01,\n",
      "          6.6657e-03,  7.7698e-02, -7.3471e-02,  4.5025e-02, -1.4065e-01,\n",
      "          2.4081e-01,  2.0508e-01,  7.2396e-02, -1.7779e-01, -6.5666e-02,\n",
      "         -2.9841e-01, -3.4563e-01,  4.9252e-02,  1.3370e-01,  1.1780e-01,\n",
      "         -7.3731e-02, -3.0306e-01, -9.5646e-03, -1.2408e-01,  1.7301e-01,\n",
      "          2.2539e-02, -1.3888e-01, -8.5002e-02, -4.8422e-02, -5.4306e-02,\n",
      "          8.5395e-02, -2.1678e-01, -1.9711e-01, -1.1068e-01, -7.4211e-02,\n",
      "         -8.2268e-02,  3.4085e-01, -4.7761e-02,  2.8144e-01, -1.5788e-01,\n",
      "         -2.7600e-03, -1.6285e-01,  1.1255e-01, -5.3734e-02,  5.3710e-02,\n",
      "          2.7850e-01, -4.5095e-01, -1.6834e-01, -5.5853e-03, -2.1426e-01,\n",
      "         -1.3786e-01, -6.6751e-02, -3.4271e-02,  2.2319e-01, -3.3784e-01,\n",
      "          2.0637e-01, -9.1620e-02,  1.6974e-01, -5.1717e-02, -2.5378e-01,\n",
      "         -1.6124e-01,  2.3597e-03,  2.4382e-01, -3.3018e-01, -2.4456e-01,\n",
      "         -2.6403e-01, -1.0818e-01, -7.3401e-02, -2.4871e-01,  4.0382e-01,\n",
      "         -1.3418e-01, -8.0234e-02,  3.4985e-02,  4.5304e-01,  2.0523e-01,\n",
      "          1.7204e-01,  2.1417e-01,  2.1020e-05,  3.2851e-02,  1.3112e-01,\n",
      "         -4.6974e-01,  2.1896e-01, -2.1904e-01, -1.3075e-01,  3.1684e-02,\n",
      "          7.6440e-02, -6.7919e-03,  6.6992e-03, -1.6380e-01, -9.6052e-02,\n",
      "          2.1348e-01, -3.6628e-01, -3.1635e-02,  2.5002e-01,  1.5173e-01,\n",
      "         -2.5626e-01,  4.5904e-02,  1.2515e-01,  3.8751e-01,  9.3422e-02,\n",
      "         -2.1809e-01,  1.3365e-01, -3.4020e-01, -4.6801e-02, -1.9954e-01,\n",
      "         -2.8700e-01,  1.5446e-01, -5.9907e-02,  8.3899e-02, -8.7197e-02,\n",
      "         -2.9615e-01,  2.2360e-01, -4.5268e-02, -6.8368e-02,  4.2204e-01,\n",
      "          2.9700e-02, -1.2791e-01,  1.5006e-01,  3.1668e-02,  2.6554e-02,\n",
      "         -9.0650e-02,  2.6014e-01,  2.0831e-01, -2.8275e-01,  1.6370e-01,\n",
      "         -1.2046e-01, -4.5698e-02, -9.0982e-02]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                   | 3/14274 [00:02<3:01:31,  1.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0443,  0.0958, -0.0258,  ..., -0.1095, -0.0524, -0.0792],\n",
      "         [ 0.0289, -0.2903, -0.0484,  ..., -0.3300,  0.1950, -0.2918],\n",
      "         [ 0.3139,  0.2377,  0.0223,  ..., -0.1324,  0.3695, -0.1022],\n",
      "         ...,\n",
      "         [-0.0213, -0.0294,  0.0015,  ...,  0.0400, -0.0248, -0.0330],\n",
      "         [-0.0213, -0.0294,  0.0015,  ...,  0.0400, -0.0248, -0.0330],\n",
      "         [-0.0213, -0.0294,  0.0015,  ...,  0.0400, -0.0248, -0.0330]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-1.1580e-02, -2.2915e-01, -2.1842e-01, -1.1189e-01,  1.5850e-01,\n",
      "          2.0361e-01,  2.5357e-01, -1.0500e-01, -8.0442e-02, -1.5308e-01,\n",
      "          2.3498e-01, -4.6535e-02, -9.5518e-02,  9.9269e-02, -1.4516e-01,\n",
      "          4.9914e-01,  2.1731e-01, -4.7995e-01,  1.4769e-02, -3.3811e-02,\n",
      "         -2.4594e-01,  4.8498e-02,  4.6983e-01,  3.0698e-01,  1.1170e-01,\n",
      "          7.3765e-02, -1.1803e-01, -2.7452e-02,  2.2611e-01,  2.2226e-01,\n",
      "          2.7711e-01,  5.7507e-02,  1.0604e-01,  2.6714e-01, -2.6487e-01,\n",
      "          3.4784e-02, -3.1754e-01,  3.9458e-02,  2.5693e-01, -1.9770e-01,\n",
      "         -9.6886e-02,  1.7862e-01,  1.9478e-01, -1.3495e-01, -1.0414e-01,\n",
      "          4.1000e-01,  2.4475e-01,  5.5740e-02, -1.4223e-01, -1.0064e-01,\n",
      "         -3.5670e-01,  3.5680e-01,  2.9191e-01,  1.9799e-01,  4.7002e-03,\n",
      "          5.7396e-02, -1.2421e-01,  2.6362e-01, -5.9490e-02, -9.8766e-02,\n",
      "         -1.0084e-01, -2.3915e-01, -3.3733e-02, -3.8969e-02,  8.9045e-03,\n",
      "         -1.3731e-01,  6.7660e-02, -1.3950e-01, -1.4377e-01,  4.9513e-02,\n",
      "         -9.9021e-02,  1.7406e-01,  1.7131e-01, -2.8817e-01, -2.9060e-01,\n",
      "          9.0836e-02, -5.9915e-01, -1.0135e-01,  2.8406e-01,  4.2875e-01,\n",
      "         -1.3101e-01,  1.8654e-01,  2.0875e-02,  2.2571e-01, -1.6542e-02,\n",
      "         -3.8573e-02, -3.3382e-02, -9.7107e-02,  1.9134e-01,  2.7259e-01,\n",
      "         -2.0975e-01, -3.6886e-01,  5.3487e-02,  2.5983e-02, -7.9409e-02,\n",
      "         -1.1268e-02, -1.8673e-02, -8.1810e-02, -1.7634e-01, -1.6153e-01,\n",
      "          6.6292e-02, -2.8301e-01, -1.3252e-01,  2.8422e-01, -4.7701e-02,\n",
      "         -2.0038e-01, -3.3635e-02,  2.8334e-01,  3.4725e-02, -1.2130e-01,\n",
      "         -1.7928e-01,  4.4339e-01,  3.1209e-01,  1.6145e-05,  3.8169e-03,\n",
      "          1.8783e-01,  1.1552e-01, -2.7092e-01,  4.2921e-01, -3.1258e-01,\n",
      "         -1.1122e-02, -9.4353e-02,  1.1086e-01,  1.3737e-01, -2.0367e-01,\n",
      "          2.7008e-01,  1.3238e-01,  2.7322e-01,  1.9531e-01,  1.0198e-01,\n",
      "         -3.4445e-02,  1.2177e-01, -1.2655e-01,  1.6047e-01,  2.2290e-01,\n",
      "          1.0654e-01, -1.8512e-02, -3.0808e-01, -2.0197e-01,  2.8361e-01,\n",
      "          3.4304e-01,  1.4663e-01, -3.0496e-02,  2.0734e-01,  8.3242e-02,\n",
      "          2.3940e-01,  1.3615e-01, -4.2697e-01,  2.4395e-02,  3.3782e-01,\n",
      "          1.1300e-01,  1.4547e-01, -9.9838e-02, -2.7942e-01, -2.5826e-01,\n",
      "         -1.1056e-01,  6.6799e-02, -3.4233e-01, -1.4014e-01,  3.6839e-01,\n",
      "          2.3171e-02,  4.0478e-03, -1.4766e-01, -2.5513e-01, -1.7769e-02,\n",
      "         -1.1876e-01,  2.8530e-02,  9.0458e-02, -9.3770e-02, -4.2703e-01,\n",
      "         -8.8396e-02, -5.4357e-01, -1.1127e-01,  1.7532e-01, -3.2689e-01,\n",
      "          2.8404e-01, -2.6585e-01,  9.3768e-02,  4.1774e-01,  4.1022e-02,\n",
      "         -8.9619e-03, -1.8084e-01, -3.6343e-02,  1.0846e-01,  3.2612e-01,\n",
      "          2.4017e-01, -3.9677e-01,  8.5880e-02,  1.5052e-01,  2.5966e-01,\n",
      "          1.5495e-01, -4.7162e-02, -1.2962e-01,  1.0417e-01, -2.0669e-01,\n",
      "          1.5648e-01, -2.4527e-01,  1.9903e-01, -2.7314e-01, -2.3207e-01,\n",
      "          2.8489e-01, -3.9827e-01, -3.1150e-02,  7.9830e-02,  2.6385e-01,\n",
      "          5.3051e-03, -4.0626e-02, -9.0997e-02,  1.3131e-01,  1.6144e-01,\n",
      "          1.3494e-01, -4.1182e-01,  2.6198e-01, -2.1616e-02, -5.5454e-03,\n",
      "         -1.9900e-02,  1.6960e-01,  2.5869e-01,  9.4003e-02, -3.9742e-01,\n",
      "         -1.5875e-01,  9.3153e-02,  2.7356e-01, -2.5322e-01,  1.7021e-01,\n",
      "         -2.8606e-01, -4.1991e-01, -1.4833e-01,  2.1506e-01,  2.4002e-01,\n",
      "          1.6670e-01, -2.7401e-01,  1.8173e-01, -1.0271e-01, -4.2225e-01,\n",
      "         -3.6710e-01, -9.1834e-02,  2.3687e-01,  1.6801e-01,  1.8168e-01,\n",
      "          2.3557e-01,  4.6719e-02,  1.0668e-01,  1.5395e-01,  1.4336e-01,\n",
      "         -1.6950e-01,  1.7775e-01, -3.7417e-01, -5.7233e-02, -2.9241e-01,\n",
      "         -2.0748e-01, -2.0157e-01,  4.0863e-01, -2.3132e-01,  2.5908e-01,\n",
      "          4.0208e-01, -3.0463e-01, -1.1887e-01,  1.3324e-01,  7.3724e-02,\n",
      "          1.0068e-01, -1.2682e-01,  1.8329e-01,  1.7448e-01, -1.4579e-01,\n",
      "          2.5268e-01,  1.2201e-02,  2.8542e-01,  1.6855e-01,  9.4160e-02,\n",
      "          1.4707e-01,  1.3775e-01, -1.5905e-01,  6.1558e-02,  3.0416e-02,\n",
      "         -3.0406e-02, -2.5504e-01, -1.7010e-01,  2.1941e-01, -2.2255e-02,\n",
      "          4.7991e-02, -1.6793e-01, -1.0591e-01,  8.7541e-03,  3.9675e-01,\n",
      "         -3.6278e-01,  2.4595e-01,  6.7610e-02,  1.2790e-01, -2.5856e-01,\n",
      "         -2.0531e-01,  9.9981e-02,  1.5368e-01, -4.1116e-01,  3.5037e-03,\n",
      "          1.8177e-01,  9.0201e-02,  2.2977e-01,  2.4482e-01, -1.7826e-02,\n",
      "         -1.1196e-01,  4.9575e-01, -1.5899e-01, -1.2415e-01,  2.7949e-01,\n",
      "         -2.9249e-01, -2.8220e-01,  2.7217e-01, -3.4125e-02,  3.0862e-01,\n",
      "          1.3084e-01,  4.4898e-02,  8.8758e-02, -6.0447e-01,  9.3964e-02,\n",
      "         -4.6341e-01, -2.9832e-02,  3.8618e-02, -8.2442e-02, -2.0319e-01,\n",
      "          1.3584e-01,  2.9886e-01, -2.5487e-01, -2.5767e-02,  2.0504e-01,\n",
      "          8.7964e-02, -1.2103e-01,  4.7450e-01, -3.5141e-02,  2.1885e-01,\n",
      "         -7.5021e-02,  2.4840e-01, -1.9416e-01,  2.7989e-01, -2.6414e-01,\n",
      "         -1.1346e-01,  2.8356e-02,  9.6881e-02,  5.8332e-02, -7.1739e-02,\n",
      "         -3.3958e-01,  2.3276e-01, -4.7072e-02, -4.4056e-02, -4.1273e-02,\n",
      "          7.8250e-02,  1.1510e-03,  6.3389e-02,  7.8265e-02,  3.1258e-01,\n",
      "          2.3345e-01, -6.8131e-03, -3.6549e-01, -3.1273e-02, -1.0368e-01,\n",
      "          5.1161e-02,  3.1824e-02, -1.4282e-02,  4.5333e-01, -1.2327e-01,\n",
      "         -4.0309e-03, -1.4677e-01,  2.6467e-01,  2.0033e-01,  1.4978e-01,\n",
      "          1.1477e-01,  5.7699e-02,  1.3606e-01, -6.4505e-02, -7.3901e-03,\n",
      "         -1.5500e-01, -2.2237e-01, -2.9899e-01,  2.3093e-01, -2.4204e-01,\n",
      "         -1.8156e-01,  1.4832e-01,  2.1582e-01, -1.4060e-01,  1.2748e-01,\n",
      "          3.0568e-01,  1.0218e-01, -1.3230e-01,  2.7016e-01, -1.3977e-01,\n",
      "          1.1556e-01,  3.0991e-01, -1.8952e-02,  1.8464e-01,  5.0476e-01,\n",
      "          2.3332e-01, -3.6071e-01, -3.0431e-02, -2.5311e-01,  1.7416e-02,\n",
      "          2.5296e-01, -1.7282e-01,  2.0214e-01,  3.7780e-01,  3.3448e-01,\n",
      "          4.6102e-01,  1.9057e-02, -1.3013e-01,  1.0611e-01,  2.2801e-01,\n",
      "          3.6510e-02, -1.6481e-01, -1.7618e-01,  2.6747e-01,  3.8432e-02,\n",
      "         -1.3507e-01, -2.0666e-02, -9.8377e-02,  5.2724e-02, -1.2774e-01,\n",
      "         -3.8202e-01,  3.4049e-02,  2.0159e-01, -4.9286e-01,  5.9598e-02,\n",
      "         -2.6825e-01,  1.3807e-02, -2.2473e-01,  2.0828e-01, -2.2684e-01,\n",
      "         -1.0456e-01,  4.0435e-01, -8.1113e-02,  6.0021e-02, -1.8384e-01,\n",
      "         -1.3594e-01,  2.0455e-02,  1.7256e-02, -2.3797e-02, -3.1402e-02,\n",
      "          3.4874e-01, -1.1418e-01,  2.3774e-02,  2.1182e-02,  2.1567e-01,\n",
      "         -6.4889e-02,  1.9027e-01, -6.1408e-03, -1.3270e-01, -3.8011e-01,\n",
      "          1.3047e-01, -1.9487e-01, -4.3996e-01, -3.5665e-01,  3.5255e-01,\n",
      "         -1.3625e-01, -2.6911e-01, -2.2606e-01, -2.5596e-01,  7.0299e-02,\n",
      "          1.8637e-01,  4.7377e-01, -4.1745e-01, -6.5771e-02,  5.0016e-01,\n",
      "         -6.9477e-02, -1.6745e-01,  3.0487e-01,  2.1109e-01, -3.2696e-01,\n",
      "          3.2110e-01,  2.6859e-01, -6.4957e-02,  2.1962e-02,  5.2271e-01,\n",
      "          1.3336e-01,  1.8802e-01, -2.1584e-01,  4.6614e-01, -2.3099e-01,\n",
      "          2.8739e-01, -1.5830e-01, -2.3563e-01, -1.8145e-01,  3.2653e-02,\n",
      "          3.0839e-01,  1.9513e-01, -3.9318e-01, -1.0445e-01,  6.1733e-02,\n",
      "          3.4895e-01, -3.8698e-01, -5.7070e-02, -9.7016e-03, -3.4534e-01,\n",
      "          1.1896e-01,  9.0933e-02,  2.2761e-01, -3.8735e-01, -4.0120e-03,\n",
      "          4.0380e-01, -2.9540e-01,  1.2783e-01,  3.1208e-01,  8.8234e-02,\n",
      "          3.4263e-01, -3.3351e-02,  7.7557e-03,  4.5386e-02, -2.3060e-01,\n",
      "         -2.1711e-02,  1.2157e-01,  5.4995e-01,  1.6696e-01, -3.6539e-01,\n",
      "          1.1459e-01,  2.6013e-01, -1.6103e-01,  2.7828e-01, -8.7109e-02,\n",
      "         -6.0765e-02,  2.5808e-01, -5.2193e-02,  1.7343e-01, -8.3517e-02,\n",
      "         -2.1480e-01, -3.1597e-01,  3.6757e-01, -2.2710e-01, -1.3269e-01,\n",
      "         -1.6432e-01, -1.2302e-01, -1.3751e-01,  7.6207e-02, -3.7409e-01,\n",
      "          3.3105e-01,  1.2751e-01, -2.0906e-01, -1.0358e-01, -9.5827e-02,\n",
      "         -1.4510e-01, -2.2326e-01, -2.8245e-01,  4.3112e-01, -1.7310e-01,\n",
      "         -4.5428e-01,  2.5673e-01,  5.5129e-02,  3.4291e-01,  5.4287e-02,\n",
      "          8.7365e-02, -5.0801e-02,  1.3405e-01,  8.5152e-02, -1.3926e-01,\n",
      "          2.8145e-01,  5.5604e-02, -5.6820e-01, -1.4817e-01, -2.4191e-01,\n",
      "          1.0328e-01,  2.0726e-01, -3.5115e-01,  1.8183e-02,  4.1356e-02,\n",
      "          1.3001e-01,  2.0131e-02, -1.2801e-01, -5.9633e-02,  4.1167e-01,\n",
      "          2.3647e-01,  2.7715e-01,  8.1544e-02,  2.3413e-01, -3.4904e-02,\n",
      "         -3.5157e-01,  4.3852e-02,  8.8417e-02, -2.0185e-01,  4.4385e-01,\n",
      "         -1.3148e-01, -3.9583e-01, -8.8055e-02,  3.9915e-01,  1.1281e-01,\n",
      "         -1.0141e-02, -3.6380e-02,  2.3138e-01,  1.8151e-01, -1.3976e-01,\n",
      "          1.8107e-01, -3.5753e-02, -1.4010e-01, -1.3643e-01,  8.6381e-02,\n",
      "         -2.2782e-01,  2.2852e-02, -1.5278e-01,  1.8571e-03, -2.1577e-01,\n",
      "          1.8011e-02, -2.2580e-01,  2.7291e-01, -3.3874e-01,  1.2000e-01,\n",
      "          6.9773e-02,  3.0793e-01, -3.6171e-01, -1.4258e-01, -6.5982e-02,\n",
      "          1.7538e-01,  2.8119e-01,  3.4108e-01,  3.5802e-02,  3.6020e-03,\n",
      "         -1.7684e-01, -2.5257e-01,  6.3717e-02, -2.1298e-01,  1.2919e-01,\n",
      "          6.1348e-02,  2.4227e-01, -3.1202e-01, -1.8310e-01,  2.4663e-01,\n",
      "         -9.4920e-02, -1.4804e-01,  4.2247e-01,  2.4830e-01,  2.1344e-01,\n",
      "          3.1649e-02,  2.4401e-01,  5.7135e-02, -1.8168e-01, -1.4827e-01,\n",
      "         -2.5817e-01,  8.4959e-02, -1.2443e-01, -6.2028e-02, -6.3609e-02,\n",
      "         -1.2703e-01, -1.9767e-01, -1.5625e-01,  1.4351e-01,  1.3035e-01,\n",
      "          1.3762e-02, -6.2970e-02, -5.8642e-02, -2.7242e-01,  3.0717e-01,\n",
      "          9.6554e-03,  8.5453e-02, -8.2862e-02,  3.4894e-02, -1.4301e-01,\n",
      "          2.4180e-01,  2.0931e-01,  6.4633e-02, -1.8594e-01, -4.2737e-02,\n",
      "         -3.1647e-01, -3.7859e-01,  4.4767e-02,  1.4221e-01,  1.3871e-01,\n",
      "         -9.2903e-02, -3.1577e-01, -1.0186e-02, -1.3969e-01,  1.8377e-01,\n",
      "          4.8466e-03, -1.8343e-01, -8.9713e-02, -4.3429e-02, -4.7644e-02,\n",
      "          7.3956e-02, -2.2820e-01, -2.0389e-01, -1.1765e-01, -9.3285e-02,\n",
      "         -7.4957e-02,  3.6290e-01, -4.6687e-02,  2.8321e-01, -1.5989e-01,\n",
      "          3.6545e-03, -1.7854e-01,  1.0508e-01, -5.4333e-02,  7.9194e-02,\n",
      "          2.8310e-01, -4.6425e-01, -1.5292e-01, -1.4209e-03, -2.1938e-01,\n",
      "         -1.5414e-01, -6.5673e-02, -3.2282e-02,  2.1139e-01, -3.3255e-01,\n",
      "          1.7837e-01, -7.9680e-02,  1.8697e-01, -7.6052e-02, -2.4356e-01,\n",
      "         -1.6496e-01,  2.2136e-04,  2.5271e-01, -3.3634e-01, -2.7069e-01,\n",
      "         -2.8098e-01, -9.3457e-02, -6.4577e-02, -2.8800e-01,  4.2327e-01,\n",
      "         -1.3651e-01, -7.6636e-02,  2.5705e-02,  4.5715e-01,  1.9693e-01,\n",
      "          2.0371e-01,  1.8938e-01, -2.6964e-02,  3.2863e-02,  1.2427e-01,\n",
      "         -4.9052e-01,  2.3797e-01, -2.0466e-01, -1.4686e-01,  4.0803e-02,\n",
      "          9.3166e-02, -3.0909e-02,  1.7621e-03, -1.5468e-01, -1.0947e-01,\n",
      "          2.2076e-01, -3.6642e-01, -3.1162e-02,  2.6837e-01,  1.5044e-01,\n",
      "         -2.5922e-01,  3.8125e-02,  1.1545e-01,  3.8037e-01,  1.0256e-01,\n",
      "         -2.4322e-01,  1.3916e-01, -3.3943e-01, -5.2445e-02, -2.3033e-01,\n",
      "         -2.9455e-01,  1.4783e-01, -6.2998e-02,  5.4090e-02, -8.2872e-02,\n",
      "         -2.8278e-01,  2.2463e-01, -4.9204e-02, -6.8271e-02,  4.3094e-01,\n",
      "          3.0685e-02, -1.0802e-01,  1.6458e-01,  1.0349e-02,  2.6148e-02,\n",
      "         -1.0311e-01,  2.6019e-01,  1.8597e-01, -3.0105e-01,  1.4853e-01,\n",
      "         -1.3116e-01, -6.5473e-02, -1.0425e-01]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                   | 4/14274 [00:03<3:00:54,  1.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0427,  0.0858, -0.0220,  ..., -0.1157, -0.0512, -0.0309],\n",
      "         [ 0.0114, -0.2390, -0.0557,  ..., -0.3332,  0.1852,  0.0751],\n",
      "         [ 0.0879,  0.1554,  0.1251,  ...,  0.1847, -0.0294, -0.0489],\n",
      "         ...,\n",
      "         [-0.0561,  0.0998, -0.0271,  ..., -0.2057,  0.0201, -0.1525],\n",
      "         [-0.0561,  0.0998, -0.0271,  ..., -0.2057,  0.0201, -0.1525],\n",
      "         [-0.0561,  0.0998, -0.0271,  ..., -0.2057,  0.0201, -0.1525]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-1.3738e-02, -2.0784e-01, -2.1963e-01, -1.1118e-01,  1.5323e-01,\n",
      "          1.8332e-01,  2.5949e-01, -7.3172e-02, -5.0565e-02, -1.7314e-01,\n",
      "          2.2505e-01, -3.7901e-05, -8.0733e-02,  7.8247e-02, -1.2294e-01,\n",
      "          5.1120e-01,  2.2906e-01, -4.6926e-01,  1.0668e-02, -3.9428e-02,\n",
      "         -2.3985e-01,  7.2482e-02,  4.5569e-01,  2.9660e-01,  1.3645e-01,\n",
      "          7.0573e-02, -1.2183e-01, -3.9758e-02,  1.9024e-01,  2.2503e-01,\n",
      "          2.6853e-01,  5.5145e-02,  1.0645e-01,  2.5476e-01, -2.5664e-01,\n",
      "          3.2860e-02, -3.0222e-01,  2.5479e-02,  2.4574e-01, -1.8196e-01,\n",
      "         -7.9732e-02,  1.6882e-01,  1.8236e-01, -1.3465e-01, -1.1506e-01,\n",
      "          3.9543e-01,  2.4116e-01,  6.0263e-02, -1.2615e-01, -9.1361e-02,\n",
      "         -3.6894e-01,  3.7509e-01,  2.9234e-01,  2.1116e-01, -3.3694e-02,\n",
      "          2.0486e-02, -1.2333e-01,  2.5168e-01, -6.4847e-02, -8.4419e-02,\n",
      "         -1.2645e-01, -2.1992e-01, -1.8065e-02, -4.8406e-02, -6.1330e-03,\n",
      "         -1.4694e-01,  8.6962e-02, -1.5516e-01, -1.3971e-01,  5.5681e-02,\n",
      "         -8.0752e-02,  1.5715e-01,  1.3595e-01, -2.6046e-01, -2.6238e-01,\n",
      "          6.4081e-02, -5.9964e-01, -9.6869e-02,  2.8238e-01,  4.2435e-01,\n",
      "         -1.2147e-01,  1.9121e-01,  1.2027e-02,  2.1614e-01, -1.4408e-02,\n",
      "         -5.6496e-02, -4.7474e-02, -8.9172e-02,  1.8438e-01,  2.6586e-01,\n",
      "         -2.1071e-01, -3.8810e-01,  7.7308e-02,  2.9462e-02, -8.9565e-02,\n",
      "         -2.3802e-03, -1.2245e-02, -1.1862e-01, -1.7846e-01, -1.6378e-01,\n",
      "          4.5173e-02, -2.6895e-01, -1.1877e-01,  2.5978e-01, -2.8880e-02,\n",
      "         -2.1120e-01, -5.6150e-02,  2.8375e-01,  5.8365e-02, -1.1251e-01,\n",
      "         -1.7851e-01,  4.1419e-01,  3.0580e-01,  3.6085e-02,  9.3646e-03,\n",
      "          1.8889e-01,  1.1144e-01, -2.7982e-01,  4.2487e-01, -3.0624e-01,\n",
      "          1.3264e-02, -9.4686e-02,  1.1394e-01,  1.2316e-01, -1.9686e-01,\n",
      "          2.6654e-01,  1.4038e-01,  2.4934e-01,  1.9326e-01,  8.8398e-02,\n",
      "         -2.2717e-02,  1.1796e-01, -1.1668e-01,  1.4215e-01,  1.8412e-01,\n",
      "          1.0750e-01,  1.9021e-02, -3.1288e-01, -1.7800e-01,  2.3299e-01,\n",
      "          3.3417e-01,  1.2716e-01, -2.0976e-02,  2.0425e-01,  8.6163e-02,\n",
      "          2.2983e-01,  1.3507e-01, -3.9807e-01,  3.8816e-02,  3.3561e-01,\n",
      "          9.2859e-02,  1.6521e-01, -7.7660e-02, -2.8074e-01, -2.5020e-01,\n",
      "         -1.0084e-01,  4.9350e-02, -3.1763e-01, -1.2561e-01,  3.6961e-01,\n",
      "          1.2413e-02,  1.0338e-02, -1.5251e-01, -2.4372e-01, -3.0193e-02,\n",
      "         -1.1928e-01,  6.9971e-03,  1.1070e-01, -7.2110e-02, -4.1608e-01,\n",
      "         -1.0029e-01, -5.3925e-01, -1.2747e-01,  1.8555e-01, -2.8994e-01,\n",
      "          2.3815e-01, -2.6426e-01,  7.3481e-02,  4.0664e-01,  3.8322e-02,\n",
      "         -1.3824e-03, -1.6394e-01, -4.1504e-02,  9.9458e-02,  3.1731e-01,\n",
      "          2.2900e-01, -3.7258e-01,  9.4569e-02,  1.4750e-01,  2.5089e-01,\n",
      "          1.4982e-01, -3.2209e-02, -1.2949e-01,  1.0631e-01, -2.0917e-01,\n",
      "          1.6898e-01, -2.3308e-01,  1.8706e-01, -2.6459e-01, -2.3859e-01,\n",
      "          2.8179e-01, -3.8775e-01, -3.5543e-02,  8.3030e-02,  2.5985e-01,\n",
      "          1.3750e-02, -5.4788e-02, -1.0391e-01,  8.8462e-02,  1.9217e-01,\n",
      "          1.3028e-01, -4.0038e-01,  2.6153e-01, -1.1120e-02, -3.8227e-02,\n",
      "         -2.4773e-02,  1.8105e-01,  2.4431e-01,  1.0559e-01, -3.9576e-01,\n",
      "         -1.4475e-01,  1.0993e-01,  2.6172e-01, -2.5879e-01,  1.6392e-01,\n",
      "         -2.6119e-01, -3.8923e-01, -1.6023e-01,  2.2013e-01,  2.2167e-01,\n",
      "          1.6544e-01, -2.7164e-01,  1.7060e-01, -8.2024e-02, -4.4174e-01,\n",
      "         -3.4875e-01, -7.1689e-02,  2.5212e-01,  1.7220e-01,  1.7698e-01,\n",
      "          2.4903e-01,  5.4578e-02,  8.4969e-02,  1.7348e-01,  1.3540e-01,\n",
      "         -1.8213e-01,  1.6397e-01, -3.7798e-01, -5.9516e-02, -2.5523e-01,\n",
      "         -1.8011e-01, -1.9400e-01,  4.0470e-01, -2.3155e-01,  2.5037e-01,\n",
      "          3.8090e-01, -2.9120e-01, -1.1569e-01,  1.2054e-01,  8.0964e-02,\n",
      "          1.1250e-01, -1.4150e-01,  1.9399e-01,  1.4661e-01, -1.2194e-01,\n",
      "          2.4775e-01,  2.6130e-02,  2.4201e-01,  1.6119e-01,  9.7540e-02,\n",
      "          1.5060e-01,  1.1387e-01, -1.5764e-01,  4.9650e-02,  1.0187e-02,\n",
      "         -1.7132e-02, -2.5850e-01, -1.7054e-01,  2.2462e-01, -3.1264e-02,\n",
      "          3.2912e-02, -1.5243e-01, -1.0648e-01,  3.8134e-03,  4.0769e-01,\n",
      "         -3.6685e-01,  2.4368e-01,  9.0243e-02,  1.4819e-01, -2.7124e-01,\n",
      "         -1.8698e-01,  8.2417e-02,  1.4159e-01, -4.0112e-01,  7.5117e-03,\n",
      "          1.6700e-01,  1.0382e-01,  1.9880e-01,  2.4740e-01, -2.0089e-02,\n",
      "         -1.0738e-01,  4.6359e-01, -1.7576e-01, -1.3635e-01,  2.5592e-01,\n",
      "         -2.8176e-01, -3.0505e-01,  2.4748e-01, -3.4087e-02,  3.0452e-01,\n",
      "          1.1722e-01,  3.4706e-02,  9.6650e-02, -6.0995e-01,  8.5993e-02,\n",
      "         -4.4688e-01,  2.1847e-04,  9.0628e-03, -8.0795e-02, -2.1819e-01,\n",
      "          1.1462e-01,  2.9976e-01, -2.6193e-01, -3.8219e-02,  2.2467e-01,\n",
      "          7.7726e-02, -1.1455e-01,  4.6885e-01, -3.0504e-02,  2.0110e-01,\n",
      "         -6.7900e-02,  2.3729e-01, -2.0609e-01,  2.4464e-01, -2.6452e-01,\n",
      "         -8.9706e-02,  2.5921e-02,  9.2370e-02,  7.9845e-02, -4.7928e-02,\n",
      "         -3.2759e-01,  2.3141e-01, -2.5475e-02, -7.6021e-02, -3.7357e-02,\n",
      "          9.6992e-02, -1.5221e-03,  4.0602e-02,  8.1614e-02,  3.1111e-01,\n",
      "          2.6519e-01, -2.7050e-02, -3.5208e-01,  2.3580e-05, -1.1349e-01,\n",
      "          6.0317e-02, -4.7683e-03, -1.8771e-02,  4.2368e-01, -1.0560e-01,\n",
      "         -6.2803e-03, -1.3935e-01,  2.4787e-01,  1.9447e-01,  1.3439e-01,\n",
      "          1.2257e-01,  6.5795e-02,  1.1268e-01, -7.3826e-02, -2.4727e-02,\n",
      "         -1.7096e-01, -2.1788e-01, -2.9055e-01,  2.2171e-01, -2.2086e-01,\n",
      "         -1.7106e-01,  1.5671e-01,  1.8322e-01, -1.3868e-01,  1.2738e-01,\n",
      "          3.0704e-01,  1.1093e-01, -1.4258e-01,  2.5226e-01, -1.1056e-01,\n",
      "          1.2409e-01,  3.1511e-01, -1.3318e-02,  1.6811e-01,  5.2618e-01,\n",
      "          2.2348e-01, -3.7091e-01, -2.9361e-02, -2.2881e-01,  2.7921e-02,\n",
      "          2.5672e-01, -1.7796e-01,  1.9079e-01,  3.7128e-01,  3.0602e-01,\n",
      "          4.5024e-01,  1.1514e-02, -1.3426e-01,  9.6926e-02,  2.1069e-01,\n",
      "          2.8830e-02, -1.5681e-01, -1.7024e-01,  2.5396e-01,  3.3795e-02,\n",
      "         -1.3163e-01, -1.4866e-02, -9.0146e-02,  4.7262e-02, -1.2754e-01,\n",
      "         -3.7125e-01,  6.2328e-02,  1.8281e-01, -4.6022e-01,  6.1831e-02,\n",
      "         -3.0232e-01,  4.3964e-02, -2.3323e-01,  2.2573e-01, -2.4731e-01,\n",
      "         -1.0687e-01,  3.8687e-01, -5.9392e-02,  6.3694e-02, -1.9767e-01,\n",
      "         -1.4341e-01,  2.4549e-02,  2.5515e-02, -2.7796e-03, -8.8916e-03,\n",
      "          3.3721e-01, -1.1451e-01,  3.0378e-02,  4.1837e-02,  2.1454e-01,\n",
      "         -6.6007e-02,  1.9859e-01,  2.1121e-02, -1.3797e-01, -3.8382e-01,\n",
      "          1.2698e-01, -1.8421e-01, -4.3488e-01, -3.5094e-01,  3.5026e-01,\n",
      "         -1.2851e-01, -2.5280e-01, -2.2254e-01, -2.6210e-01,  6.3290e-02,\n",
      "          1.8655e-01,  4.4873e-01, -3.9922e-01, -5.5689e-02,  4.7566e-01,\n",
      "         -5.2843e-02, -1.7847e-01,  3.0661e-01,  2.1565e-01, -3.1661e-01,\n",
      "          3.3200e-01,  2.6061e-01, -5.4383e-02,  3.5332e-02,  5.1761e-01,\n",
      "          1.1656e-01,  1.8705e-01, -2.1689e-01,  4.5178e-01, -2.0907e-01,\n",
      "          2.8275e-01, -1.7805e-01, -2.1844e-01, -1.8612e-01, -3.2450e-03,\n",
      "          2.9824e-01,  1.7486e-01, -3.9991e-01, -1.0023e-01,  5.5393e-02,\n",
      "          3.3319e-01, -3.7568e-01, -1.0051e-01,  6.5355e-03, -3.3357e-01,\n",
      "          8.9189e-02,  8.3718e-02,  2.2533e-01, -3.7333e-01, -2.8443e-02,\n",
      "          3.9973e-01, -3.1242e-01,  1.3992e-01,  3.0810e-01,  9.4430e-02,\n",
      "          3.5147e-01, -1.7682e-02,  1.2199e-02,  6.2532e-02, -2.3871e-01,\n",
      "         -2.4904e-02,  1.2400e-01,  5.2425e-01,  1.4688e-01, -3.7190e-01,\n",
      "          8.3527e-02,  2.2501e-01, -1.1827e-01,  3.0823e-01, -8.2846e-02,\n",
      "         -1.0621e-01,  2.4558e-01, -5.3732e-02,  1.5855e-01, -8.3015e-02,\n",
      "         -2.1439e-01, -3.2777e-01,  3.3787e-01, -2.3729e-01, -1.1992e-01,\n",
      "         -1.4811e-01, -1.3900e-01, -1.1758e-01,  5.2820e-02, -3.7526e-01,\n",
      "          3.3155e-01,  9.8186e-02, -2.1262e-01, -6.3616e-02, -9.2228e-02,\n",
      "         -1.5030e-01, -2.0985e-01, -2.7123e-01,  4.3007e-01, -1.6541e-01,\n",
      "         -4.4177e-01,  2.4577e-01,  5.4075e-02,  3.3454e-01,  1.8470e-02,\n",
      "          9.8244e-02, -4.5387e-02,  1.1357e-01,  5.6002e-02, -1.1408e-01,\n",
      "          2.6805e-01,  6.0636e-02, -5.5832e-01, -1.1866e-01, -2.2960e-01,\n",
      "          9.6015e-02,  2.1143e-01, -3.2770e-01,  2.0481e-02,  3.8221e-02,\n",
      "          1.5487e-01,  6.5494e-02, -1.0550e-01, -6.0732e-02,  3.8805e-01,\n",
      "          2.0846e-01,  2.5222e-01,  9.1403e-02,  2.5561e-01, -1.9185e-02,\n",
      "         -2.9432e-01,  6.2596e-02,  7.8002e-02, -1.7559e-01,  4.3824e-01,\n",
      "         -9.4428e-02, -3.7116e-01, -7.4195e-02,  4.0764e-01,  1.1137e-01,\n",
      "         -2.7143e-02, -5.5861e-02,  2.0065e-01,  1.5758e-01, -1.2464e-01,\n",
      "          1.8349e-01, -4.0718e-02, -1.3982e-01, -1.2257e-01,  9.0734e-02,\n",
      "         -2.2488e-01,  6.5939e-02, -1.5425e-01, -1.7627e-02, -2.3061e-01,\n",
      "         -9.4021e-04, -2.0405e-01,  2.6178e-01, -3.5106e-01,  9.5059e-02,\n",
      "          8.6194e-02,  3.0698e-01, -3.5709e-01, -1.5190e-01, -7.6547e-02,\n",
      "          1.4599e-01,  2.7367e-01,  3.2298e-01,  5.1319e-02,  5.4435e-03,\n",
      "         -1.6572e-01, -2.3376e-01,  8.8638e-02, -2.1186e-01,  1.4427e-01,\n",
      "          8.5933e-02,  2.1961e-01, -3.3271e-01, -1.6521e-01,  2.5469e-01,\n",
      "         -1.1038e-01, -1.1558e-01,  4.1236e-01,  2.5380e-01,  2.4200e-01,\n",
      "          3.2643e-02,  2.4007e-01,  6.2139e-02, -2.1629e-01, -1.3608e-01,\n",
      "         -2.1606e-01,  7.7549e-02, -9.3092e-02, -4.9673e-02, -1.6321e-02,\n",
      "         -1.0006e-01, -1.9450e-01, -1.5866e-01,  1.4843e-01,  1.1879e-01,\n",
      "          1.0816e-02, -3.6059e-02, -2.3634e-02, -2.4975e-01,  3.2113e-01,\n",
      "          3.1602e-03,  8.1050e-02, -6.9495e-02,  2.4539e-02, -1.5525e-01,\n",
      "          2.3026e-01,  2.0984e-01,  6.6012e-02, -1.7468e-01, -5.2185e-02,\n",
      "         -3.0013e-01, -3.7438e-01,  4.6131e-02,  1.4883e-01,  1.1954e-01,\n",
      "         -7.0130e-02, -2.9781e-01,  1.7678e-02, -1.0666e-01,  1.7220e-01,\n",
      "          1.2239e-02, -1.6354e-01, -8.2216e-02, -5.4968e-02, -5.1539e-02,\n",
      "          8.3620e-02, -2.1072e-01, -1.8101e-01, -1.0218e-01, -7.9847e-02,\n",
      "         -7.8580e-02,  3.7299e-01, -3.7343e-02,  2.6894e-01, -1.6783e-01,\n",
      "          8.2604e-03, -1.6038e-01,  1.0799e-01, -5.1231e-02,  6.6679e-02,\n",
      "          2.6846e-01, -4.5012e-01, -1.5863e-01,  5.8280e-03, -2.2639e-01,\n",
      "         -1.1740e-01, -7.4587e-02, -6.1548e-02,  2.1864e-01, -3.2731e-01,\n",
      "          2.0820e-01, -6.8002e-02,  1.6901e-01, -5.0454e-02, -2.4870e-01,\n",
      "         -1.5163e-01,  6.3636e-03,  2.5521e-01, -3.1723e-01, -2.3559e-01,\n",
      "         -2.6820e-01, -1.1044e-01, -5.2613e-02, -2.5985e-01,  4.1600e-01,\n",
      "         -1.3400e-01, -6.5371e-02,  4.5778e-02,  4.3950e-01,  2.0608e-01,\n",
      "          1.9025e-01,  1.9252e-01,  6.1164e-03,  2.8154e-02,  1.2875e-01,\n",
      "         -4.8037e-01,  2.0694e-01, -2.1245e-01, -1.2695e-01,  4.7168e-02,\n",
      "          6.9215e-02, -1.9297e-02,  4.4753e-03, -1.6522e-01, -9.3764e-02,\n",
      "          2.1077e-01, -3.8233e-01, -1.6527e-02,  2.5590e-01,  1.3662e-01,\n",
      "         -2.4629e-01,  6.7003e-02,  1.3753e-01,  4.0413e-01,  1.2173e-01,\n",
      "         -2.1620e-01,  1.3157e-01, -3.3446e-01, -2.6433e-02, -2.0985e-01,\n",
      "         -2.9063e-01,  1.3632e-01, -8.3510e-02,  8.8725e-02, -7.7173e-02,\n",
      "         -2.8979e-01,  2.2380e-01, -6.0198e-02, -7.4448e-02,  4.2782e-01,\n",
      "          4.1159e-02, -1.0455e-01,  1.4314e-01,  1.8544e-02,  4.3278e-02,\n",
      "         -1.0243e-01,  2.6940e-01,  1.9063e-01, -2.8900e-01,  1.4467e-01,\n",
      "         -1.0151e-01, -5.8920e-02, -1.1731e-01]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_batch_embeddings(tokenizer_res, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f96a3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4b5e9",
   "metadata": {},
   "source": [
    "## gather all questions for embeddings generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ace391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746105\n"
     ]
    }
   ],
   "source": [
    "all_questions = []\n",
    "\n",
    "for ds in ['train', 'dev', 'test']:\n",
    "    for nhop in ['1', '2', '3']:\n",
    "        raw = load_raw_qa('./data/QA_data/MetaQA/', mode=f'{ds}_{nhop}hop')\n",
    "        questions, _, _ = extract_question_entity_target(raw)\n",
    "        all_questions.extend(questions)\n",
    "\n",
    "print(len(all_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7210ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which movies can be described by robert schwentke'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8abdae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all-questions.pickle', 'wb') as f:\n",
    "    pickle.dump(all_questions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72a943",
   "metadata": {},
   "source": [
    "## tokenize and generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_res = tokenize_sentences(all_questions, batch_size=256)\n",
    "embeddings = get_batch_embeddings(tokenizer_res)\n",
    "\n",
    "\n",
    "with open('./embeddings.pickle', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fe06c9",
   "metadata": {},
   "source": [
    "## load question embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9b51c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('q-emb-dict.pickle', 'rb') as f:\n",
    "    question_embs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12bde3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embs['which movies can be described by robert schwentke'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6de62931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.array(list(question_embs.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff8b47",
   "metadata": {},
   "source": [
    "# Knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c50bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = data_loader.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bc48ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({767: {'relation_id': 0, 'relation_text': 'directed_by'}, 7125: {'relation_id': 10, 'relation_text': 'has_genre'}, 184: {'relation_id': 2, 'relation_text': 'release_year'}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.adj[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f92d2b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({1121: {'relation_id': 12, 'relation_text': 'written_by'}, 167: {'relation_id': 2, 'relation_text': 'release_year'}, 15595: {'relation_id': 6, 'relation_text': 'in_language'}, 31150: {'relation_id': 0, 'relation_text': 'directed_by'}, 40514: {'relation_id': 14, 'relation_text': 'has_tags'}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as graph.adj\n",
    "graph[1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "504adda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_text': 'has_tags_reverse'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes[1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20378487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37824 {'relation_id': 12, 'relation_text': 'written_by'}\n",
      "165 {'relation_id': 2, 'relation_text': 'release_year'}\n",
      "28874 {'relation_id': 0, 'relation_text': 'directed_by'}\n"
     ]
    }
   ],
   "source": [
    "for nbr, eattr in graph[5].items():\n",
    "    print(nbr, eattr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0be18",
   "metadata": {},
   "source": [
    "## moving in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "882bd866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Akira Kurosawa'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def traverse(entity_name, relation):\n",
    "    entity_id = entities_voc[entity_name]\n",
    "    neighbors = graph[entity_id]\n",
    "    for nbr_id, eattr in neighbors.items():\n",
    "        if eattr['relation_text'] == relation:\n",
    "            return entities_inv_voc[nbr_id]\n",
    "        \n",
    "traverse('After the Rain', 'written_by')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9068a60",
   "metadata": {},
   "source": [
    "## creating knowledge graph environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4c69023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total env size in mode train: 667874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1368,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class KGEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, n_relations, observation_space, q_embeddings, ent_embeddings, rel_embeddings,\n",
    "                 entities_vocab, entities_inv_vocab, rel_inv_voc, rel_voc, mode='train', nhops=[1,2,3]):\n",
    "        super(KGEnv, self).__init__()\n",
    "        \n",
    "        self.entities_vocab = entities_vocab\n",
    "        self.entities_inv_vocab = entities_inv_vocab\n",
    "        self.relations_inv_voc = rel_inv_voc\n",
    "        self.action_space = spaces.Discrete(n_relations)\n",
    "        self.rel_embeddings = rel_embeddings\n",
    "        self.observation_space = spaces.Box(low=-3, high=3, shape=(observation_space,))\n",
    "        self.q_embeddings = q_embeddings\n",
    "        self.ent_embeddings = ent_embeddings\n",
    "        self.relations_voc = rel_voc\n",
    "        self.questions = []\n",
    "        self.entities = []\n",
    "        self.targets = []\n",
    "        \n",
    "        for nhop in [str(h) for h in nhops]:\n",
    "            raw = load_raw_qa('./data/QA_data/MetaQA/', mode=f'{mode}_{nhop}hop')\n",
    "            questions, entities, targets = extract_question_entity_target(raw)\n",
    "            self.questions.extend(questions)\n",
    "            self.entities.extend(entities)\n",
    "            self.targets.extend(targets)\n",
    "            \n",
    "        print(f\"Total env size in mode {mode}: {len(self.targets)}\")\n",
    "\n",
    "        self.entities_idx = [entities_voc[t] for t in self.entities]\n",
    "        self.targets_idx = [[entities_voc[t] for t in ts] for ts in self.targets]\n",
    "        self.env_size = len(self.targets)\n",
    "        self.goal = None\n",
    "        self.hops = 0\n",
    "        self.current_q = self.current_ent = None\n",
    "        self.ent_hist = []\n",
    "        self.rel_hist = []\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.hops += 1\n",
    "        next_ent_id = self.traverse(self.current_ent, action)\n",
    "        if next_ent_id == -1:\n",
    "            next_ent_id = self.entities_vocab[self.current_ent]\n",
    "            \n",
    "        reward = 0\n",
    "        done = False\n",
    "        \n",
    "        #TODO:\n",
    "        if next_ent_id in self.goal:\n",
    "            done = True\n",
    "            reward = 1\n",
    "            \n",
    "        if self.hops > 3:\n",
    "            done = True\n",
    "            \n",
    "        e2_emb = self.ent_embeddings[next_ent_id]\n",
    "        e1_emb = self.ent_embeddings[self.entities_vocab[self.current_ent]]\n",
    "        r_emb = self.rel_embeddings[action]\n",
    "        \n",
    "#         self.rel_hist = r_emb if self.rel_hist is None else (r_emb + self.rel_hist)/2\n",
    "#         self.ent_hist = (e1_emb + e2_emb)/2\n",
    "        \n",
    "        self.rel_hist.append(r_emb)\n",
    "        self.ent_hist.append(e2_emb)\n",
    "        \n",
    "        self.current_ent = self.entities_inv_vocab[next_ent_id]\n",
    "        next_state = self.build_state_vec(self.current_q, next_ent_id, self.ent_hist, self.rel_hist)\n",
    "        \n",
    "        return next_state, reward, done, {}\n",
    "    \n",
    "    \n",
    "    def build_state_vec(self, question: str, entity: int, ent_hist, rel_hist):\n",
    "        q_emb = self.q_embeddings[question]\n",
    "        e_emb = self.ent_embeddings[entity]\n",
    "        \n",
    "        ent_track = len(ent_hist)\n",
    "        ent_hist_emb = sum(ent_hist)/ent_track\n",
    "        \n",
    "        rel_track = len(rel_hist)\n",
    "        rel_hist_emb = sum(rel_hist)/rel_track\n",
    "        \n",
    "        return np.concatenate([q_emb, e_emb, ent_hist_emb, rel_hist_emb])\n",
    "        \n",
    "    def traverse(self, entity_name, relation):\n",
    "        entity_id = entities_voc[entity_name]\n",
    "        neighbors = graph[entity_id]\n",
    "        possible_moves = []\n",
    "        for nbr_id, eattr in neighbors.items():\n",
    "            if eattr['relation_id'] == relation:\n",
    "                possible_moves.append(nbr_id)\n",
    "        \n",
    "        if len(possible_moves):\n",
    "            return choice(possible_moves)\n",
    "        return -1\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        self.hops = 0\n",
    "        self.rel_hist = [np.zeros(200)]\n",
    "        self.ent_hist = []\n",
    "        init_state = np.random.randint(low=0, high=self.env_size-1)\n",
    "        self.goal = self.targets_idx[init_state]\n",
    "        self.current_q = self.questions[init_state]\n",
    "        self.current_ent = self.entities[init_state]\n",
    "        e_emb = self.ent_embeddings[self.entities_idx[init_state]]\n",
    "        self.ent_hist.append(e_emb)\n",
    "        return self.build_state_vec(self.current_q, self.entities_idx[init_state], self.ent_hist, self.rel_hist)\n",
    "    \n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        print(self.current_q)\n",
    "        print(f\"current entity: {self.current_ent}\")\n",
    "        entity_id = entities_voc[self.current_ent]\n",
    "        neighbors = graph[entity_id]\n",
    "        \n",
    "        print(\"available moves:\")\n",
    "        for nbr_id, eattr in neighbors.items():\n",
    "            print(f\"--{eattr['relation_text']}({eattr['relation_id']})--> {self.entities_inv_vocab[nbr_id]}\")\n",
    "    \n",
    "    \n",
    "kg_env = KGEnv(len(relations_voc), observation_space=768+200+200+200, q_embeddings=question_embs,\n",
    "               ent_embeddings=ent_emb_dict, rel_embeddings=rel_emb_dict, entities_vocab=entities_voc, entities_inv_vocab=entities_inv_voc,\n",
    "                rel_inv_voc=relations_inv_voc, rel_voc=relations_voc)\n",
    "s = kg_env.reset()\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ced26b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when was the film Be with Me released\n",
      "current entity: Be with Me\n",
      "available moves:\n",
      "--written_by(11)--> Eric Khoo\n",
      "--written_by(11)--> Theresa Poh Lin Chan\n",
      "--release_year(16)--> 2005\n",
      "--has_genre(13)--> Drama\n",
      "--in_language(8)--> English\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "def manual_play_in_env():\n",
    "    state = kg_env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        kg_env.render()        \n",
    "        action = int(input())\n",
    "        state, reward, done, _ = kg_env.step(action)\n",
    "        \n",
    "manual_play_in_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f392de",
   "metadata": {},
   "source": [
    "# RL agent definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf26c21d",
   "metadata": {},
   "source": [
    "## QActor-critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65f9b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QActorCritic:\n",
    "    def __init__(self, tau, buffer_size, gamma, actor_lr, critic_lr, state_size, action_size, batch_size,\n",
    "                 device, warmup_step=1000, verbose=0, critic_warmup=5000, eps=0.5, min_eps=0.05):\n",
    "\n",
    "        self.max_buffer_size = buffer_size\n",
    "        self.gamma = torch.tensor(gamma)\n",
    "        \n",
    "        self.buffer = deque()\n",
    "        self.action_size = action_size\n",
    "        self.state_size = state_size\n",
    "        self.critic_warmup = critic_warmup\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.verbose = verbose\n",
    "        self.tau = tau\n",
    "        self.min_eps = min_eps\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.q = FCNet(state_size, action_size)\n",
    "        self.q_target = FCNet(state_size, action_size)\n",
    "        self.q.to(self.device)\n",
    "        self.q_target.to(self.device)\n",
    "        self.q_target.load_state_dict(self.q.state_dict())\n",
    "        self.critic_opt = optim.Adam(self.q.parameters(), lr=critic_lr)\n",
    "        \n",
    "        self.actor = FCNet(state_size, action_size, last_activation='softmax')\n",
    "        self.actor_target = FCNet(state_size, action_size, last_activation='softmax')\n",
    "        self.actor.to(self.device)\n",
    "        self.actor_target.to(self.device)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "        self.actor_opt = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        \n",
    "        \n",
    "        self.update_step = 0\n",
    "        self.warmup_step = warmup_step\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_q_val(self, qnet, state, action=None):\n",
    "        if action is None:\n",
    "            return qnet(state)\n",
    "        return qnet(state).gather(1, action.reshape(-1,1).long())\n",
    "        \n",
    "    def add_to_buffer(self, experience):\n",
    "        if len(self.buffer) >= self.max_buffer_size:\n",
    "            self.buffer.pop()\n",
    "        self.buffer.appendleft(experience)\n",
    "        \n",
    "    def _np_to_tensor(self, nparrs):\n",
    "        return [torch.from_numpy(arr).float().to(self.device) for arr in nparrs]\n",
    "        \n",
    "    def sample_minibatch(self):\n",
    "        idxs = np.random.randint(0, len(self.buffer), self.batch_size)\n",
    "        sample = [self.buffer[i] for i in idxs]\n",
    "        \n",
    "        states, actions, rewards, next_states, dones = list(map(lambda x: np.array(x, dtype=np.float64), zip(*sample)))\n",
    "        return tuple(self._np_to_tensor([states, actions, rewards, next_states, dones]))\n",
    "        \n",
    "    def get_action(self, state, det=False):\n",
    "        \"\"\"\n",
    "        if det=False it will sample based on output probabilities of policy function\n",
    "        \"\"\"\n",
    "#         state = torch.from_numpy(state.reshape(-1, self.state_size)).float().to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if not det:\n",
    "                dist = Categorical(self.policy(state))\n",
    "                actions = dist.sample()\n",
    "            else:\n",
    "                actions = torch.argmax(self.policy(state), dim=1)\n",
    "            \n",
    "            return actions\n",
    "        \n",
    "    def get_target_action(self, state, det=False):\n",
    "        with torch.no_grad():\n",
    "            if not det:\n",
    "                dist = Categorical(self.actor_target(state))\n",
    "                actions = dist.sample()\n",
    "            else:\n",
    "                actions = torch.argmax(self.actor_target(state), dim=1)\n",
    "            \n",
    "            return actions\n",
    "        \n",
    "    def get_single_action(self, state, det=False):\n",
    "        if self.update_step < self.critic_warmup:\n",
    "            return np.random.randint(self.action_size)\n",
    "        \n",
    "        if (random() < self.eps and not det):\n",
    "            return np.random.randint(self.action_size)\n",
    "        \n",
    "        state = torch.from_numpy(state.reshape(-1, self.state_size)).float().to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if not det:\n",
    "                dist = Categorical(self.policy(state))\n",
    "                action = dist.sample()\n",
    "            else:\n",
    "                action = torch.argmax(self.policy(state), dim=1)\n",
    "            \n",
    "        return action.cpu().numpy()[0]\n",
    "    \n",
    "    def policy(self, state):\n",
    "        return self.actor(state)\n",
    "    \n",
    "    def synchronize(self):\n",
    "        with torch.no_grad():\n",
    "            params = self.q.parameters()\n",
    "            targ_params = self.q_target.parameters()\n",
    "            for p, p_targ in zip(params, targ_params):\n",
    "                p_targ.data.mul_(1 - self.tau)\n",
    "                p_targ.data.add_(self.tau * p.data)\n",
    "                \n",
    "            params = self.actor.parameters()\n",
    "            targ_params = self.actor_target.parameters()\n",
    "            for p, p_targ in zip(params, targ_params):\n",
    "                p_targ.data.mul_(1 - self.tau)\n",
    "                p_targ.data.add_(self.tau * p.data)\n",
    "            \n",
    "        \n",
    "    def update_critic(self, batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones):\n",
    "        with torch.no_grad():\n",
    "            last_step_target = batch_dones * batch_rewards\n",
    "                        \n",
    "            next_actions = self.get_target_action(batch_next_states, det=False)\n",
    "            \n",
    "            middle_step_target = (1-batch_dones)*(batch_rewards + self.gamma*self.get_q_val(self.q_target, batch_next_states, next_actions).squeeze())\n",
    "            targets =  last_step_target + middle_step_target\n",
    "        \n",
    "        predictions = self.get_q_val(self.q, batch_states, batch_actions).squeeze()\n",
    "        loss = F.mse_loss(predictions, targets)\n",
    "        self.critic_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.critic_opt.step()\n",
    "        \n",
    "        self.synchronize()\n",
    "        \n",
    "        return loss.detach().cpu().numpy()\n",
    "    \n",
    "\n",
    "    def update_actor(self, batch_states):\n",
    "#         with torch.no_grad():\n",
    "#             q_vals = self.get_q_val(self.q_target, batch_states, batch_actions).squeeze()\n",
    "        dist = self.policy(batch_states)\n",
    "        actions = dist.sample()\n",
    "        with torch.no_grad():\n",
    "            q_vals = self.get_q_val(self.q, batch_states, actions).squeeze()\n",
    "            \n",
    "        action_probs = self.policy(batch_states)\n",
    "        action_logprobs = torch.clip(dist.log_prob(actions), min=-10, max=10)\n",
    "        \n",
    "        loss = -torch.mean(q_vals*action_logprobs)\n",
    "        \n",
    "        self.actor_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.actor_opt.step()\n",
    "        \n",
    "        return loss.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        self.update_step += 1\n",
    "    \n",
    "        self.add_to_buffer([state, action, reward, next_state, done])\n",
    "        \n",
    "        #TODO: warmup. should be configurable.\n",
    "        if len(self.buffer) < self.warmup_step:\n",
    "            return None, None         \n",
    "\n",
    "\n",
    "        batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones = self.sample_minibatch()\n",
    "\n",
    "        if self.update_step < self.critic_warmup:\n",
    "            critic_loss = self.update_critic(batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones)\n",
    "            return None, critic_loss\n",
    "\n",
    "        if done:\n",
    "            self.eps = max(self.min_eps, self.eps*0.999)\n",
    "        \n",
    "        critic_loss = self.update_critic(batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones)\n",
    "        actor_loss = self.update_actor(batch_states)\n",
    "        \n",
    "        return actor_loss, critic_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df1bca",
   "metadata": {},
   "source": [
    "## Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3472be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, last_activation=None):\n",
    "        super(FCNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, output_size)\n",
    "        self.last_activation = last_activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        if self.last_activation == 'softmax':\n",
    "            x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class DoubleDQN:\n",
    "    def __init__(self, buffer_size, gamma, lr, eps, state_size, action_size, batch_size,\n",
    "                 device, tau=0.99, eps_decay=0.999, min_eps=0.05, warmup_step=1000):\n",
    "        self.max_buffer_size = buffer_size\n",
    "        self.gamma = torch.tensor(gamma)\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        \n",
    "        #self.buffer = deque()\n",
    "        self.buffer = [None]*self.max_buffer_size\n",
    "        self.buf_idx = 0\n",
    "        \n",
    "        self.action_size = action_size\n",
    "        self.device = device\n",
    "        self.q = FCNet(state_size, action_size)\n",
    "        self.q_target = FCNet(state_size, action_size)\n",
    "        self.q.to(self.device)\n",
    "        self.q_target.to(self.device)\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optim.Adam(self.q.parameters(), lr=lr)\n",
    "        self.update_step = 0\n",
    "        self.tau = tau\n",
    "        self.min_eps = min_eps\n",
    "        self.eps_decay = eps_decay\n",
    "        self.warmup_steps = warmup_step\n",
    "        \n",
    "       \n",
    "        \n",
    "    def get_q_val(self, qnet, state, action=None):\n",
    "        if action is None:\n",
    "            return qnet(state)\n",
    "        return qnet(state).gather(1, action.reshape(-1,1).long())\n",
    "        \n",
    "    def add_to_buffer(self, experience):\n",
    "#         if len(self.buffer) >= self.max_buffer_size:\n",
    "#             self.buffer.pop()\n",
    "#         self.buffer.appendleft(experience)\n",
    "        self.buffer[self.buf_idx%self.max_buffer_size] = experience\n",
    "        self.buf_idx += 1\n",
    "        \n",
    "    def _np_to_tensor(self, nparrs):\n",
    "        return [torch.from_numpy(arr).float().to(self.device) for arr in nparrs]\n",
    "        \n",
    "    def sample_minibatch(self):\n",
    "        #idxs = np.random.randint(0, len(self.buffer), self.batch_size)\n",
    "        idxs = np.random.randint(0, min(self.max_buffer_size, self.buf_idx), self.batch_size)\n",
    "        sample = [self.buffer[i] for i in idxs]\n",
    "        \n",
    "        states, actions, rewards, next_states, dones = list(map(lambda x: np.array(x, dtype=np.float64), zip(*sample)))\n",
    "        return tuple(self._np_to_tensor([states, actions, rewards, next_states, dones]))\n",
    "    \n",
    "    def synchronize(self):\n",
    "        with torch.no_grad():\n",
    "            params = self.q.parameters()\n",
    "            targ_params = self.q_target.parameters()\n",
    "            for p, p_targ in zip(params, targ_params):\n",
    "                p_targ.data.mul_(1 - self.tau)\n",
    "                p_targ.data.add_(self.tau * p.data)\n",
    "        \n",
    "    def get_action(self, state, det=False):\n",
    "        state = torch.from_numpy(state).float().to(self.device)\n",
    "        with torch.no_grad():\n",
    "            act = np.argmax(self.get_q_val(self.q, state).cpu().numpy())\n",
    "        if det:\n",
    "            return act\n",
    "        if random() < self.eps:\n",
    "            return np.random.randint(0, self.action_size)\n",
    "        else:\n",
    "            #TODO: sample from q dist?\n",
    "            return act\n",
    "        \n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        self.update_step += 1\n",
    "        \n",
    "        self.add_to_buffer([state, action, reward, next_state, done])\n",
    "        \n",
    "        if self.buf_idx < self.warmup_steps:\n",
    "            return\n",
    "        \n",
    "        if done:\n",
    "            self.eps = max(self.min_eps, self.eps * self.eps_decay)\n",
    "        \n",
    "        \n",
    "        batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones = self.sample_minibatch()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            last_step_target = batch_dones * batch_rewards\n",
    "            \n",
    "            random_vals = torch.rand(size=(self.batch_size, ), device=self.device)\n",
    "            rand_mask = random_vals < self.eps\n",
    "            det_mask = random_vals >= self.eps\n",
    "            random_actions = torch.randint(low=0, high=self.action_size, size=(self.batch_size, ), device=self.device)\n",
    "            random_actions[det_mask] = 0\n",
    "            \n",
    "            next_actions = torch.argmax(self.get_q_val(self.q_target, batch_next_states), dim=1)\n",
    "            next_actions[rand_mask] = 0\n",
    "            \n",
    "            next_actions = next_actions + random_actions\n",
    "            middle_step_target = (1-batch_dones)*(batch_rewards + self.gamma*self.get_q_val(self.q, batch_next_states, next_actions).squeeze())\n",
    "            targets =  last_step_target + middle_step_target\n",
    "        \n",
    "        predictions = self.get_q_val(self.q, batch_states, batch_actions).squeeze()\n",
    "        loss = F.mse_loss(predictions, targets)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        self.synchronize()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02496fe6",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8d3b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total env size in mode train: 667874\n",
      "Total env size in mode dev: 39138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1070/800000 [00:01<29:56, 444.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1000 average return=0.07 current_eps:0.8 buffer_size:3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2070/800000 [00:03<28:21, 468.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2000 average return=0.07 current_eps:0.8 buffer_size:7541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3066/800000 [00:05<28:43, 462.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3000 average return=0.07 current_eps:0.8 buffer_size:11317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4108/800000 [00:07<30:09, 439.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4000 average return=0.02 current_eps:0.8 buffer_size:15075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5112/800000 [00:09<28:08, 470.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5000 average return=0.1 current_eps:0.8 buffer_size:18857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6124/800000 [00:11<27:55, 473.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6000 average return=0.03 current_eps:0.8 buffer_size:22672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7103/800000 [00:12<29:19, 450.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7000 average return=0.05 current_eps:0.8 buffer_size:26464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8118/800000 [00:14<28:31, 462.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8000 average return=0.11 current_eps:0.8 buffer_size:30254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9083/800000 [00:16<28:44, 458.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9000 average return=0.08 current_eps:0.8 buffer_size:34012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 10103/800000 [00:18<27:43, 474.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10000 average return=0.08 current_eps:0.8 buffer_size:37809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 11125/800000 [00:19<26:51, 489.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11000 average return=0.1 current_eps:0.8 buffer_size:41592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12075/800000 [00:21<28:04, 467.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12000 average return=0.1 current_eps:0.8 buffer_size:45348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13106/800000 [00:23<28:08, 466.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13000 average return=0.04 current_eps:0.8 buffer_size:49118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14009/800000 [00:40<5:35:53, 39.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14000 average return=0.15 current_eps:0.5459438850462682 buffer_size:52632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15012/800000 [01:01<4:16:42, 50.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15000 average return=0.33 current_eps:0.3310903020863681 buffer_size:55413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16012/800000 [01:18<4:04:28, 53.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16000 average return=0.23 current_eps:0.20079131049586138 buffer_size:57988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17000/800000 [01:37<4:25:52, 49.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17000 average return=0.31 current_eps:0.12177085863459788 buffer_size:60499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18000/800000 [01:57<3:30:08, 62.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18000 average return=0.31 current_eps:0.07384852450033136 buffer_size:63036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19013/800000 [02:13<4:10:21, 51.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19000 average return=0.39 current_eps:0.05 buffer_size:65559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20010/800000 [02:27<3:58:20, 54.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20000 average return=0.43 current_eps:0.05 buffer_size:68039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 21009/800000 [02:41<3:34:30, 60.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21000 average return=0.48 current_eps:0.05 buffer_size:70496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 22010/800000 [02:57<8:33:58, 25.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22000 average return=0.45 current_eps:0.05 buffer_size:73082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 29016/800000 [05:00<3:19:18, 64.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29000 average return=0.67 current_eps:0.05 buffer_size:90882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 30000/800000 [05:16<4:21:06, 49.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30000 average return=0.62 current_eps:0.05 buffer_size:93437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 31003/800000 [05:36<5:34:02, 38.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31000 average return=0.61 current_eps:0.05 buffer_size:96069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 32012/800000 [05:53<3:36:45, 59.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32000 average return=0.64 current_eps:0.05 buffer_size:98607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 33013/800000 [06:15<3:56:26, 54.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33000 average return=0.63 current_eps:0.05 buffer_size:101173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 34009/800000 [06:38<4:17:12, 49.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34000 average return=0.5 current_eps:0.05 buffer_size:103796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 35016/800000 [06:56<3:49:52, 55.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35000 average return=0.64 current_eps:0.05 buffer_size:106543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 36009/800000 [07:19<3:45:41, 56.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36000 average return=0.65 current_eps:0.05 buffer_size:109157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 37010/800000 [07:36<4:08:20, 51.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37000 average return=0.62 current_eps:0.05 buffer_size:111792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 38006/800000 [07:52<4:04:42, 51.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38000 average return=0.56 current_eps:0.05 buffer_size:114436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 39008/800000 [08:08<3:42:19, 57.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39000 average return=0.62 current_eps:0.05 buffer_size:116989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 40010/800000 [08:25<3:18:40, 63.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40000 average return=0.61 current_eps:0.05 buffer_size:119638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 41014/800000 [08:46<3:51:08, 54.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41000 average return=0.67 current_eps:0.05 buffer_size:122324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 42008/800000 [09:04<4:40:55, 44.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42000 average return=0.57 current_eps:0.05 buffer_size:124938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 43002/800000 [09:25<10:04:23, 20.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43000 average return=0.64 current_eps:0.05 buffer_size:127560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 44002/800000 [09:46<15:15:44, 13.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44000 average return=0.6 current_eps:0.05 buffer_size:130167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 45003/800000 [10:03<3:28:10, 60.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45000 average return=0.73 current_eps:0.05 buffer_size:132771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 46011/800000 [10:24<6:48:40, 30.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46000 average return=0.59 current_eps:0.05 buffer_size:135403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 47001/800000 [10:46<10:16:37, 20.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47000 average return=0.67 current_eps:0.05 buffer_size:138026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 48007/800000 [11:05<4:54:53, 42.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48000 average return=0.64 current_eps:0.05 buffer_size:140729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 54003/800000 [13:05<4:00:44, 51.65it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:54000 average return=0.7 current_eps:0.05 buffer_size:156695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 55014/800000 [13:24<3:22:13, 61.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:55000 average return=0.61 current_eps:0.05 buffer_size:159306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 56014/800000 [13:48<4:13:58, 48.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:56000 average return=0.62 current_eps:0.05 buffer_size:161984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 57007/800000 [14:11<7:23:42, 27.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:57000 average return=0.7 current_eps:0.05 buffer_size:164645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 58009/800000 [14:32<3:53:08, 53.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:58000 average return=0.63 current_eps:0.05 buffer_size:167269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 59002/800000 [14:54<13:26:05, 15.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:59000 average return=0.71 current_eps:0.05 buffer_size:169888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 60009/800000 [15:16<4:21:29, 47.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:60000 average return=0.67 current_eps:0.05 buffer_size:172548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 61013/800000 [15:40<3:51:45, 53.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:61000 average return=0.74 current_eps:0.05 buffer_size:175155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 62011/800000 [16:00<4:07:05, 49.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:62000 average return=0.66 current_eps:0.05 buffer_size:177844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 63013/800000 [16:19<3:30:49, 58.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:63000 average return=0.68 current_eps:0.05 buffer_size:180472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 64011/800000 [16:42<4:33:46, 44.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:64000 average return=0.62 current_eps:0.05 buffer_size:183065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 65001/800000 [17:01<4:10:32, 48.89it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:65000 average return=0.73 current_eps:0.05 buffer_size:185669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 66011/800000 [17:24<3:36:30, 56.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:66000 average return=0.74 current_eps:0.05 buffer_size:188297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 67012/800000 [17:45<3:36:06, 56.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:67000 average return=0.59 current_eps:0.05 buffer_size:190880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 68008/800000 [18:08<4:55:56, 41.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:68000 average return=0.61 current_eps:0.05 buffer_size:193481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 69015/800000 [18:34<4:11:25, 48.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:69000 average return=0.59 current_eps:0.05 buffer_size:196122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 70003/800000 [18:56<4:17:47, 47.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:70000 average return=0.72 current_eps:0.05 buffer_size:198718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 71005/800000 [19:21<4:16:02, 47.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:71000 average return=0.69 current_eps:0.05 buffer_size:201328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 72012/800000 [19:44<3:44:46, 53.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:72000 average return=0.57 current_eps:0.05 buffer_size:203966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 73010/800000 [20:05<2:54:01, 69.63it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:73000 average return=0.69 current_eps:0.05 buffer_size:206608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 74005/800000 [20:23<3:40:09, 54.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:74000 average return=0.67 current_eps:0.05 buffer_size:209178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 75014/800000 [20:42<3:27:59, 58.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:75000 average return=0.69 current_eps:0.05 buffer_size:211787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 75116/800000 [20:44<7:17:52, 27.59it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 19%|█▉        | 154000/800000 [45:14<2:56:03, 61.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:154000 average return=0.74 current_eps:0.05 buffer_size:413662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 155009/800000 [45:31<3:28:30, 51.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:155000 average return=0.71 current_eps:0.05 buffer_size:416162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 156009/800000 [45:47<3:02:07, 58.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:156000 average return=0.71 current_eps:0.05 buffer_size:418686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 157011/800000 [46:04<3:01:36, 59.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:157000 average return=0.73 current_eps:0.05 buffer_size:421226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 158000/800000 [46:20<3:04:39, 57.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:158000 average return=0.76 current_eps:0.05 buffer_size:423754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 159013/800000 [46:35<3:04:44, 57.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:159000 average return=0.66 current_eps:0.05 buffer_size:426339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 160008/800000 [46:51<3:07:54, 56.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:160000 average return=0.7 current_eps:0.05 buffer_size:428853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 161013/800000 [47:06<3:42:45, 47.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:161000 average return=0.58 current_eps:0.05 buffer_size:431391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 162012/800000 [47:23<3:40:28, 48.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:162000 average return=0.64 current_eps:0.05 buffer_size:433965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 163011/800000 [47:38<4:38:10, 38.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:163000 average return=0.71 current_eps:0.05 buffer_size:436492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 164008/800000 [47:56<2:55:42, 60.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:164000 average return=0.57 current_eps:0.05 buffer_size:439027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 165007/800000 [48:11<3:40:24, 48.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:165000 average return=0.68 current_eps:0.05 buffer_size:441601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 166010/800000 [48:27<3:16:26, 53.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:166000 average return=0.66 current_eps:0.05 buffer_size:444135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 167011/800000 [48:42<2:35:06, 68.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:167000 average return=0.72 current_eps:0.05 buffer_size:446650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 168006/800000 [48:57<3:45:00, 46.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:168000 average return=0.69 current_eps:0.05 buffer_size:449217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 169013/800000 [49:13<2:51:28, 61.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:169000 average return=0.65 current_eps:0.05 buffer_size:451758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 170005/800000 [49:29<3:26:50, 50.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:170000 average return=0.67 current_eps:0.05 buffer_size:454253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 171008/800000 [49:44<3:10:49, 54.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:171000 average return=0.66 current_eps:0.05 buffer_size:456721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 172008/800000 [50:02<4:19:35, 40.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:172000 average return=0.61 current_eps:0.05 buffer_size:459160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 172999/800000 [50:20<2:52:32, 60.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:173000 average return=0.65 current_eps:0.05 buffer_size:461675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 173999/800000 [50:37<2:12:49, 78.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:174000 average return=0.77 current_eps:0.05 buffer_size:464188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 175010/800000 [50:54<3:47:38, 45.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:175000 average return=0.75 current_eps:0.05 buffer_size:466745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 176012/800000 [51:09<2:47:02, 62.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:176000 average return=0.69 current_eps:0.05 buffer_size:469315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 177009/800000 [51:26<3:30:41, 49.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:177000 average return=0.63 current_eps:0.05 buffer_size:471826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 178007/800000 [51:41<4:03:28, 42.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:178000 average return=0.74 current_eps:0.05 buffer_size:474338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 179012/800000 [51:56<3:03:31, 56.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:179000 average return=0.64 current_eps:0.05 buffer_size:476906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 179232/800000 [52:00<2:28:56, 69.46it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 33%|███▎      | 261997/800000 [1:15:50<2:07:40, 70.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:262000 average return=0.72 current_eps:0.05 buffer_size:682904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 263014/800000 [1:16:07<2:38:08, 56.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:263000 average return=0.71 current_eps:0.05 buffer_size:685316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 264001/800000 [1:16:25<3:22:50, 44.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:264000 average return=0.62 current_eps:0.05 buffer_size:687767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 265010/800000 [1:16:43<3:10:44, 46.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:265000 average return=0.76 current_eps:0.05 buffer_size:690256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 266000/800000 [1:17:02<4:53:11, 30.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:266000 average return=0.78 current_eps:0.05 buffer_size:692790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 267005/800000 [1:17:23<3:50:14, 38.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:267000 average return=0.72 current_eps:0.05 buffer_size:695319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 268007/800000 [1:17:41<2:56:34, 50.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:268000 average return=0.67 current_eps:0.05 buffer_size:697814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 269009/800000 [1:17:57<2:40:32, 55.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:269000 average return=0.63 current_eps:0.05 buffer_size:700309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 270016/800000 [1:18:12<2:34:57, 57.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:270000 average return=0.62 current_eps:0.05 buffer_size:702785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 271010/800000 [1:18:29<2:16:57, 64.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:271000 average return=0.76 current_eps:0.05 buffer_size:705160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 272014/800000 [1:18:45<2:22:55, 61.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:272000 average return=0.7 current_eps:0.05 buffer_size:707625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 273013/800000 [1:19:00<2:27:04, 59.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:273000 average return=0.62 current_eps:0.05 buffer_size:710090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 274010/800000 [1:19:18<2:51:42, 51.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:274000 average return=0.69 current_eps:0.05 buffer_size:712517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 275013/800000 [1:19:33<2:04:05, 70.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:275000 average return=0.55 current_eps:0.05 buffer_size:714980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 276000/800000 [1:19:48<3:04:41, 47.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:276000 average return=0.65 current_eps:0.05 buffer_size:717432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 276996/800000 [1:20:04<2:16:27, 63.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:277000 average return=0.61 current_eps:0.05 buffer_size:719966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 278015/800000 [1:20:22<2:03:23, 70.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:278000 average return=0.68 current_eps:0.05 buffer_size:722453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 279008/800000 [1:20:37<2:34:09, 56.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:279000 average return=0.71 current_eps:0.05 buffer_size:724888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 280005/800000 [1:20:53<3:02:21, 47.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:280000 average return=0.61 current_eps:0.05 buffer_size:727336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 281012/800000 [1:21:10<2:03:49, 69.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:281000 average return=0.6 current_eps:0.05 buffer_size:729860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 282002/800000 [1:21:25<2:37:43, 54.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:282000 average return=0.62 current_eps:0.05 buffer_size:732238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 283012/800000 [1:21:40<2:11:27, 65.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:283000 average return=0.63 current_eps:0.05 buffer_size:734716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 284012/800000 [1:21:56<2:06:18, 68.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:284000 average return=0.62 current_eps:0.05 buffer_size:737149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 285013/800000 [1:22:13<2:39:19, 53.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:285000 average return=0.64 current_eps:0.05 buffer_size:739663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 286009/800000 [1:22:30<2:33:45, 55.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:286000 average return=0.74 current_eps:0.05 buffer_size:742125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 286026/800000 [1:22:30<2:12:30, 64.64it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 38%|███▊      | 300012/800000 [1:26:26<2:37:39, 52.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:300000 average return=0.71 current_eps:0.05 buffer_size:776502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 300999/800000 [1:26:42<1:44:45, 79.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:301000 average return=0.69 current_eps:0.05 buffer_size:778954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 302005/800000 [1:26:59<3:00:55, 45.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:302000 average return=0.6 current_eps:0.05 buffer_size:781324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 303010/800000 [1:27:16<2:39:32, 51.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:303000 average return=0.7 current_eps:0.05 buffer_size:783817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 304003/800000 [1:27:33<2:30:13, 55.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:304000 average return=0.72 current_eps:0.05 buffer_size:786256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 305014/800000 [1:27:49<2:39:08, 51.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:305000 average return=0.67 current_eps:0.05 buffer_size:788598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 306005/800000 [1:28:04<2:59:29, 45.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:306000 average return=0.7 current_eps:0.05 buffer_size:791032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 307005/800000 [1:28:22<4:23:46, 31.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:307000 average return=0.62 current_eps:0.05 buffer_size:793462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 308001/800000 [1:28:37<2:17:44, 59.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:308000 average return=0.63 current_eps:0.05 buffer_size:795834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 309009/800000 [1:28:56<2:28:11, 55.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:309000 average return=0.68 current_eps:0.05 buffer_size:798309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 310010/800000 [1:29:13<2:52:35, 47.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:310000 average return=0.71 current_eps:0.05 buffer_size:800720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 311010/800000 [1:29:31<2:12:05, 61.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:311000 average return=0.57 current_eps:0.05 buffer_size:803178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 311805/800000 [1:29:43<1:26:42, 93.83it/s]"
     ]
    }
   ],
   "source": [
    "def log(_str, path='./log.txt'):\n",
    "    print(_str)\n",
    "    with open(path, 'a') as f:\n",
    "        f.write(f\"{_str}\\n\")\n",
    "\n",
    "\n",
    "def evaluate_agent(env, agent, k=10):\n",
    "    returns = []\n",
    "    for _ in range(k):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        ret = 0\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            ret += reward\n",
    "        returns.append(ret)\n",
    "    return returns\n",
    "            \n",
    "def train_and_evaluate(env, agent, epochs, eval_env, eval_step=100, eval_it=50):\n",
    "    \n",
    "    returns = []\n",
    "    epsilons = []\n",
    "    eval_rets = []\n",
    "    for i in tqdm(range(1, epochs+1)):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        \n",
    "        ret = 0\n",
    "        while not done:\n",
    "            a = agent.get_action(state)\n",
    "            next_state, r, done, _ = env.step(a)\n",
    "            agent.update(state, a, r, next_state, done)\n",
    "            ret += r\n",
    "            state = next_state\n",
    "        done = False\n",
    "        epsilons.append(agent.eps)\n",
    "        returns.append(ret)\n",
    "        \n",
    "        \n",
    "        if i%eval_step == 0:\n",
    "            avg_ret = np.mean(evaluate_agent(eval_env, agent, k=eval_it))\n",
    "            log(f\"epoch:{i} average return={avg_ret} current_eps:{agent.eps} buffer_size:{agent.buf_idx}\")\n",
    "            eval_rets.append(avg_ret)\n",
    "            \n",
    "    return returns, epsilons, eval_rets\n",
    "\n",
    "\n",
    "\n",
    "env = KGEnv(\n",
    "    len(relations_voc),\n",
    "    observation_space=768+200+200+200,\n",
    "    q_embeddings=question_embs,\n",
    "    ent_embeddings=ent_emb_dict,\n",
    "    rel_embeddings=rel_emb_dict,\n",
    "    entities_vocab=entities_voc, \n",
    "    entities_inv_vocab=entities_inv_voc,\n",
    "    rel_inv_voc=relations_inv_voc, rel_voc=relations_voc,\n",
    "    mode='train'\n",
    ")\n",
    "\n",
    "\n",
    "eval_env = KGEnv(\n",
    "    len(relations_voc),\n",
    "    observation_space=768+200+200+200,\n",
    "    q_embeddings=question_embs,\n",
    "    ent_embeddings=ent_emb_dict,\n",
    "    rel_embeddings=rel_emb_dict,\n",
    "    entities_vocab=entities_voc, \n",
    "    entities_inv_vocab=entities_inv_voc,\n",
    "    rel_inv_voc=relations_inv_voc, rel_voc=relations_voc,\n",
    "    mode='dev'\n",
    ")\n",
    "\n",
    "ddqn = DoubleDQN(\n",
    "    buffer_size=150000,\n",
    "    gamma=0.99,\n",
    "    lr=3e-5,\n",
    "    eps=0.8,\n",
    "    state_size=env.observation_space.shape[0],\n",
    "    action_size=env.action_space.n,\n",
    "    batch_size=128,\n",
    "    eps_decay=0.9995,\n",
    "    warmup_step=50000,\n",
    "    min_eps=0.05,\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")\n",
    "\n",
    "\n",
    "returns, epsilons, eval_rets = train_and_evaluate(env, ddqn, epochs=800000, eval_env=eval_env, eval_step=1000, eval_it=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2c9d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total env size in mode dev: 14872\n",
      "0.716\n"
     ]
    }
   ],
   "source": [
    "eval_env = KGEnv(\n",
    "    len(relations_voc),\n",
    "    observation_space=768+200+200+200,\n",
    "    q_embeddings=question_embs,\n",
    "    ent_embeddings=ent_emb_dict,\n",
    "    rel_embeddings=rel_emb_dict,\n",
    "    entities_vocab=entities_voc, \n",
    "    entities_inv_vocab=entities_inv_voc,\n",
    "    rel_inv_voc=relations_inv_voc, rel_voc=relations_voc,\n",
    "    mode='dev',\n",
    "    nhops=[2]\n",
    ")\n",
    "\n",
    "avg_ret = np.mean(evaluate_agent(eval_env, ddqn, k=1000))\n",
    "print(avg_ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "01d7b75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n",
      "The Spanish Earth has_genre\n",
      "current entity: The Spanish Earth\n",
      "available moves:\n",
      "--directed_by(6)--> Joris Ivens\n",
      "--release_year(16)--> 1937\n",
      "--written_by(11)--> Ernest Hemingway\n",
      "--in_language(8)--> Spanish\n",
      "--written_by(11)--> John Dos Passos\n",
      "--has_genre(13)--> War\n",
      "--has_tags(7)--> spanish civil war\n"
     ]
    }
   ],
   "source": [
    "def play_in_env(ddqn):\n",
    "    state = kg_env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        kg_env.render()        \n",
    "        action = ddqn.get_action(state, det=True)\n",
    "        state, reward, done, _ = kg_env.step(action)\n",
    "        \n",
    "play_in_env(ddqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "5a3eed84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-05 12:38.55 [warning  ] Unused arguments are passed.   use_batch_norm=True\n",
      "2021-12-05 12:38.55 [info     ] Directory is created at d3rlpy_logs/DiscreteSAC_online_20211205123855\n",
      "2021-12-05 12:38.55 [debug    ] Building model...\n",
      "2021-12-05 12:38.55 [debug    ] Model has been built.\n",
      "2021-12-05 12:38.55 [info     ] Parameters are saved to d3rlpy_logs/DiscreteSAC_online_20211205123855/params.json params={'action_scaler': None, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'actor_learning_rate': 0.0003, 'actor_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 0.0001, 'weight_decay': 0, 'amsgrad': False}, 'batch_size': 64, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_learning_rate': 0.0003, 'critic_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 0.0001, 'weight_decay': 0, 'amsgrad': False}, 'gamma': 0.99, 'generated_maxlen': 100000, 'initial_temperature': 1.0, 'n_critics': 2, 'n_frames': 1, 'n_steps': 1, 'q_func_factory': {'type': 'mean', 'params': {'bootstrap': False, 'share_encoder': False}}, 'real_ratio': 1.0, 'reward_scaler': None, 'scaler': None, 'target_update_interval': 1000, 'temp_learning_rate': 0.0003, 'temp_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 0.0001, 'weight_decay': 0, 'amsgrad': False}, 'use_gpu': None, 'algorithm': 'DiscreteSAC', 'observation_shape': (1368,), 'action_size': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                                                                | 82/100000 [00:09<3:19:36,  8.34it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_5420/3356815215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m sac.fit_online(\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/d3rlpy/algos/base.py\u001b[0m in \u001b[0;36mfit_online\u001b[0;34m(self, env, buffer, explorer, n_steps, n_steps_per_epoch, update_interval, update_start_step, eval_env, eval_epsilon, save_metrics, save_interval, experiment_name, with_timestamp, logdir, verbose, show_progress, tensorboard_dir, timelimit_aware, callback)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0m_assert_action_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         train_single_env(\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/d3rlpy/online/iterators.py\u001b[0m in \u001b[0;36mtrain_single_env\u001b[0;34m(algo, env, buffer, explorer, n_steps, n_steps_per_epoch, update_interval, update_start_step, eval_env, eval_epsilon, save_metrics, save_interval, experiment_name, with_timestamp, logdir, verbose, show_progress, tensorboard_dir, timelimit_aware, callback)\u001b[0m\n\u001b[1;32m    254\u001b[0m                     \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"algorithm_update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0;31m# record metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/d3rlpy/base.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \"\"\"\n\u001b[0;32m--> 738\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/d3rlpy/algos/sac.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# lagrangian parameter update for SAC temeprature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_learning_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mtemp_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_temp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"temp_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtemp_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"temp\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/d3rlpy/torch_utility.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mset_train_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/d3rlpy/torch_utility.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/d3rlpy/algos/torch/sac_impl.py\u001b[0m in \u001b[0;36mupdate_temp\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_temp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarg_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "\n",
    "from d3rlpy.algos import DQN, DiscreteSAC\n",
    "from d3rlpy.online.buffers import ReplayBuffer\n",
    "from d3rlpy.online.explorers import LinearDecayEpsilonGreedy\n",
    "from d3rlpy.metrics.scorer import evaluate_on_environment\n",
    "\n",
    "env=kg_env\n",
    "\n",
    "dqn = DQN(\n",
    "    batch_size=32,\n",
    "    learning_rate=2.5e-4,\n",
    "    target_update_interval=100,\n",
    "    use_gpu=False\n",
    ")\n",
    "\n",
    "sac = DiscreteSAC(\n",
    "    use_batch_norm=True,\n",
    "    target_update_interval=1000,\n",
    "    use_gpu=False,\n",
    ")\n",
    "\n",
    "# setup replay buffer\n",
    "buffer = ReplayBuffer(maxlen=100000, env=env)\n",
    "\n",
    "# setup explorers\n",
    "explorer = LinearDecayEpsilonGreedy(start_epsilon=1.0,\n",
    "                                    end_epsilon=0.1,\n",
    "                                    duration=10000)\n",
    "\n",
    "# start training\n",
    "sac.fit_online(\n",
    "    env,\n",
    "    buffer,\n",
    "    n_steps=100000,\n",
    "    n_steps_per_epoch=100,\n",
    "    callback=evaluate_on_environment(eval_env, n_trials=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c32f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
