{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "198962b1",
   "metadata": {},
   "source": [
    "# initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "0e22e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from graph_embeddings.data_loader import DataLoader\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d772d98",
   "metadata": {},
   "source": [
    "# observing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c926e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset='MetaQA', reverse_rel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a6c7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_voc, relations_voc = data_loader.load_entity_relations_vocab()\n",
    "entities_inv_voc = {v: k for k, v in entities_voc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "971aad3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'written_by_reverse': 0,\n",
       " 'has_imdb_rating_reverse': 1,\n",
       " 'has_imdb_votes_reverse': 2,\n",
       " 'starred_actors': 3,\n",
       " 'release_year_reverse': 4,\n",
       " 'directed_by_reverse': 5,\n",
       " 'directed_by': 6,\n",
       " 'has_tags': 7,\n",
       " 'in_language': 8,\n",
       " 'in_language_reverse': 9,\n",
       " 'starred_actors_reverse': 10,\n",
       " 'written_by': 11,\n",
       " 'has_imdb_rating': 12,\n",
       " 'has_genre': 13,\n",
       " 'has_imdb_votes': 14,\n",
       " 'has_tags_reverse': 15,\n",
       " 'release_year': 16,\n",
       " 'has_genre_reverse': 17}"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_inv_voc = {v: k for k, v in relations_voc.items()}\n",
    "relations_voc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a60f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entities_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df742878",
   "metadata": {},
   "source": [
    "# creating embeddings from KGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc7cd1",
   "metadata": {},
   "source": [
    "## loading trained kge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f1ca49a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operating on cpu\n",
      "building tucker model for embedding generation\n",
      "TuckER(\n",
      "  (input_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (hidden_dropout1): Dropout(p=0.4, inplace=False)\n",
      "  (hidden_dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (E): Embedding(43234, 200, padding_idx=0)\n",
      "  (R): Embedding(18, 200, padding_idx=0)\n",
      ")\n",
      "operating on cpu\n",
      "building tucker model for embedding generation\n"
     ]
    }
   ],
   "source": [
    "from kg_env import load_kge_model\n",
    "import torch\n",
    "\n",
    "model = load_kge_model(\n",
    "    dataset_name='MetaQA',\n",
    "    model_name='TuckER',\n",
    "    ent_vec_dim=200,\n",
    "    rel_vec_dim=200,\n",
    "    loss_type='CE',\n",
    "    device=('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    path='TuckER_MetaQA',\n",
    "    input_dropout=0.3,\n",
    "    hidden_dropout1=0.4,\n",
    "    hidden_dropout2=0.5,\n",
    "    l3_reg=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0149c52e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 200])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Adrian Moat': 970,\n",
    "#'Adrian Pasdar': 971,\n",
    "# 'Adrian Rawlins': 972,\n",
    "# 'Adrian Shergold': 973\n",
    "\n",
    "model.E(torch.Tensor([970, 971, 972]).long()).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c51b33",
   "metadata": {},
   "source": [
    "## generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ffcdce7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kg_env import generate_entity_embeddings\n",
    "import pickle\n",
    "\n",
    "ent_emb_dict = generate_entity_embeddings(model, entities_voc)\n",
    "rel_emb_dict = generate_entity_embeddings(model, relations_voc)\n",
    "\n",
    "with open('data/MetaQA/entity_emb.pickle', 'wb') as f:\n",
    "    pickle.dump(ent_emb_dict, f)\n",
    "    \n",
    "\n",
    "with open('data/MetaQA/relation_emb.pickle', 'wb') as f:\n",
    "    pickle.dump(rel_emb_dict, f)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd0857",
   "metadata": {},
   "source": [
    "## load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "75862816",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/MetaQA/entity_emb.pickle', 'rb') as f:\n",
    "    ent_emb_dict = pickle.load(f)\n",
    "    \n",
    "\n",
    "with open('data/MetaQA/relation_emb.pickle', 'rb') as f:\n",
    "    rel_emb_dict = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "47ca490d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_emb_dict[list(ent_emb_dict.keys())[0]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4d073",
   "metadata": {},
   "source": [
    "## generating question embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d679af",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## analyze qa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2112536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_qa(path, mode='train_1hop'):\n",
    "    with open(os.path.join(path, f'qa_{mode}.txt'), 'r') as f:\n",
    "        text = f.read().strip().split('\\n')\n",
    "    return text\n",
    "\n",
    "qa_train_raw = load_raw_qa('./data/QA_data/MetaQA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf3fb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_question_entity_target(raw_questions):\n",
    "    all_questions = []\n",
    "    all_entities = []\n",
    "    all_targets = []\n",
    "\n",
    "    for raw_q in raw_questions:\n",
    "        question, targets = raw_q.split('\\t')\n",
    "        entity = re.findall('\\[.*?\\]', question)[0] \\\n",
    "            .replace('[', '') \\\n",
    "            .replace(']', '')\n",
    "\n",
    "        # todo: should I replace entity with some special token?\n",
    "        question = question.replace(']', '').replace('[', '')\n",
    "        targets = targets.strip().split('|')\n",
    "        all_questions.append(question)\n",
    "        all_targets.append(targets)\n",
    "        all_entities.append(entity)\n",
    "\n",
    "    return all_questions, all_entities, all_targets\n",
    "\n",
    "\n",
    "qa_train_raw = load_raw_qa('./data/QA_data/MetaQA/', mode='dev_3hop')\n",
    "questions, _, _ = extract_question_entity_target(qa_train_raw)\n",
    "print(max([len(s) for s in questions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "481e3ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MODELS_CACHE_PATH = '.'\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_sentences(sentences: List[str], tokenizer_path=MODELS_CACHE_PATH, max_len=160):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base', cache_dir=MODELS_CACHE_PATH)\n",
    "    tokenizer_res = tokenizer(\n",
    "        sentences, return_tensors='pt', max_length=max_len, truncation=True, padding='max_length')\n",
    "    tokenizer_res.to(device)\n",
    "    return tokenizer_res\n",
    "\n",
    "def get_batch_embeddings(tokenizer_results: Dict, batch_size=128):\n",
    "    i = 0\n",
    "    embeddings = []\n",
    "    roberta = RobertaModel.from_pretrained('roberta-base', cache_dir=MODELS_CACHE_PATH).to(device)\n",
    "    pbar = tqdm(total=len(tokenizer_results['input_ids'])//batch_size)\n",
    "    while i < len(tokenizer_results['input_ids']):\n",
    "        model_input = {}\n",
    "        for key in tokenizer_results:\n",
    "            model_input[key] = tokenizer_results[key][i:i+batch_size]\n",
    "        outputs = roberta(**model_input)\n",
    "        embeddings.append(outputs.pooler_output.detach().cpu().numpy())\n",
    "        i += batch_size\n",
    "        pbar.update(1)\n",
    "    \n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd21def",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_res = tokenize_sentences(questions)\n",
    "print(tokenizer_res['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58a95464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                             | 0/14274 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                   | 1/14274 [00:00<2:56:23,  1.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0486,  0.0761, -0.0288,  ..., -0.1312, -0.0418, -0.0443],\n",
      "         [ 0.0131, -0.1777, -0.0614,  ..., -0.3306,  0.1801,  0.0568],\n",
      "         [ 0.0847,  0.1649,  0.0865,  ...,  0.2064, -0.0259, -0.0863],\n",
      "         ...,\n",
      "         [ 0.0565,  0.0920,  0.0201,  ..., -0.1220, -0.0156, -0.0208],\n",
      "         [ 0.0565,  0.0920,  0.0201,  ..., -0.1220, -0.0156, -0.0208],\n",
      "         [ 0.0565,  0.0920,  0.0201,  ..., -0.1220, -0.0156, -0.0208]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-1.1188e-02, -2.0919e-01, -2.2745e-01, -1.1578e-01,  1.6160e-01,\n",
      "          1.9390e-01,  2.5668e-01, -7.2665e-02, -5.9200e-02, -1.7820e-01,\n",
      "          2.3287e-01, -1.2546e-03, -8.6979e-02,  8.9313e-02, -1.3310e-01,\n",
      "          5.0997e-01,  2.2478e-01, -4.6840e-01,  7.0964e-03, -3.6931e-02,\n",
      "         -2.4895e-01,  5.7112e-02,  4.6074e-01,  2.9635e-01,  1.3442e-01,\n",
      "          7.6506e-02, -1.2433e-01, -3.5329e-02,  1.8925e-01,  2.2929e-01,\n",
      "          2.6687e-01,  5.3384e-02,  1.1271e-01,  2.6096e-01, -2.4925e-01,\n",
      "          4.0644e-02, -3.0925e-01,  2.8859e-02,  2.4695e-01, -1.9093e-01,\n",
      "         -8.1733e-02,  1.6844e-01,  1.8241e-01, -1.3373e-01, -1.2038e-01,\n",
      "          3.9230e-01,  2.4602e-01,  6.2669e-02, -1.1978e-01, -9.9425e-02,\n",
      "         -3.6967e-01,  3.7862e-01,  2.9659e-01,  2.1889e-01, -3.6361e-02,\n",
      "          1.6310e-02, -1.2171e-01,  2.4879e-01, -6.3768e-02, -9.3117e-02,\n",
      "         -1.2315e-01, -2.2095e-01, -2.0968e-02, -4.6416e-02, -5.4636e-03,\n",
      "         -1.4861e-01,  8.8895e-02, -1.5646e-01, -1.3950e-01,  6.6408e-02,\n",
      "         -9.1845e-02,  1.5884e-01,  1.4340e-01, -2.5681e-01, -2.7499e-01,\n",
      "          6.8022e-02, -5.9804e-01, -1.1069e-01,  2.8616e-01,  4.2135e-01,\n",
      "         -1.2036e-01,  1.9856e-01,  5.3969e-03,  2.1307e-01, -1.5159e-02,\n",
      "         -5.8735e-02, -4.8426e-02, -8.9487e-02,  1.8401e-01,  2.7185e-01,\n",
      "         -2.1071e-01, -3.9132e-01,  6.8983e-02,  2.7503e-02, -8.9308e-02,\n",
      "         -4.4563e-03, -1.2084e-02, -1.2257e-01, -1.7279e-01, -1.6770e-01,\n",
      "          5.8874e-02, -2.6735e-01, -1.1952e-01,  2.5871e-01, -2.2517e-02,\n",
      "         -2.1607e-01, -4.8969e-02,  2.8515e-01,  4.9705e-02, -1.0885e-01,\n",
      "         -1.6721e-01,  4.1988e-01,  3.0605e-01,  3.5891e-02,  1.2066e-02,\n",
      "          1.8398e-01,  1.1072e-01, -2.7404e-01,  4.2434e-01, -3.0238e-01,\n",
      "          1.0596e-02, -8.7341e-02,  1.0814e-01,  1.2790e-01, -1.9897e-01,\n",
      "          2.6877e-01,  1.3323e-01,  2.5240e-01,  1.8176e-01,  9.7297e-02,\n",
      "         -3.1075e-02,  1.1824e-01, -1.1883e-01,  1.4174e-01,  1.9202e-01,\n",
      "          9.8663e-02,  1.9818e-02, -3.1942e-01, -1.8734e-01,  2.4032e-01,\n",
      "          3.3376e-01,  1.3323e-01, -2.1350e-02,  2.0321e-01,  8.6403e-02,\n",
      "          2.2743e-01,  1.3382e-01, -4.0449e-01,  3.2264e-02,  3.3956e-01,\n",
      "          9.3516e-02,  1.6496e-01, -8.1447e-02, -2.7567e-01, -2.4679e-01,\n",
      "         -1.0275e-01,  4.9817e-02, -3.2355e-01, -1.3344e-01,  3.7563e-01,\n",
      "          1.3042e-02,  6.8725e-03, -1.4987e-01, -2.3697e-01, -2.5353e-02,\n",
      "         -1.1643e-01,  2.1004e-02,  1.1027e-01, -7.7165e-02, -4.1245e-01,\n",
      "         -1.0317e-01, -5.3930e-01, -1.3135e-01,  1.9023e-01, -2.8375e-01,\n",
      "          2.3776e-01, -2.7051e-01,  7.1539e-02,  4.1583e-01,  4.4491e-02,\n",
      "         -4.4609e-04, -1.6799e-01, -4.9517e-02,  9.4211e-02,  3.1649e-01,\n",
      "          2.3264e-01, -3.7430e-01,  8.3252e-02,  1.4224e-01,  2.5311e-01,\n",
      "          1.4493e-01, -3.5384e-02, -1.3160e-01,  1.1245e-01, -2.0808e-01,\n",
      "          1.6170e-01, -2.3719e-01,  1.7978e-01, -2.6692e-01, -2.3898e-01,\n",
      "          2.8766e-01, -3.9164e-01, -3.6212e-02,  8.1917e-02,  2.5863e-01,\n",
      "          1.8094e-02, -5.4518e-02, -9.3592e-02,  9.8821e-02,  1.8494e-01,\n",
      "          1.3155e-01, -4.0184e-01,  2.6600e-01, -4.5834e-03, -3.5810e-02,\n",
      "         -1.9091e-02,  1.7912e-01,  2.4393e-01,  1.1064e-01, -3.9554e-01,\n",
      "         -1.5327e-01,  1.0446e-01,  2.6614e-01, -2.5814e-01,  1.6387e-01,\n",
      "         -2.6440e-01, -3.8640e-01, -1.5941e-01,  2.1318e-01,  2.2224e-01,\n",
      "          1.6139e-01, -2.7027e-01,  1.6799e-01, -8.0651e-02, -4.4226e-01,\n",
      "         -3.4625e-01, -8.0286e-02,  2.5599e-01,  1.7042e-01,  1.6646e-01,\n",
      "          2.4002e-01,  5.2622e-02,  8.1711e-02,  1.6431e-01,  1.3258e-01,\n",
      "         -1.7808e-01,  1.5969e-01, -3.7079e-01, -5.6438e-02, -2.6568e-01,\n",
      "         -1.9257e-01, -1.9651e-01,  3.9430e-01, -2.3357e-01,  2.5260e-01,\n",
      "          3.9017e-01, -2.9072e-01, -1.1284e-01,  1.2129e-01,  8.6426e-02,\n",
      "          1.1709e-01, -1.4663e-01,  2.0240e-01,  1.5713e-01, -1.1842e-01,\n",
      "          2.3573e-01,  2.5016e-02,  2.4471e-01,  1.6077e-01,  9.8463e-02,\n",
      "          1.5344e-01,  1.2574e-01, -1.4931e-01,  5.6045e-02,  1.7958e-02,\n",
      "         -2.3391e-02, -2.6058e-01, -1.6683e-01,  2.1879e-01, -3.0872e-02,\n",
      "          3.3287e-02, -1.5824e-01, -1.0101e-01,  5.0377e-03,  4.0324e-01,\n",
      "         -3.6525e-01,  2.4094e-01,  8.2509e-02,  1.5406e-01, -2.6033e-01,\n",
      "         -1.8464e-01,  8.3674e-02,  1.4398e-01, -4.0854e-01,  8.4427e-03,\n",
      "          1.6837e-01,  1.0425e-01,  2.0160e-01,  2.4735e-01, -2.4569e-02,\n",
      "         -1.0804e-01,  4.6905e-01, -1.6608e-01, -1.4172e-01,  2.6076e-01,\n",
      "         -2.7547e-01, -2.9055e-01,  2.4955e-01, -2.8635e-02,  3.0873e-01,\n",
      "          1.2274e-01,  3.0787e-02,  9.9014e-02, -6.1298e-01,  7.7012e-02,\n",
      "         -4.5004e-01, -9.7540e-03, -1.7009e-03, -7.8210e-02, -2.0849e-01,\n",
      "          1.1364e-01,  2.9598e-01, -2.6443e-01, -3.4871e-02,  2.2010e-01,\n",
      "          7.8711e-02, -1.1895e-01,  4.7314e-01, -2.1995e-02,  2.1134e-01,\n",
      "         -7.7447e-02,  2.4071e-01, -2.1173e-01,  2.5045e-01, -2.5404e-01,\n",
      "         -9.8583e-02,  2.6421e-02,  8.5607e-02,  6.6336e-02, -5.0331e-02,\n",
      "         -3.3156e-01,  2.3587e-01, -3.3458e-02, -6.8789e-02, -3.9614e-02,\n",
      "          9.7006e-02, -1.4869e-03,  4.4646e-02,  7.7698e-02,  3.1041e-01,\n",
      "          2.6542e-01, -1.3054e-02, -3.5620e-01, -5.7255e-03, -1.0589e-01,\n",
      "          6.4708e-02, -4.0590e-03, -1.9004e-02,  4.2065e-01, -1.1506e-01,\n",
      "         -1.8892e-02, -1.4197e-01,  2.4754e-01,  2.0611e-01,  1.3794e-01,\n",
      "          1.2080e-01,  5.7478e-02,  1.1916e-01, -6.9815e-02, -2.6834e-02,\n",
      "         -1.6217e-01, -2.1778e-01, -2.9370e-01,  2.2117e-01, -2.2505e-01,\n",
      "         -1.7203e-01,  1.6243e-01,  1.8333e-01, -1.4149e-01,  1.3386e-01,\n",
      "          3.1075e-01,  1.1054e-01, -1.4404e-01,  2.5680e-01, -1.0776e-01,\n",
      "          1.1621e-01,  3.1853e-01, -1.5372e-02,  1.6992e-01,  5.2048e-01,\n",
      "          2.2517e-01, -3.6132e-01, -2.9862e-02, -2.2175e-01,  2.6862e-02,\n",
      "          2.4986e-01, -1.6520e-01,  1.8812e-01,  3.7639e-01,  3.0572e-01,\n",
      "          4.4881e-01,  1.1725e-02, -1.2780e-01,  1.0286e-01,  2.1637e-01,\n",
      "          3.7588e-02, -1.5371e-01, -1.7303e-01,  2.5824e-01,  4.2484e-02,\n",
      "         -1.2665e-01, -1.5781e-02, -1.0052e-01,  4.2760e-02, -1.2713e-01,\n",
      "         -3.7700e-01,  6.0978e-02,  1.9395e-01, -4.6589e-01,  7.4386e-02,\n",
      "         -2.8537e-01,  3.6367e-02, -2.3551e-01,  2.2834e-01, -2.5683e-01,\n",
      "         -1.1240e-01,  3.8967e-01, -5.9668e-02,  5.9608e-02, -1.9760e-01,\n",
      "         -1.3847e-01,  2.3140e-02,  2.7385e-02,  1.1254e-03, -5.5126e-03,\n",
      "          3.3689e-01, -1.2206e-01,  2.0787e-02,  4.3763e-02,  2.1667e-01,\n",
      "         -5.3485e-02,  1.9359e-01,  1.4117e-02, -1.3556e-01, -3.8523e-01,\n",
      "          1.2875e-01, -1.8608e-01, -4.3626e-01, -3.5393e-01,  3.3947e-01,\n",
      "         -1.2275e-01, -2.5499e-01, -2.2255e-01, -2.6307e-01,  6.8029e-02,\n",
      "          1.8523e-01,  4.5094e-01, -4.0172e-01, -5.8062e-02,  4.7992e-01,\n",
      "         -5.6064e-02, -1.8358e-01,  3.0997e-01,  2.1517e-01, -3.1549e-01,\n",
      "          3.3028e-01,  2.6935e-01, -5.1444e-02,  3.8904e-02,  5.1735e-01,\n",
      "          1.1491e-01,  1.9039e-01, -2.1634e-01,  4.5490e-01, -2.1855e-01,\n",
      "          2.8709e-01, -1.8214e-01, -2.1484e-01, -1.8381e-01,  4.6452e-03,\n",
      "          3.0193e-01,  1.8006e-01, -3.9775e-01, -1.0326e-01,  6.1032e-02,\n",
      "          3.2888e-01, -3.6808e-01, -9.5998e-02,  4.2539e-03, -3.3181e-01,\n",
      "          1.0162e-01,  7.6902e-02,  2.3066e-01, -3.6972e-01, -3.0019e-02,\n",
      "          3.9877e-01, -3.1557e-01,  1.2971e-01,  3.0784e-01,  9.0853e-02,\n",
      "          3.5627e-01, -1.6670e-02,  3.2885e-03,  6.2807e-02, -2.3643e-01,\n",
      "         -2.5299e-02,  1.2971e-01,  5.2514e-01,  1.5653e-01, -3.6971e-01,\n",
      "          8.7315e-02,  2.1877e-01, -1.1668e-01,  3.0325e-01, -7.9747e-02,\n",
      "         -9.4750e-02,  2.5346e-01, -5.5457e-02,  1.5617e-01, -8.5734e-02,\n",
      "         -2.1583e-01, -3.3036e-01,  3.4039e-01, -2.3922e-01, -1.2404e-01,\n",
      "         -1.4703e-01, -1.3724e-01, -1.2208e-01,  5.0816e-02, -3.7565e-01,\n",
      "          3.3892e-01,  1.0257e-01, -2.1184e-01, -7.4271e-02, -9.1163e-02,\n",
      "         -1.4743e-01, -2.1390e-01, -2.7186e-01,  4.2361e-01, -1.7262e-01,\n",
      "         -4.5126e-01,  2.3993e-01,  5.7977e-02,  3.3652e-01,  3.1556e-02,\n",
      "          9.9695e-02, -5.1597e-02,  1.1890e-01,  6.7281e-02, -1.1161e-01,\n",
      "          2.6747e-01,  6.2781e-02, -5.5565e-01, -1.2271e-01, -2.3861e-01,\n",
      "          9.7591e-02,  2.0741e-01, -3.3160e-01,  2.8880e-02,  3.6459e-02,\n",
      "          1.4967e-01,  7.0331e-02, -1.1716e-01, -6.2648e-02,  3.9126e-01,\n",
      "          2.1311e-01,  2.5444e-01,  8.4248e-02,  2.5367e-01, -8.8551e-03,\n",
      "         -2.9380e-01,  5.5636e-02,  7.8802e-02, -1.6839e-01,  4.4235e-01,\n",
      "         -9.8178e-02, -3.7649e-01, -7.7330e-02,  4.0899e-01,  1.0421e-01,\n",
      "         -1.8241e-02, -5.9381e-02,  1.9835e-01,  1.5378e-01, -1.2768e-01,\n",
      "          1.7856e-01, -3.4573e-02, -1.4182e-01, -1.2097e-01,  8.7649e-02,\n",
      "         -2.2547e-01,  6.3402e-02, -1.5257e-01, -1.8431e-02, -2.2518e-01,\n",
      "          1.3364e-02, -2.1048e-01,  2.6089e-01, -3.4860e-01,  1.0823e-01,\n",
      "          8.0148e-02,  3.0582e-01, -3.5686e-01, -1.5832e-01, -8.1461e-02,\n",
      "          1.5693e-01,  2.7522e-01,  3.2453e-01,  4.9840e-02,  2.0398e-03,\n",
      "         -1.6572e-01, -2.3365e-01,  8.5096e-02, -2.0885e-01,  1.4073e-01,\n",
      "          8.2835e-02,  2.2332e-01, -3.3486e-01, -1.5829e-01,  2.4842e-01,\n",
      "         -1.0276e-01, -1.1352e-01,  4.1104e-01,  2.4601e-01,  2.3780e-01,\n",
      "          2.9289e-02,  2.4512e-01,  5.5535e-02, -2.1516e-01, -1.3922e-01,\n",
      "         -2.2048e-01,  7.7506e-02, -9.7506e-02, -4.7085e-02, -1.8393e-02,\n",
      "         -1.1245e-01, -1.9330e-01, -1.5900e-01,  1.4603e-01,  1.2054e-01,\n",
      "          4.9536e-03, -4.3481e-02, -2.4076e-02, -2.6384e-01,  3.1992e-01,\n",
      "         -3.7652e-03,  9.1943e-02, -6.2227e-02,  3.6433e-02, -1.5600e-01,\n",
      "          2.3127e-01,  2.1741e-01,  6.3174e-02, -1.7549e-01, -4.9375e-02,\n",
      "         -2.9875e-01, -3.7411e-01,  5.0310e-02,  1.5423e-01,  1.1475e-01,\n",
      "         -7.9982e-02, -2.9252e-01,  9.7424e-03, -1.1580e-01,  1.7734e-01,\n",
      "          1.5810e-02, -1.4982e-01, -7.5721e-02, -5.8512e-02, -4.0495e-02,\n",
      "          7.5904e-02, -2.0747e-01, -1.8747e-01, -1.0897e-01, -9.0045e-02,\n",
      "         -7.4401e-02,  3.7118e-01, -3.2076e-02,  2.6849e-01, -1.6522e-01,\n",
      "          1.0161e-02, -1.5164e-01,  1.1188e-01, -4.4754e-02,  6.1240e-02,\n",
      "          2.6880e-01, -4.5481e-01, -1.6239e-01, -6.8406e-04, -2.2495e-01,\n",
      "         -1.1270e-01, -6.1609e-02, -6.0749e-02,  2.1339e-01, -3.2958e-01,\n",
      "          2.0177e-01, -6.8470e-02,  1.6611e-01, -5.0780e-02, -2.5206e-01,\n",
      "         -1.5280e-01, -9.7897e-04,  2.4954e-01, -3.2134e-01, -2.4031e-01,\n",
      "         -2.6522e-01, -1.1165e-01, -6.1674e-02, -2.6536e-01,  4.1979e-01,\n",
      "         -1.3386e-01, -7.3119e-02,  4.1915e-02,  4.4271e-01,  2.0353e-01,\n",
      "          1.9584e-01,  1.8875e-01,  9.3959e-03,  2.6744e-02,  1.2165e-01,\n",
      "         -4.8035e-01,  2.1368e-01, -2.2242e-01, -1.2983e-01,  4.5349e-02,\n",
      "          7.2326e-02, -2.3445e-02, -2.9127e-04, -1.6284e-01, -9.1300e-02,\n",
      "          2.0786e-01, -3.8508e-01, -1.6360e-02,  2.5471e-01,  1.3238e-01,\n",
      "         -2.5224e-01,  5.5705e-02,  1.3180e-01,  4.0407e-01,  1.1795e-01,\n",
      "         -2.2077e-01,  1.3753e-01, -3.3343e-01, -2.5092e-02, -2.0800e-01,\n",
      "         -2.9913e-01,  1.4438e-01, -7.6070e-02,  8.2675e-02, -7.8103e-02,\n",
      "         -2.8954e-01,  2.2712e-01, -5.5337e-02, -6.4956e-02,  4.1866e-01,\n",
      "          4.0210e-02, -1.0189e-01,  1.3930e-01,  2.2170e-02,  4.4782e-02,\n",
      "         -1.0715e-01,  2.6985e-01,  1.9685e-01, -2.8743e-01,  1.4581e-01,\n",
      "         -1.0827e-01, -5.8784e-02, -1.0703e-01]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                   | 2/14274 [00:01<3:06:13,  1.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0483,  0.0658, -0.0396,  ..., -0.0925, -0.0512, -0.0151],\n",
      "         [ 0.0408, -0.3234, -0.2024,  ..., -0.2671,  0.1068, -0.0395],\n",
      "         [ 0.0705, -0.1757, -0.1514,  ..., -0.5613, -0.1411, -0.0526],\n",
      "         ...,\n",
      "         [ 0.0405, -0.0021,  0.0159,  ..., -0.0421, -0.0428,  0.0964],\n",
      "         [ 0.0405, -0.0021,  0.0159,  ..., -0.0421, -0.0428,  0.0964],\n",
      "         [ 0.0405, -0.0021,  0.0159,  ..., -0.0421, -0.0428,  0.0964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-3.0601e-03, -2.1779e-01, -2.0223e-01, -9.0303e-02,  1.1932e-01,\n",
      "          1.8957e-01,  2.5946e-01, -7.7788e-02, -7.1099e-02, -1.6559e-01,\n",
      "          2.2084e-01, -1.8129e-02, -1.0156e-01,  8.3201e-02, -1.3346e-01,\n",
      "          4.9150e-01,  2.0551e-01, -4.5526e-01,  2.3696e-02, -3.3467e-02,\n",
      "         -2.4801e-01,  6.0791e-02,  4.5524e-01,  3.0210e-01,  1.1699e-01,\n",
      "          7.6753e-02, -1.2701e-01, -1.6016e-02,  1.9760e-01,  2.1011e-01,\n",
      "          2.7757e-01,  5.5025e-02,  9.7133e-02,  2.4107e-01, -2.4190e-01,\n",
      "          5.5581e-02, -3.0928e-01,  1.4506e-02,  2.5347e-01, -1.9439e-01,\n",
      "         -8.5167e-02,  1.6398e-01,  1.8422e-01, -1.1708e-01, -1.1026e-01,\n",
      "          3.9440e-01,  2.3544e-01,  4.3261e-02, -1.2205e-01, -9.3475e-02,\n",
      "         -3.6078e-01,  3.4580e-01,  2.8926e-01,  2.0060e-01, -2.1491e-02,\n",
      "          4.3079e-02, -1.2802e-01,  2.5031e-01, -7.5249e-02, -9.7561e-02,\n",
      "         -1.1553e-01, -2.1751e-01, -1.5028e-03, -4.7819e-02,  1.8180e-02,\n",
      "         -1.3559e-01,  9.1748e-02, -1.3641e-01, -1.4478e-01,  6.0454e-02,\n",
      "         -9.3886e-02,  1.3682e-01,  1.4357e-01, -2.7226e-01, -2.7390e-01,\n",
      "          6.9627e-02, -5.7498e-01, -1.0130e-01,  2.8926e-01,  4.2119e-01,\n",
      "         -1.1912e-01,  1.8745e-01,  3.0970e-02,  2.0457e-01, -3.1848e-02,\n",
      "         -6.6738e-02, -4.1192e-02, -1.0539e-01,  1.9270e-01,  2.6900e-01,\n",
      "         -1.8039e-01, -3.5528e-01,  6.6947e-02,  2.1026e-02, -8.3927e-02,\n",
      "          1.4979e-02, -4.8093e-03, -1.0491e-01, -1.7686e-01, -1.6273e-01,\n",
      "          5.1806e-02, -2.6790e-01, -1.2906e-01,  2.6610e-01, -3.4590e-02,\n",
      "         -1.9781e-01, -4.2674e-02,  2.9447e-01,  7.1568e-02, -1.4029e-01,\n",
      "         -1.7684e-01,  4.1689e-01,  3.0050e-01,  1.4069e-02,  7.4098e-03,\n",
      "          1.8003e-01,  1.2221e-01, -2.8956e-01,  4.2042e-01, -3.1228e-01,\n",
      "         -9.3785e-03, -1.0171e-01,  1.1083e-01,  1.3707e-01, -2.0814e-01,\n",
      "          2.6469e-01,  1.5270e-01,  2.6854e-01,  1.8595e-01,  9.7735e-02,\n",
      "         -3.1212e-02,  1.2858e-01, -1.0604e-01,  1.3670e-01,  2.2017e-01,\n",
      "          1.1082e-01, -7.0050e-04, -3.1272e-01, -2.1101e-01,  2.5782e-01,\n",
      "          3.4068e-01,  1.4170e-01, -5.2969e-02,  1.9704e-01,  8.7842e-02,\n",
      "          2.3961e-01,  1.2800e-01, -4.0030e-01,  2.6277e-02,  3.4316e-01,\n",
      "          1.0063e-01,  1.7360e-01, -8.2813e-02, -2.8094e-01, -2.4633e-01,\n",
      "         -9.7929e-02,  4.2665e-02, -3.2924e-01, -1.2518e-01,  3.5112e-01,\n",
      "          9.9167e-03,  1.6249e-02, -1.3752e-01, -2.3502e-01, -3.0962e-02,\n",
      "         -1.1200e-01,  1.8630e-02,  1.0058e-01, -8.2081e-02, -4.0754e-01,\n",
      "         -9.2631e-02, -5.4853e-01, -1.3161e-01,  1.8866e-01, -3.0952e-01,\n",
      "          2.4771e-01, -2.8458e-01,  9.3974e-02,  4.1577e-01,  2.9710e-02,\n",
      "         -1.3436e-02, -1.5983e-01, -1.5088e-02,  1.0949e-01,  3.0751e-01,\n",
      "          2.4568e-01, -3.8239e-01,  6.5394e-02,  1.4418e-01,  2.4423e-01,\n",
      "          1.5185e-01, -4.1407e-02, -1.3552e-01,  1.1889e-01, -2.0227e-01,\n",
      "          1.5241e-01, -2.3293e-01,  2.0463e-01, -2.3673e-01, -2.1860e-01,\n",
      "          2.8004e-01, -3.9535e-01, -4.0185e-02,  8.0984e-02,  2.4688e-01,\n",
      "          2.4458e-02, -4.1475e-02, -9.5473e-02,  1.1226e-01,  1.8956e-01,\n",
      "          1.4990e-01, -3.9103e-01,  2.5420e-01, -1.9029e-02, -2.5573e-02,\n",
      "         -3.2177e-02,  1.7600e-01,  2.4190e-01,  1.0645e-01, -3.9654e-01,\n",
      "         -1.4353e-01,  1.1139e-01,  2.7145e-01, -2.3824e-01,  1.7330e-01,\n",
      "         -2.6888e-01, -3.8162e-01, -1.5051e-01,  1.9889e-01,  2.1195e-01,\n",
      "          1.8384e-01, -2.6794e-01,  1.6789e-01, -9.6864e-02, -4.1262e-01,\n",
      "         -3.5328e-01, -9.9705e-02,  2.4085e-01,  1.6811e-01,  1.6752e-01,\n",
      "          2.3432e-01,  4.1197e-02,  1.0179e-01,  1.6730e-01,  1.5288e-01,\n",
      "         -1.8803e-01,  1.6893e-01, -3.6545e-01, -5.6911e-02, -2.6087e-01,\n",
      "         -1.9217e-01, -2.0984e-01,  4.0103e-01, -2.3060e-01,  2.3940e-01,\n",
      "          3.8331e-01, -2.8713e-01, -1.2056e-01,  1.3847e-01,  8.2055e-02,\n",
      "          1.1556e-01, -1.2439e-01,  1.9416e-01,  1.7564e-01, -1.0394e-01,\n",
      "          2.2752e-01, -6.5950e-03,  2.6349e-01,  1.6819e-01,  1.0671e-01,\n",
      "          1.4759e-01,  1.1191e-01, -1.7121e-01,  7.4554e-02,  1.4229e-03,\n",
      "         -1.3066e-02, -2.3312e-01, -1.5764e-01,  2.3039e-01, -5.4207e-02,\n",
      "          3.9329e-02, -1.7579e-01, -1.0478e-01,  2.3580e-02,  3.9759e-01,\n",
      "         -3.5167e-01,  2.3927e-01,  6.5736e-02,  1.6434e-01, -2.5006e-01,\n",
      "         -1.9279e-01,  8.2090e-02,  1.7623e-01, -3.9441e-01,  2.8462e-03,\n",
      "          1.6315e-01,  1.0203e-01,  2.0417e-01,  2.6027e-01, -2.8769e-02,\n",
      "         -1.1299e-01,  4.8154e-01, -1.5742e-01, -1.4858e-01,  2.5606e-01,\n",
      "         -2.7235e-01, -2.7897e-01,  2.5478e-01, -2.4917e-02,  3.0605e-01,\n",
      "          1.2037e-01,  4.3891e-02,  7.8140e-02, -6.0726e-01,  8.1094e-02,\n",
      "         -4.4711e-01, -8.4721e-03,  1.1308e-02, -7.4386e-02, -2.0657e-01,\n",
      "          1.2766e-01,  2.8606e-01, -2.5721e-01, -4.3137e-02,  1.9841e-01,\n",
      "          8.0424e-02, -1.2537e-01,  4.6907e-01, -1.2709e-02,  2.1587e-01,\n",
      "         -7.0726e-02,  2.5098e-01, -2.2176e-01,  2.6471e-01, -2.6866e-01,\n",
      "         -1.0608e-01,  1.0730e-02,  7.6712e-02,  5.1296e-02, -8.3217e-02,\n",
      "         -3.2420e-01,  2.3807e-01, -2.6904e-02, -4.4335e-02, -4.0234e-02,\n",
      "          9.3619e-02, -5.1186e-03,  4.5575e-02,  6.4946e-02,  3.2048e-01,\n",
      "          2.4999e-01, -1.7158e-02, -3.4510e-01, -3.7162e-02, -9.2623e-02,\n",
      "          5.4931e-02,  1.7124e-02, -2.6450e-02,  4.2139e-01, -1.0119e-01,\n",
      "         -8.0821e-03, -1.4290e-01,  2.4807e-01,  2.1160e-01,  1.2710e-01,\n",
      "          1.1954e-01,  6.1918e-02,  1.3783e-01, -6.5457e-02, -5.5752e-03,\n",
      "         -1.5287e-01, -2.3073e-01, -3.0667e-01,  2.2690e-01, -2.3967e-01,\n",
      "         -1.6226e-01,  1.6285e-01,  2.1951e-01, -1.4095e-01,  1.2903e-01,\n",
      "          3.0433e-01,  1.0181e-01, -1.3791e-01,  2.5513e-01, -1.0979e-01,\n",
      "          1.2978e-01,  3.1136e-01, -1.5075e-02,  1.8240e-01,  4.9895e-01,\n",
      "          2.1894e-01, -3.6173e-01, -2.0306e-02, -2.2840e-01,  4.9970e-03,\n",
      "          2.4581e-01, -1.5546e-01,  1.8161e-01,  3.9772e-01,  3.1507e-01,\n",
      "          4.5299e-01,  1.2639e-02, -1.2024e-01,  9.3994e-02,  2.0586e-01,\n",
      "          5.0800e-02, -1.5255e-01, -1.5874e-01,  2.5461e-01,  3.3626e-02,\n",
      "         -1.4861e-01, -1.1760e-02, -9.6517e-02,  3.1845e-02, -1.1813e-01,\n",
      "         -3.6619e-01,  4.4250e-02,  1.9922e-01, -4.6507e-01,  8.0135e-02,\n",
      "         -2.8399e-01,  3.9860e-02, -2.3901e-01,  2.1757e-01, -2.1145e-01,\n",
      "         -1.0534e-01,  3.7825e-01, -6.8760e-02,  6.2266e-02, -1.8236e-01,\n",
      "         -1.2979e-01,  1.8273e-02,  2.4656e-02, -8.7346e-03, -2.9849e-02,\n",
      "          3.4852e-01, -1.1857e-01,  2.1669e-02,  2.4936e-02,  2.0730e-01,\n",
      "         -4.8361e-02,  1.8664e-01,  1.7074e-02, -1.2091e-01, -3.8130e-01,\n",
      "          1.2289e-01, -1.9271e-01, -4.2068e-01, -3.6108e-01,  3.4398e-01,\n",
      "         -1.3151e-01, -2.3929e-01, -2.1586e-01, -2.5452e-01,  7.3397e-02,\n",
      "          1.8503e-01,  4.5226e-01, -4.0655e-01, -6.7058e-02,  4.7751e-01,\n",
      "         -5.0228e-02, -1.7430e-01,  2.9249e-01,  1.9614e-01, -3.1385e-01,\n",
      "          3.3794e-01,  2.7531e-01, -4.5551e-02,  3.1835e-02,  5.2041e-01,\n",
      "          1.2562e-01,  1.8065e-01, -2.1673e-01,  4.5743e-01, -2.2429e-01,\n",
      "          2.9028e-01, -1.5583e-01, -2.0935e-01, -2.1202e-01,  1.1541e-02,\n",
      "          3.2800e-01,  1.8344e-01, -4.0559e-01, -1.1322e-01,  4.9813e-02,\n",
      "          3.3198e-01, -3.8208e-01, -8.4951e-02,  2.2124e-02, -3.2916e-01,\n",
      "          1.0805e-01,  9.7858e-02,  2.4040e-01, -3.6722e-01, -1.3647e-02,\n",
      "          3.8937e-01, -3.0528e-01,  1.2540e-01,  3.0389e-01,  8.3512e-02,\n",
      "          3.4700e-01, -3.3692e-02,  3.9840e-03,  3.6900e-02, -2.1936e-01,\n",
      "         -4.1298e-02,  1.2701e-01,  5.4103e-01,  1.4645e-01, -3.7344e-01,\n",
      "          8.1148e-02,  2.5586e-01, -1.4711e-01,  2.8330e-01, -9.0373e-02,\n",
      "         -6.7602e-02,  2.5595e-01, -5.8437e-02,  1.5861e-01, -1.0880e-01,\n",
      "         -2.4224e-01, -2.9305e-01,  3.5354e-01, -2.2613e-01, -1.0867e-01,\n",
      "         -1.4397e-01, -1.0677e-01, -1.3374e-01,  5.6418e-02, -3.7041e-01,\n",
      "          3.3515e-01,  1.1836e-01, -2.1869e-01, -1.0226e-01, -9.0284e-02,\n",
      "         -1.4779e-01, -2.2256e-01, -2.7501e-01,  4.3499e-01, -1.6491e-01,\n",
      "         -4.4743e-01,  2.5660e-01,  4.2545e-02,  3.4421e-01,  2.7343e-02,\n",
      "          1.0848e-01, -7.1130e-02,  1.2831e-01,  8.1952e-02, -1.2328e-01,\n",
      "          2.6946e-01,  3.7461e-02, -5.5642e-01, -1.4360e-01, -2.3667e-01,\n",
      "          8.0499e-02,  1.7508e-01, -3.3601e-01,  2.5789e-02,  2.8759e-02,\n",
      "          1.2633e-01,  3.8216e-02, -1.2685e-01, -7.1871e-02,  3.8713e-01,\n",
      "          2.2802e-01,  2.5932e-01,  1.0437e-01,  2.4057e-01, -1.1051e-03,\n",
      "         -3.0478e-01,  5.0219e-02,  8.5841e-02, -2.0906e-01,  4.3533e-01,\n",
      "         -9.9659e-02, -3.8525e-01, -9.5374e-02,  4.0527e-01,  1.1484e-01,\n",
      "         -3.9019e-02, -5.4144e-02,  1.9547e-01,  1.6235e-01, -1.3801e-01,\n",
      "          1.7618e-01, -3.5161e-02, -1.2998e-01, -1.2797e-01,  8.2593e-02,\n",
      "         -2.1275e-01,  5.2536e-02, -1.6832e-01, -1.4315e-02, -2.0441e-01,\n",
      "          9.6758e-04, -1.9324e-01,  2.5768e-01, -3.3573e-01,  1.0550e-01,\n",
      "          9.0135e-02,  3.1484e-01, -3.4254e-01, -1.5708e-01, -7.0237e-02,\n",
      "          1.7199e-01,  2.7194e-01,  3.4243e-01,  3.8340e-02, -1.0878e-02,\n",
      "         -1.5716e-01, -2.3823e-01,  9.6925e-02, -2.0422e-01,  1.4161e-01,\n",
      "          6.5201e-02,  2.1608e-01, -3.2298e-01, -1.8314e-01,  2.3119e-01,\n",
      "         -8.8526e-02, -1.4665e-01,  4.0070e-01,  2.3950e-01,  2.0998e-01,\n",
      "          4.0708e-02,  2.3718e-01,  4.2710e-02, -1.9939e-01, -1.3970e-01,\n",
      "         -2.4073e-01,  6.5729e-02, -9.2609e-02, -5.6419e-02, -3.3000e-02,\n",
      "         -1.2400e-01, -1.9894e-01, -1.6315e-01,  1.4078e-01,  1.2637e-01,\n",
      "          2.5591e-02, -4.6280e-02, -3.1523e-02, -2.7837e-01,  3.0409e-01,\n",
      "          6.6657e-03,  7.7698e-02, -7.3471e-02,  4.5025e-02, -1.4065e-01,\n",
      "          2.4081e-01,  2.0508e-01,  7.2396e-02, -1.7779e-01, -6.5666e-02,\n",
      "         -2.9841e-01, -3.4563e-01,  4.9252e-02,  1.3370e-01,  1.1780e-01,\n",
      "         -7.3731e-02, -3.0306e-01, -9.5646e-03, -1.2408e-01,  1.7301e-01,\n",
      "          2.2539e-02, -1.3888e-01, -8.5002e-02, -4.8422e-02, -5.4306e-02,\n",
      "          8.5395e-02, -2.1678e-01, -1.9711e-01, -1.1068e-01, -7.4211e-02,\n",
      "         -8.2268e-02,  3.4085e-01, -4.7761e-02,  2.8144e-01, -1.5788e-01,\n",
      "         -2.7600e-03, -1.6285e-01,  1.1255e-01, -5.3734e-02,  5.3710e-02,\n",
      "          2.7850e-01, -4.5095e-01, -1.6834e-01, -5.5853e-03, -2.1426e-01,\n",
      "         -1.3786e-01, -6.6751e-02, -3.4271e-02,  2.2319e-01, -3.3784e-01,\n",
      "          2.0637e-01, -9.1620e-02,  1.6974e-01, -5.1717e-02, -2.5378e-01,\n",
      "         -1.6124e-01,  2.3597e-03,  2.4382e-01, -3.3018e-01, -2.4456e-01,\n",
      "         -2.6403e-01, -1.0818e-01, -7.3401e-02, -2.4871e-01,  4.0382e-01,\n",
      "         -1.3418e-01, -8.0234e-02,  3.4985e-02,  4.5304e-01,  2.0523e-01,\n",
      "          1.7204e-01,  2.1417e-01,  2.1020e-05,  3.2851e-02,  1.3112e-01,\n",
      "         -4.6974e-01,  2.1896e-01, -2.1904e-01, -1.3075e-01,  3.1684e-02,\n",
      "          7.6440e-02, -6.7919e-03,  6.6992e-03, -1.6380e-01, -9.6052e-02,\n",
      "          2.1348e-01, -3.6628e-01, -3.1635e-02,  2.5002e-01,  1.5173e-01,\n",
      "         -2.5626e-01,  4.5904e-02,  1.2515e-01,  3.8751e-01,  9.3422e-02,\n",
      "         -2.1809e-01,  1.3365e-01, -3.4020e-01, -4.6801e-02, -1.9954e-01,\n",
      "         -2.8700e-01,  1.5446e-01, -5.9907e-02,  8.3899e-02, -8.7197e-02,\n",
      "         -2.9615e-01,  2.2360e-01, -4.5268e-02, -6.8368e-02,  4.2204e-01,\n",
      "          2.9700e-02, -1.2791e-01,  1.5006e-01,  3.1668e-02,  2.6554e-02,\n",
      "         -9.0650e-02,  2.6014e-01,  2.0831e-01, -2.8275e-01,  1.6370e-01,\n",
      "         -1.2046e-01, -4.5698e-02, -9.0982e-02]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                   | 3/14274 [00:02<3:01:31,  1.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0443,  0.0958, -0.0258,  ..., -0.1095, -0.0524, -0.0792],\n",
      "         [ 0.0289, -0.2903, -0.0484,  ..., -0.3300,  0.1950, -0.2918],\n",
      "         [ 0.3139,  0.2377,  0.0223,  ..., -0.1324,  0.3695, -0.1022],\n",
      "         ...,\n",
      "         [-0.0213, -0.0294,  0.0015,  ...,  0.0400, -0.0248, -0.0330],\n",
      "         [-0.0213, -0.0294,  0.0015,  ...,  0.0400, -0.0248, -0.0330],\n",
      "         [-0.0213, -0.0294,  0.0015,  ...,  0.0400, -0.0248, -0.0330]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-1.1580e-02, -2.2915e-01, -2.1842e-01, -1.1189e-01,  1.5850e-01,\n",
      "          2.0361e-01,  2.5357e-01, -1.0500e-01, -8.0442e-02, -1.5308e-01,\n",
      "          2.3498e-01, -4.6535e-02, -9.5518e-02,  9.9269e-02, -1.4516e-01,\n",
      "          4.9914e-01,  2.1731e-01, -4.7995e-01,  1.4769e-02, -3.3811e-02,\n",
      "         -2.4594e-01,  4.8498e-02,  4.6983e-01,  3.0698e-01,  1.1170e-01,\n",
      "          7.3765e-02, -1.1803e-01, -2.7452e-02,  2.2611e-01,  2.2226e-01,\n",
      "          2.7711e-01,  5.7507e-02,  1.0604e-01,  2.6714e-01, -2.6487e-01,\n",
      "          3.4784e-02, -3.1754e-01,  3.9458e-02,  2.5693e-01, -1.9770e-01,\n",
      "         -9.6886e-02,  1.7862e-01,  1.9478e-01, -1.3495e-01, -1.0414e-01,\n",
      "          4.1000e-01,  2.4475e-01,  5.5740e-02, -1.4223e-01, -1.0064e-01,\n",
      "         -3.5670e-01,  3.5680e-01,  2.9191e-01,  1.9799e-01,  4.7002e-03,\n",
      "          5.7396e-02, -1.2421e-01,  2.6362e-01, -5.9490e-02, -9.8766e-02,\n",
      "         -1.0084e-01, -2.3915e-01, -3.3733e-02, -3.8969e-02,  8.9045e-03,\n",
      "         -1.3731e-01,  6.7660e-02, -1.3950e-01, -1.4377e-01,  4.9513e-02,\n",
      "         -9.9021e-02,  1.7406e-01,  1.7131e-01, -2.8817e-01, -2.9060e-01,\n",
      "          9.0836e-02, -5.9915e-01, -1.0135e-01,  2.8406e-01,  4.2875e-01,\n",
      "         -1.3101e-01,  1.8654e-01,  2.0875e-02,  2.2571e-01, -1.6542e-02,\n",
      "         -3.8573e-02, -3.3382e-02, -9.7107e-02,  1.9134e-01,  2.7259e-01,\n",
      "         -2.0975e-01, -3.6886e-01,  5.3487e-02,  2.5983e-02, -7.9409e-02,\n",
      "         -1.1268e-02, -1.8673e-02, -8.1810e-02, -1.7634e-01, -1.6153e-01,\n",
      "          6.6292e-02, -2.8301e-01, -1.3252e-01,  2.8422e-01, -4.7701e-02,\n",
      "         -2.0038e-01, -3.3635e-02,  2.8334e-01,  3.4725e-02, -1.2130e-01,\n",
      "         -1.7928e-01,  4.4339e-01,  3.1209e-01,  1.6145e-05,  3.8169e-03,\n",
      "          1.8783e-01,  1.1552e-01, -2.7092e-01,  4.2921e-01, -3.1258e-01,\n",
      "         -1.1122e-02, -9.4353e-02,  1.1086e-01,  1.3737e-01, -2.0367e-01,\n",
      "          2.7008e-01,  1.3238e-01,  2.7322e-01,  1.9531e-01,  1.0198e-01,\n",
      "         -3.4445e-02,  1.2177e-01, -1.2655e-01,  1.6047e-01,  2.2290e-01,\n",
      "          1.0654e-01, -1.8512e-02, -3.0808e-01, -2.0197e-01,  2.8361e-01,\n",
      "          3.4304e-01,  1.4663e-01, -3.0496e-02,  2.0734e-01,  8.3242e-02,\n",
      "          2.3940e-01,  1.3615e-01, -4.2697e-01,  2.4395e-02,  3.3782e-01,\n",
      "          1.1300e-01,  1.4547e-01, -9.9838e-02, -2.7942e-01, -2.5826e-01,\n",
      "         -1.1056e-01,  6.6799e-02, -3.4233e-01, -1.4014e-01,  3.6839e-01,\n",
      "          2.3171e-02,  4.0478e-03, -1.4766e-01, -2.5513e-01, -1.7769e-02,\n",
      "         -1.1876e-01,  2.8530e-02,  9.0458e-02, -9.3770e-02, -4.2703e-01,\n",
      "         -8.8396e-02, -5.4357e-01, -1.1127e-01,  1.7532e-01, -3.2689e-01,\n",
      "          2.8404e-01, -2.6585e-01,  9.3768e-02,  4.1774e-01,  4.1022e-02,\n",
      "         -8.9619e-03, -1.8084e-01, -3.6343e-02,  1.0846e-01,  3.2612e-01,\n",
      "          2.4017e-01, -3.9677e-01,  8.5880e-02,  1.5052e-01,  2.5966e-01,\n",
      "          1.5495e-01, -4.7162e-02, -1.2962e-01,  1.0417e-01, -2.0669e-01,\n",
      "          1.5648e-01, -2.4527e-01,  1.9903e-01, -2.7314e-01, -2.3207e-01,\n",
      "          2.8489e-01, -3.9827e-01, -3.1150e-02,  7.9830e-02,  2.6385e-01,\n",
      "          5.3051e-03, -4.0626e-02, -9.0997e-02,  1.3131e-01,  1.6144e-01,\n",
      "          1.3494e-01, -4.1182e-01,  2.6198e-01, -2.1616e-02, -5.5454e-03,\n",
      "         -1.9900e-02,  1.6960e-01,  2.5869e-01,  9.4003e-02, -3.9742e-01,\n",
      "         -1.5875e-01,  9.3153e-02,  2.7356e-01, -2.5322e-01,  1.7021e-01,\n",
      "         -2.8606e-01, -4.1991e-01, -1.4833e-01,  2.1506e-01,  2.4002e-01,\n",
      "          1.6670e-01, -2.7401e-01,  1.8173e-01, -1.0271e-01, -4.2225e-01,\n",
      "         -3.6710e-01, -9.1834e-02,  2.3687e-01,  1.6801e-01,  1.8168e-01,\n",
      "          2.3557e-01,  4.6719e-02,  1.0668e-01,  1.5395e-01,  1.4336e-01,\n",
      "         -1.6950e-01,  1.7775e-01, -3.7417e-01, -5.7233e-02, -2.9241e-01,\n",
      "         -2.0748e-01, -2.0157e-01,  4.0863e-01, -2.3132e-01,  2.5908e-01,\n",
      "          4.0208e-01, -3.0463e-01, -1.1887e-01,  1.3324e-01,  7.3724e-02,\n",
      "          1.0068e-01, -1.2682e-01,  1.8329e-01,  1.7448e-01, -1.4579e-01,\n",
      "          2.5268e-01,  1.2201e-02,  2.8542e-01,  1.6855e-01,  9.4160e-02,\n",
      "          1.4707e-01,  1.3775e-01, -1.5905e-01,  6.1558e-02,  3.0416e-02,\n",
      "         -3.0406e-02, -2.5504e-01, -1.7010e-01,  2.1941e-01, -2.2255e-02,\n",
      "          4.7991e-02, -1.6793e-01, -1.0591e-01,  8.7541e-03,  3.9675e-01,\n",
      "         -3.6278e-01,  2.4595e-01,  6.7610e-02,  1.2790e-01, -2.5856e-01,\n",
      "         -2.0531e-01,  9.9981e-02,  1.5368e-01, -4.1116e-01,  3.5037e-03,\n",
      "          1.8177e-01,  9.0201e-02,  2.2977e-01,  2.4482e-01, -1.7826e-02,\n",
      "         -1.1196e-01,  4.9575e-01, -1.5899e-01, -1.2415e-01,  2.7949e-01,\n",
      "         -2.9249e-01, -2.8220e-01,  2.7217e-01, -3.4125e-02,  3.0862e-01,\n",
      "          1.3084e-01,  4.4898e-02,  8.8758e-02, -6.0447e-01,  9.3964e-02,\n",
      "         -4.6341e-01, -2.9832e-02,  3.8618e-02, -8.2442e-02, -2.0319e-01,\n",
      "          1.3584e-01,  2.9886e-01, -2.5487e-01, -2.5767e-02,  2.0504e-01,\n",
      "          8.7964e-02, -1.2103e-01,  4.7450e-01, -3.5141e-02,  2.1885e-01,\n",
      "         -7.5021e-02,  2.4840e-01, -1.9416e-01,  2.7989e-01, -2.6414e-01,\n",
      "         -1.1346e-01,  2.8356e-02,  9.6881e-02,  5.8332e-02, -7.1739e-02,\n",
      "         -3.3958e-01,  2.3276e-01, -4.7072e-02, -4.4056e-02, -4.1273e-02,\n",
      "          7.8250e-02,  1.1510e-03,  6.3389e-02,  7.8265e-02,  3.1258e-01,\n",
      "          2.3345e-01, -6.8131e-03, -3.6549e-01, -3.1273e-02, -1.0368e-01,\n",
      "          5.1161e-02,  3.1824e-02, -1.4282e-02,  4.5333e-01, -1.2327e-01,\n",
      "         -4.0309e-03, -1.4677e-01,  2.6467e-01,  2.0033e-01,  1.4978e-01,\n",
      "          1.1477e-01,  5.7699e-02,  1.3606e-01, -6.4505e-02, -7.3901e-03,\n",
      "         -1.5500e-01, -2.2237e-01, -2.9899e-01,  2.3093e-01, -2.4204e-01,\n",
      "         -1.8156e-01,  1.4832e-01,  2.1582e-01, -1.4060e-01,  1.2748e-01,\n",
      "          3.0568e-01,  1.0218e-01, -1.3230e-01,  2.7016e-01, -1.3977e-01,\n",
      "          1.1556e-01,  3.0991e-01, -1.8952e-02,  1.8464e-01,  5.0476e-01,\n",
      "          2.3332e-01, -3.6071e-01, -3.0431e-02, -2.5311e-01,  1.7416e-02,\n",
      "          2.5296e-01, -1.7282e-01,  2.0214e-01,  3.7780e-01,  3.3448e-01,\n",
      "          4.6102e-01,  1.9057e-02, -1.3013e-01,  1.0611e-01,  2.2801e-01,\n",
      "          3.6510e-02, -1.6481e-01, -1.7618e-01,  2.6747e-01,  3.8432e-02,\n",
      "         -1.3507e-01, -2.0666e-02, -9.8377e-02,  5.2724e-02, -1.2774e-01,\n",
      "         -3.8202e-01,  3.4049e-02,  2.0159e-01, -4.9286e-01,  5.9598e-02,\n",
      "         -2.6825e-01,  1.3807e-02, -2.2473e-01,  2.0828e-01, -2.2684e-01,\n",
      "         -1.0456e-01,  4.0435e-01, -8.1113e-02,  6.0021e-02, -1.8384e-01,\n",
      "         -1.3594e-01,  2.0455e-02,  1.7256e-02, -2.3797e-02, -3.1402e-02,\n",
      "          3.4874e-01, -1.1418e-01,  2.3774e-02,  2.1182e-02,  2.1567e-01,\n",
      "         -6.4889e-02,  1.9027e-01, -6.1408e-03, -1.3270e-01, -3.8011e-01,\n",
      "          1.3047e-01, -1.9487e-01, -4.3996e-01, -3.5665e-01,  3.5255e-01,\n",
      "         -1.3625e-01, -2.6911e-01, -2.2606e-01, -2.5596e-01,  7.0299e-02,\n",
      "          1.8637e-01,  4.7377e-01, -4.1745e-01, -6.5771e-02,  5.0016e-01,\n",
      "         -6.9477e-02, -1.6745e-01,  3.0487e-01,  2.1109e-01, -3.2696e-01,\n",
      "          3.2110e-01,  2.6859e-01, -6.4957e-02,  2.1962e-02,  5.2271e-01,\n",
      "          1.3336e-01,  1.8802e-01, -2.1584e-01,  4.6614e-01, -2.3099e-01,\n",
      "          2.8739e-01, -1.5830e-01, -2.3563e-01, -1.8145e-01,  3.2653e-02,\n",
      "          3.0839e-01,  1.9513e-01, -3.9318e-01, -1.0445e-01,  6.1733e-02,\n",
      "          3.4895e-01, -3.8698e-01, -5.7070e-02, -9.7016e-03, -3.4534e-01,\n",
      "          1.1896e-01,  9.0933e-02,  2.2761e-01, -3.8735e-01, -4.0120e-03,\n",
      "          4.0380e-01, -2.9540e-01,  1.2783e-01,  3.1208e-01,  8.8234e-02,\n",
      "          3.4263e-01, -3.3351e-02,  7.7557e-03,  4.5386e-02, -2.3060e-01,\n",
      "         -2.1711e-02,  1.2157e-01,  5.4995e-01,  1.6696e-01, -3.6539e-01,\n",
      "          1.1459e-01,  2.6013e-01, -1.6103e-01,  2.7828e-01, -8.7109e-02,\n",
      "         -6.0765e-02,  2.5808e-01, -5.2193e-02,  1.7343e-01, -8.3517e-02,\n",
      "         -2.1480e-01, -3.1597e-01,  3.6757e-01, -2.2710e-01, -1.3269e-01,\n",
      "         -1.6432e-01, -1.2302e-01, -1.3751e-01,  7.6207e-02, -3.7409e-01,\n",
      "          3.3105e-01,  1.2751e-01, -2.0906e-01, -1.0358e-01, -9.5827e-02,\n",
      "         -1.4510e-01, -2.2326e-01, -2.8245e-01,  4.3112e-01, -1.7310e-01,\n",
      "         -4.5428e-01,  2.5673e-01,  5.5129e-02,  3.4291e-01,  5.4287e-02,\n",
      "          8.7365e-02, -5.0801e-02,  1.3405e-01,  8.5152e-02, -1.3926e-01,\n",
      "          2.8145e-01,  5.5604e-02, -5.6820e-01, -1.4817e-01, -2.4191e-01,\n",
      "          1.0328e-01,  2.0726e-01, -3.5115e-01,  1.8183e-02,  4.1356e-02,\n",
      "          1.3001e-01,  2.0131e-02, -1.2801e-01, -5.9633e-02,  4.1167e-01,\n",
      "          2.3647e-01,  2.7715e-01,  8.1544e-02,  2.3413e-01, -3.4904e-02,\n",
      "         -3.5157e-01,  4.3852e-02,  8.8417e-02, -2.0185e-01,  4.4385e-01,\n",
      "         -1.3148e-01, -3.9583e-01, -8.8055e-02,  3.9915e-01,  1.1281e-01,\n",
      "         -1.0141e-02, -3.6380e-02,  2.3138e-01,  1.8151e-01, -1.3976e-01,\n",
      "          1.8107e-01, -3.5753e-02, -1.4010e-01, -1.3643e-01,  8.6381e-02,\n",
      "         -2.2782e-01,  2.2852e-02, -1.5278e-01,  1.8571e-03, -2.1577e-01,\n",
      "          1.8011e-02, -2.2580e-01,  2.7291e-01, -3.3874e-01,  1.2000e-01,\n",
      "          6.9773e-02,  3.0793e-01, -3.6171e-01, -1.4258e-01, -6.5982e-02,\n",
      "          1.7538e-01,  2.8119e-01,  3.4108e-01,  3.5802e-02,  3.6020e-03,\n",
      "         -1.7684e-01, -2.5257e-01,  6.3717e-02, -2.1298e-01,  1.2919e-01,\n",
      "          6.1348e-02,  2.4227e-01, -3.1202e-01, -1.8310e-01,  2.4663e-01,\n",
      "         -9.4920e-02, -1.4804e-01,  4.2247e-01,  2.4830e-01,  2.1344e-01,\n",
      "          3.1649e-02,  2.4401e-01,  5.7135e-02, -1.8168e-01, -1.4827e-01,\n",
      "         -2.5817e-01,  8.4959e-02, -1.2443e-01, -6.2028e-02, -6.3609e-02,\n",
      "         -1.2703e-01, -1.9767e-01, -1.5625e-01,  1.4351e-01,  1.3035e-01,\n",
      "          1.3762e-02, -6.2970e-02, -5.8642e-02, -2.7242e-01,  3.0717e-01,\n",
      "          9.6554e-03,  8.5453e-02, -8.2862e-02,  3.4894e-02, -1.4301e-01,\n",
      "          2.4180e-01,  2.0931e-01,  6.4633e-02, -1.8594e-01, -4.2737e-02,\n",
      "         -3.1647e-01, -3.7859e-01,  4.4767e-02,  1.4221e-01,  1.3871e-01,\n",
      "         -9.2903e-02, -3.1577e-01, -1.0186e-02, -1.3969e-01,  1.8377e-01,\n",
      "          4.8466e-03, -1.8343e-01, -8.9713e-02, -4.3429e-02, -4.7644e-02,\n",
      "          7.3956e-02, -2.2820e-01, -2.0389e-01, -1.1765e-01, -9.3285e-02,\n",
      "         -7.4957e-02,  3.6290e-01, -4.6687e-02,  2.8321e-01, -1.5989e-01,\n",
      "          3.6545e-03, -1.7854e-01,  1.0508e-01, -5.4333e-02,  7.9194e-02,\n",
      "          2.8310e-01, -4.6425e-01, -1.5292e-01, -1.4209e-03, -2.1938e-01,\n",
      "         -1.5414e-01, -6.5673e-02, -3.2282e-02,  2.1139e-01, -3.3255e-01,\n",
      "          1.7837e-01, -7.9680e-02,  1.8697e-01, -7.6052e-02, -2.4356e-01,\n",
      "         -1.6496e-01,  2.2136e-04,  2.5271e-01, -3.3634e-01, -2.7069e-01,\n",
      "         -2.8098e-01, -9.3457e-02, -6.4577e-02, -2.8800e-01,  4.2327e-01,\n",
      "         -1.3651e-01, -7.6636e-02,  2.5705e-02,  4.5715e-01,  1.9693e-01,\n",
      "          2.0371e-01,  1.8938e-01, -2.6964e-02,  3.2863e-02,  1.2427e-01,\n",
      "         -4.9052e-01,  2.3797e-01, -2.0466e-01, -1.4686e-01,  4.0803e-02,\n",
      "          9.3166e-02, -3.0909e-02,  1.7621e-03, -1.5468e-01, -1.0947e-01,\n",
      "          2.2076e-01, -3.6642e-01, -3.1162e-02,  2.6837e-01,  1.5044e-01,\n",
      "         -2.5922e-01,  3.8125e-02,  1.1545e-01,  3.8037e-01,  1.0256e-01,\n",
      "         -2.4322e-01,  1.3916e-01, -3.3943e-01, -5.2445e-02, -2.3033e-01,\n",
      "         -2.9455e-01,  1.4783e-01, -6.2998e-02,  5.4090e-02, -8.2872e-02,\n",
      "         -2.8278e-01,  2.2463e-01, -4.9204e-02, -6.8271e-02,  4.3094e-01,\n",
      "          3.0685e-02, -1.0802e-01,  1.6458e-01,  1.0349e-02,  2.6148e-02,\n",
      "         -1.0311e-01,  2.6019e-01,  1.8597e-01, -3.0105e-01,  1.4853e-01,\n",
      "         -1.3116e-01, -6.5473e-02, -1.0425e-01]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                   | 4/14274 [00:03<3:00:54,  1.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0427,  0.0858, -0.0220,  ..., -0.1157, -0.0512, -0.0309],\n",
      "         [ 0.0114, -0.2390, -0.0557,  ..., -0.3332,  0.1852,  0.0751],\n",
      "         [ 0.0879,  0.1554,  0.1251,  ...,  0.1847, -0.0294, -0.0489],\n",
      "         ...,\n",
      "         [-0.0561,  0.0998, -0.0271,  ..., -0.2057,  0.0201, -0.1525],\n",
      "         [-0.0561,  0.0998, -0.0271,  ..., -0.2057,  0.0201, -0.1525],\n",
      "         [-0.0561,  0.0998, -0.0271,  ..., -0.2057,  0.0201, -0.1525]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-1.3738e-02, -2.0784e-01, -2.1963e-01, -1.1118e-01,  1.5323e-01,\n",
      "          1.8332e-01,  2.5949e-01, -7.3172e-02, -5.0565e-02, -1.7314e-01,\n",
      "          2.2505e-01, -3.7901e-05, -8.0733e-02,  7.8247e-02, -1.2294e-01,\n",
      "          5.1120e-01,  2.2906e-01, -4.6926e-01,  1.0668e-02, -3.9428e-02,\n",
      "         -2.3985e-01,  7.2482e-02,  4.5569e-01,  2.9660e-01,  1.3645e-01,\n",
      "          7.0573e-02, -1.2183e-01, -3.9758e-02,  1.9024e-01,  2.2503e-01,\n",
      "          2.6853e-01,  5.5145e-02,  1.0645e-01,  2.5476e-01, -2.5664e-01,\n",
      "          3.2860e-02, -3.0222e-01,  2.5479e-02,  2.4574e-01, -1.8196e-01,\n",
      "         -7.9732e-02,  1.6882e-01,  1.8236e-01, -1.3465e-01, -1.1506e-01,\n",
      "          3.9543e-01,  2.4116e-01,  6.0263e-02, -1.2615e-01, -9.1361e-02,\n",
      "         -3.6894e-01,  3.7509e-01,  2.9234e-01,  2.1116e-01, -3.3694e-02,\n",
      "          2.0486e-02, -1.2333e-01,  2.5168e-01, -6.4847e-02, -8.4419e-02,\n",
      "         -1.2645e-01, -2.1992e-01, -1.8065e-02, -4.8406e-02, -6.1330e-03,\n",
      "         -1.4694e-01,  8.6962e-02, -1.5516e-01, -1.3971e-01,  5.5681e-02,\n",
      "         -8.0752e-02,  1.5715e-01,  1.3595e-01, -2.6046e-01, -2.6238e-01,\n",
      "          6.4081e-02, -5.9964e-01, -9.6869e-02,  2.8238e-01,  4.2435e-01,\n",
      "         -1.2147e-01,  1.9121e-01,  1.2027e-02,  2.1614e-01, -1.4408e-02,\n",
      "         -5.6496e-02, -4.7474e-02, -8.9172e-02,  1.8438e-01,  2.6586e-01,\n",
      "         -2.1071e-01, -3.8810e-01,  7.7308e-02,  2.9462e-02, -8.9565e-02,\n",
      "         -2.3802e-03, -1.2245e-02, -1.1862e-01, -1.7846e-01, -1.6378e-01,\n",
      "          4.5173e-02, -2.6895e-01, -1.1877e-01,  2.5978e-01, -2.8880e-02,\n",
      "         -2.1120e-01, -5.6150e-02,  2.8375e-01,  5.8365e-02, -1.1251e-01,\n",
      "         -1.7851e-01,  4.1419e-01,  3.0580e-01,  3.6085e-02,  9.3646e-03,\n",
      "          1.8889e-01,  1.1144e-01, -2.7982e-01,  4.2487e-01, -3.0624e-01,\n",
      "          1.3264e-02, -9.4686e-02,  1.1394e-01,  1.2316e-01, -1.9686e-01,\n",
      "          2.6654e-01,  1.4038e-01,  2.4934e-01,  1.9326e-01,  8.8398e-02,\n",
      "         -2.2717e-02,  1.1796e-01, -1.1668e-01,  1.4215e-01,  1.8412e-01,\n",
      "          1.0750e-01,  1.9021e-02, -3.1288e-01, -1.7800e-01,  2.3299e-01,\n",
      "          3.3417e-01,  1.2716e-01, -2.0976e-02,  2.0425e-01,  8.6163e-02,\n",
      "          2.2983e-01,  1.3507e-01, -3.9807e-01,  3.8816e-02,  3.3561e-01,\n",
      "          9.2859e-02,  1.6521e-01, -7.7660e-02, -2.8074e-01, -2.5020e-01,\n",
      "         -1.0084e-01,  4.9350e-02, -3.1763e-01, -1.2561e-01,  3.6961e-01,\n",
      "          1.2413e-02,  1.0338e-02, -1.5251e-01, -2.4372e-01, -3.0193e-02,\n",
      "         -1.1928e-01,  6.9971e-03,  1.1070e-01, -7.2110e-02, -4.1608e-01,\n",
      "         -1.0029e-01, -5.3925e-01, -1.2747e-01,  1.8555e-01, -2.8994e-01,\n",
      "          2.3815e-01, -2.6426e-01,  7.3481e-02,  4.0664e-01,  3.8322e-02,\n",
      "         -1.3824e-03, -1.6394e-01, -4.1504e-02,  9.9458e-02,  3.1731e-01,\n",
      "          2.2900e-01, -3.7258e-01,  9.4569e-02,  1.4750e-01,  2.5089e-01,\n",
      "          1.4982e-01, -3.2209e-02, -1.2949e-01,  1.0631e-01, -2.0917e-01,\n",
      "          1.6898e-01, -2.3308e-01,  1.8706e-01, -2.6459e-01, -2.3859e-01,\n",
      "          2.8179e-01, -3.8775e-01, -3.5543e-02,  8.3030e-02,  2.5985e-01,\n",
      "          1.3750e-02, -5.4788e-02, -1.0391e-01,  8.8462e-02,  1.9217e-01,\n",
      "          1.3028e-01, -4.0038e-01,  2.6153e-01, -1.1120e-02, -3.8227e-02,\n",
      "         -2.4773e-02,  1.8105e-01,  2.4431e-01,  1.0559e-01, -3.9576e-01,\n",
      "         -1.4475e-01,  1.0993e-01,  2.6172e-01, -2.5879e-01,  1.6392e-01,\n",
      "         -2.6119e-01, -3.8923e-01, -1.6023e-01,  2.2013e-01,  2.2167e-01,\n",
      "          1.6544e-01, -2.7164e-01,  1.7060e-01, -8.2024e-02, -4.4174e-01,\n",
      "         -3.4875e-01, -7.1689e-02,  2.5212e-01,  1.7220e-01,  1.7698e-01,\n",
      "          2.4903e-01,  5.4578e-02,  8.4969e-02,  1.7348e-01,  1.3540e-01,\n",
      "         -1.8213e-01,  1.6397e-01, -3.7798e-01, -5.9516e-02, -2.5523e-01,\n",
      "         -1.8011e-01, -1.9400e-01,  4.0470e-01, -2.3155e-01,  2.5037e-01,\n",
      "          3.8090e-01, -2.9120e-01, -1.1569e-01,  1.2054e-01,  8.0964e-02,\n",
      "          1.1250e-01, -1.4150e-01,  1.9399e-01,  1.4661e-01, -1.2194e-01,\n",
      "          2.4775e-01,  2.6130e-02,  2.4201e-01,  1.6119e-01,  9.7540e-02,\n",
      "          1.5060e-01,  1.1387e-01, -1.5764e-01,  4.9650e-02,  1.0187e-02,\n",
      "         -1.7132e-02, -2.5850e-01, -1.7054e-01,  2.2462e-01, -3.1264e-02,\n",
      "          3.2912e-02, -1.5243e-01, -1.0648e-01,  3.8134e-03,  4.0769e-01,\n",
      "         -3.6685e-01,  2.4368e-01,  9.0243e-02,  1.4819e-01, -2.7124e-01,\n",
      "         -1.8698e-01,  8.2417e-02,  1.4159e-01, -4.0112e-01,  7.5117e-03,\n",
      "          1.6700e-01,  1.0382e-01,  1.9880e-01,  2.4740e-01, -2.0089e-02,\n",
      "         -1.0738e-01,  4.6359e-01, -1.7576e-01, -1.3635e-01,  2.5592e-01,\n",
      "         -2.8176e-01, -3.0505e-01,  2.4748e-01, -3.4087e-02,  3.0452e-01,\n",
      "          1.1722e-01,  3.4706e-02,  9.6650e-02, -6.0995e-01,  8.5993e-02,\n",
      "         -4.4688e-01,  2.1847e-04,  9.0628e-03, -8.0795e-02, -2.1819e-01,\n",
      "          1.1462e-01,  2.9976e-01, -2.6193e-01, -3.8219e-02,  2.2467e-01,\n",
      "          7.7726e-02, -1.1455e-01,  4.6885e-01, -3.0504e-02,  2.0110e-01,\n",
      "         -6.7900e-02,  2.3729e-01, -2.0609e-01,  2.4464e-01, -2.6452e-01,\n",
      "         -8.9706e-02,  2.5921e-02,  9.2370e-02,  7.9845e-02, -4.7928e-02,\n",
      "         -3.2759e-01,  2.3141e-01, -2.5475e-02, -7.6021e-02, -3.7357e-02,\n",
      "          9.6992e-02, -1.5221e-03,  4.0602e-02,  8.1614e-02,  3.1111e-01,\n",
      "          2.6519e-01, -2.7050e-02, -3.5208e-01,  2.3580e-05, -1.1349e-01,\n",
      "          6.0317e-02, -4.7683e-03, -1.8771e-02,  4.2368e-01, -1.0560e-01,\n",
      "         -6.2803e-03, -1.3935e-01,  2.4787e-01,  1.9447e-01,  1.3439e-01,\n",
      "          1.2257e-01,  6.5795e-02,  1.1268e-01, -7.3826e-02, -2.4727e-02,\n",
      "         -1.7096e-01, -2.1788e-01, -2.9055e-01,  2.2171e-01, -2.2086e-01,\n",
      "         -1.7106e-01,  1.5671e-01,  1.8322e-01, -1.3868e-01,  1.2738e-01,\n",
      "          3.0704e-01,  1.1093e-01, -1.4258e-01,  2.5226e-01, -1.1056e-01,\n",
      "          1.2409e-01,  3.1511e-01, -1.3318e-02,  1.6811e-01,  5.2618e-01,\n",
      "          2.2348e-01, -3.7091e-01, -2.9361e-02, -2.2881e-01,  2.7921e-02,\n",
      "          2.5672e-01, -1.7796e-01,  1.9079e-01,  3.7128e-01,  3.0602e-01,\n",
      "          4.5024e-01,  1.1514e-02, -1.3426e-01,  9.6926e-02,  2.1069e-01,\n",
      "          2.8830e-02, -1.5681e-01, -1.7024e-01,  2.5396e-01,  3.3795e-02,\n",
      "         -1.3163e-01, -1.4866e-02, -9.0146e-02,  4.7262e-02, -1.2754e-01,\n",
      "         -3.7125e-01,  6.2328e-02,  1.8281e-01, -4.6022e-01,  6.1831e-02,\n",
      "         -3.0232e-01,  4.3964e-02, -2.3323e-01,  2.2573e-01, -2.4731e-01,\n",
      "         -1.0687e-01,  3.8687e-01, -5.9392e-02,  6.3694e-02, -1.9767e-01,\n",
      "         -1.4341e-01,  2.4549e-02,  2.5515e-02, -2.7796e-03, -8.8916e-03,\n",
      "          3.3721e-01, -1.1451e-01,  3.0378e-02,  4.1837e-02,  2.1454e-01,\n",
      "         -6.6007e-02,  1.9859e-01,  2.1121e-02, -1.3797e-01, -3.8382e-01,\n",
      "          1.2698e-01, -1.8421e-01, -4.3488e-01, -3.5094e-01,  3.5026e-01,\n",
      "         -1.2851e-01, -2.5280e-01, -2.2254e-01, -2.6210e-01,  6.3290e-02,\n",
      "          1.8655e-01,  4.4873e-01, -3.9922e-01, -5.5689e-02,  4.7566e-01,\n",
      "         -5.2843e-02, -1.7847e-01,  3.0661e-01,  2.1565e-01, -3.1661e-01,\n",
      "          3.3200e-01,  2.6061e-01, -5.4383e-02,  3.5332e-02,  5.1761e-01,\n",
      "          1.1656e-01,  1.8705e-01, -2.1689e-01,  4.5178e-01, -2.0907e-01,\n",
      "          2.8275e-01, -1.7805e-01, -2.1844e-01, -1.8612e-01, -3.2450e-03,\n",
      "          2.9824e-01,  1.7486e-01, -3.9991e-01, -1.0023e-01,  5.5393e-02,\n",
      "          3.3319e-01, -3.7568e-01, -1.0051e-01,  6.5355e-03, -3.3357e-01,\n",
      "          8.9189e-02,  8.3718e-02,  2.2533e-01, -3.7333e-01, -2.8443e-02,\n",
      "          3.9973e-01, -3.1242e-01,  1.3992e-01,  3.0810e-01,  9.4430e-02,\n",
      "          3.5147e-01, -1.7682e-02,  1.2199e-02,  6.2532e-02, -2.3871e-01,\n",
      "         -2.4904e-02,  1.2400e-01,  5.2425e-01,  1.4688e-01, -3.7190e-01,\n",
      "          8.3527e-02,  2.2501e-01, -1.1827e-01,  3.0823e-01, -8.2846e-02,\n",
      "         -1.0621e-01,  2.4558e-01, -5.3732e-02,  1.5855e-01, -8.3015e-02,\n",
      "         -2.1439e-01, -3.2777e-01,  3.3787e-01, -2.3729e-01, -1.1992e-01,\n",
      "         -1.4811e-01, -1.3900e-01, -1.1758e-01,  5.2820e-02, -3.7526e-01,\n",
      "          3.3155e-01,  9.8186e-02, -2.1262e-01, -6.3616e-02, -9.2228e-02,\n",
      "         -1.5030e-01, -2.0985e-01, -2.7123e-01,  4.3007e-01, -1.6541e-01,\n",
      "         -4.4177e-01,  2.4577e-01,  5.4075e-02,  3.3454e-01,  1.8470e-02,\n",
      "          9.8244e-02, -4.5387e-02,  1.1357e-01,  5.6002e-02, -1.1408e-01,\n",
      "          2.6805e-01,  6.0636e-02, -5.5832e-01, -1.1866e-01, -2.2960e-01,\n",
      "          9.6015e-02,  2.1143e-01, -3.2770e-01,  2.0481e-02,  3.8221e-02,\n",
      "          1.5487e-01,  6.5494e-02, -1.0550e-01, -6.0732e-02,  3.8805e-01,\n",
      "          2.0846e-01,  2.5222e-01,  9.1403e-02,  2.5561e-01, -1.9185e-02,\n",
      "         -2.9432e-01,  6.2596e-02,  7.8002e-02, -1.7559e-01,  4.3824e-01,\n",
      "         -9.4428e-02, -3.7116e-01, -7.4195e-02,  4.0764e-01,  1.1137e-01,\n",
      "         -2.7143e-02, -5.5861e-02,  2.0065e-01,  1.5758e-01, -1.2464e-01,\n",
      "          1.8349e-01, -4.0718e-02, -1.3982e-01, -1.2257e-01,  9.0734e-02,\n",
      "         -2.2488e-01,  6.5939e-02, -1.5425e-01, -1.7627e-02, -2.3061e-01,\n",
      "         -9.4021e-04, -2.0405e-01,  2.6178e-01, -3.5106e-01,  9.5059e-02,\n",
      "          8.6194e-02,  3.0698e-01, -3.5709e-01, -1.5190e-01, -7.6547e-02,\n",
      "          1.4599e-01,  2.7367e-01,  3.2298e-01,  5.1319e-02,  5.4435e-03,\n",
      "         -1.6572e-01, -2.3376e-01,  8.8638e-02, -2.1186e-01,  1.4427e-01,\n",
      "          8.5933e-02,  2.1961e-01, -3.3271e-01, -1.6521e-01,  2.5469e-01,\n",
      "         -1.1038e-01, -1.1558e-01,  4.1236e-01,  2.5380e-01,  2.4200e-01,\n",
      "          3.2643e-02,  2.4007e-01,  6.2139e-02, -2.1629e-01, -1.3608e-01,\n",
      "         -2.1606e-01,  7.7549e-02, -9.3092e-02, -4.9673e-02, -1.6321e-02,\n",
      "         -1.0006e-01, -1.9450e-01, -1.5866e-01,  1.4843e-01,  1.1879e-01,\n",
      "          1.0816e-02, -3.6059e-02, -2.3634e-02, -2.4975e-01,  3.2113e-01,\n",
      "          3.1602e-03,  8.1050e-02, -6.9495e-02,  2.4539e-02, -1.5525e-01,\n",
      "          2.3026e-01,  2.0984e-01,  6.6012e-02, -1.7468e-01, -5.2185e-02,\n",
      "         -3.0013e-01, -3.7438e-01,  4.6131e-02,  1.4883e-01,  1.1954e-01,\n",
      "         -7.0130e-02, -2.9781e-01,  1.7678e-02, -1.0666e-01,  1.7220e-01,\n",
      "          1.2239e-02, -1.6354e-01, -8.2216e-02, -5.4968e-02, -5.1539e-02,\n",
      "          8.3620e-02, -2.1072e-01, -1.8101e-01, -1.0218e-01, -7.9847e-02,\n",
      "         -7.8580e-02,  3.7299e-01, -3.7343e-02,  2.6894e-01, -1.6783e-01,\n",
      "          8.2604e-03, -1.6038e-01,  1.0799e-01, -5.1231e-02,  6.6679e-02,\n",
      "          2.6846e-01, -4.5012e-01, -1.5863e-01,  5.8280e-03, -2.2639e-01,\n",
      "         -1.1740e-01, -7.4587e-02, -6.1548e-02,  2.1864e-01, -3.2731e-01,\n",
      "          2.0820e-01, -6.8002e-02,  1.6901e-01, -5.0454e-02, -2.4870e-01,\n",
      "         -1.5163e-01,  6.3636e-03,  2.5521e-01, -3.1723e-01, -2.3559e-01,\n",
      "         -2.6820e-01, -1.1044e-01, -5.2613e-02, -2.5985e-01,  4.1600e-01,\n",
      "         -1.3400e-01, -6.5371e-02,  4.5778e-02,  4.3950e-01,  2.0608e-01,\n",
      "          1.9025e-01,  1.9252e-01,  6.1164e-03,  2.8154e-02,  1.2875e-01,\n",
      "         -4.8037e-01,  2.0694e-01, -2.1245e-01, -1.2695e-01,  4.7168e-02,\n",
      "          6.9215e-02, -1.9297e-02,  4.4753e-03, -1.6522e-01, -9.3764e-02,\n",
      "          2.1077e-01, -3.8233e-01, -1.6527e-02,  2.5590e-01,  1.3662e-01,\n",
      "         -2.4629e-01,  6.7003e-02,  1.3753e-01,  4.0413e-01,  1.2173e-01,\n",
      "         -2.1620e-01,  1.3157e-01, -3.3446e-01, -2.6433e-02, -2.0985e-01,\n",
      "         -2.9063e-01,  1.3632e-01, -8.3510e-02,  8.8725e-02, -7.7173e-02,\n",
      "         -2.8979e-01,  2.2380e-01, -6.0198e-02, -7.4448e-02,  4.2782e-01,\n",
      "          4.1159e-02, -1.0455e-01,  1.4314e-01,  1.8544e-02,  4.3278e-02,\n",
      "         -1.0243e-01,  2.6940e-01,  1.9063e-01, -2.8900e-01,  1.4467e-01,\n",
      "         -1.0151e-01, -5.8920e-02, -1.1731e-01]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_batch_embeddings(tokenizer_res, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bcb8723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65aaffc",
   "metadata": {},
   "source": [
    "## gather all questions for embeddings generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae30f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746105\n"
     ]
    }
   ],
   "source": [
    "all_questions = []\n",
    "\n",
    "for ds in ['train', 'dev', 'test']:\n",
    "    for nhop in ['1', '2', '3']:\n",
    "        raw = load_raw_qa('./data/QA_data/MetaQA/', mode=f'{ds}_{nhop}hop')\n",
    "        questions, _, _ = extract_question_entity_target(raw)\n",
    "        all_questions.extend(questions)\n",
    "\n",
    "print(len(all_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6d87f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which movies can be described by robert schwentke'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "811312d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all-questions.pickle', 'wb') as f:\n",
    "    pickle.dump(all_questions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60e8b0",
   "metadata": {},
   "source": [
    "## load question embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21257202",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('q-emb-dict.pickle', 'rb') as f:\n",
    "    question_embs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cb75097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embs['which movies can be described by robert schwentke'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8a852ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.array(list(question_embs.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff8b47",
   "metadata": {},
   "source": [
    "# Knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c50bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = data_loader.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bc48ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({767: {'relation_id': 6, 'relation_text': 'directed_by'}, 7125: {'relation_id': 13, 'relation_text': 'has_genre'}, 184: {'relation_id': 16, 'relation_text': 'release_year'}})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.adj[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f92d2b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({1121: {'relation_id': 11, 'relation_text': 'written_by'}, 167: {'relation_id': 16, 'relation_text': 'release_year'}, 15595: {'relation_id': 8, 'relation_text': 'in_language'}, 31150: {'relation_id': 6, 'relation_text': 'directed_by'}, 40514: {'relation_id': 7, 'relation_text': 'has_tags'}})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as graph.adj\n",
    "graph[1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "504adda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_text': 'has_tags_reverse'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes[1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20378487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37824 {'relation_id': 11, 'relation_text': 'written_by'}\n",
      "165 {'relation_id': 16, 'relation_text': 'release_year'}\n",
      "28874 {'relation_id': 6, 'relation_text': 'directed_by'}\n"
     ]
    }
   ],
   "source": [
    "for nbr, eattr in graph[5].items():\n",
    "    print(nbr, eattr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0be18",
   "metadata": {},
   "source": [
    "## moving in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "882bd866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Akira Kurosawa'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def traverse(entity_name, relation):\n",
    "    entity_id = entities_voc[entity_name]\n",
    "    neighbors = graph[entity_id]\n",
    "    for nbr_id, eattr in neighbors.items():\n",
    "        if eattr['relation_text'] == relation:\n",
    "            return entities_inv_voc[nbr_id]\n",
    "        \n",
    "traverse('After the Rain', 'written_by')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f81d0",
   "metadata": {},
   "source": [
    "## creating knowledge graph environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "710fdab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968,)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class KGEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, n_relations, observation_space, q_embeddings, ent_embeddings,\n",
    "                 entities_vocab, entities_inv_vocab, rel_inv_voc, rel_voc, mode='train'):\n",
    "        super(KGEnv, self).__init__()\n",
    "        \n",
    "        self.entities_vocab = entities_vocab\n",
    "        self.entities_inv_vocab = entities_inv_vocab\n",
    "        self.relations_inv_voc = rel_inv_voc\n",
    "        self.action_space = spaces.Discrete(n_relations)\n",
    "        self.observation_space = spaces.Box(low=-3, high=3, shape=(observation_space,))\n",
    "        self.q_embeddings = q_embeddings\n",
    "        self.ent_embeddings = ent_embeddings\n",
    "        self.relations_voc = rel_voc\n",
    "        \n",
    "        for nhop in ['1', '2', '3']:\n",
    "            raw = load_raw_qa('./data/QA_data/MetaQA/', mode=f'{mode}_{nhop}hop')\n",
    "            self.questions, self.entities, self.targets = extract_question_entity_target(raw)\n",
    "\n",
    "        self.entities_idx = [entities_voc[t] for t in self.entities]\n",
    "        self.targets_idx = [[entities_voc[t] for t in ts] for ts in self.targets]\n",
    "        self.env_size = len(self.targets)\n",
    "        self.goal = None\n",
    "        self.current_q = self.current_ent = None\n",
    "    \n",
    "    def step(self, action):\n",
    "        next_ent_id = self.traverse(self.current_ent, action)\n",
    "        if next_ent_id == -1:\n",
    "            next_ent_id = self.entities_vocab[self.current_ent]\n",
    "            \n",
    "        reward = 0\n",
    "        done = False\n",
    "        \n",
    "        #TODO:\n",
    "        if next_ent_id in self.goal:\n",
    "            done = True\n",
    "            reward = 1\n",
    "            \n",
    "        self.current_ent = self.entities_inv_vocab[next_ent_id]\n",
    "        next_state = self.build_state_vec(self.current_q, next_ent_id)\n",
    "        \n",
    "        return next_state, reward, done, {}\n",
    "    \n",
    "    \n",
    "    def build_state_vec(self, question: str, entity: int):\n",
    "        q_emb = self.q_embeddings[question]\n",
    "        e_emb = self.ent_embeddings[entity]\n",
    "        return np.concatenate([q_emb, e_emb])\n",
    "        \n",
    "    def traverse(self, entity_name, relation):\n",
    "        entity_id = entities_voc[entity_name]\n",
    "        neighbors = graph[entity_id]\n",
    "        possible_moves = []\n",
    "        for nbr_id, eattr in neighbors.items():\n",
    "            if eattr['relation_id'] == relation:\n",
    "                possible_moves.append(nbr_id)\n",
    "        \n",
    "        if len(possible_moves):\n",
    "            return choice(possible_moves)\n",
    "        return -1\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        init_state = np.random.randint(low=0, high=self.env_size-1)\n",
    "        self.goal = self.targets_idx[init_state]\n",
    "        self.current_q = self.questions[init_state]\n",
    "        self.current_ent = self.entities[init_state]\n",
    "        return self.build_state_vec(self.current_q, self.entities_idx[init_state])\n",
    "    \n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        print(self.current_q)\n",
    "        print(f\"current entity: {self.current_ent}\")\n",
    "        entity_id = entities_voc[self.current_ent]\n",
    "        neighbors = graph[entity_id]\n",
    "        \n",
    "        print(\"available moves:\")\n",
    "        for nbr_id, eattr in neighbors.items():\n",
    "            print(f\"--{eattr['relation_text']}({eattr['relation_id']})--> {self.entities_inv_vocab[nbr_id]}\")\n",
    "    \n",
    "    \n",
    "kg_env = KGEnv(len(relations_voc), observation_space=768+200, q_embeddings=question_embs,\n",
    "               ent_embeddings=ent_emb_dict, entities_vocab=entities_voc, entities_inv_vocab=entities_inv_voc,\n",
    "                rel_inv_voc=relations_inv_voc, rel_voc=relations_voc)\n",
    "s = kg_env.reset()\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "06637499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what types are the movies starred by actors in What's the Worst That Could Happen?\n",
      "current entity: What's the Worst That Could Happen?\n",
      "available moves:\n",
      "--written_by(11)--> Donald E. Westlake\n",
      "--directed_by(6)--> Sam Weisman\n",
      "--release_year(16)--> 2001\n",
      "--starred_actors(3)--> Martin Lawrence\n",
      "--starred_actors(3)--> John Leguizamo\n",
      "--has_tags(7)--> martin lawrence\n",
      "--starred_actors(3)--> Danny DeVito\n",
      "--has_tags(7)--> sam weisman\n",
      "--has_genre(13)--> Comedy\n",
      "3\n",
      "what types are the movies starred by actors in What's the Worst That Could Happen?\n",
      "current entity: John Leguizamo\n",
      "available moves:\n",
      "--starred_actors_reverse(10)--> King of the Jungle\n",
      "--starred_actors_reverse(10)--> Executive Decision\n",
      "--starred_actors_reverse(10)--> Spawn\n",
      "--starred_actors_reverse(10)--> Carlito's Way\n",
      "--starred_actors_reverse(10)--> The Pest\n",
      "--starred_actors_reverse(10)--> Titan A.E.\n",
      "--starred_actors_reverse(10)--> Super Mario Bros.\n",
      "--starred_actors_reverse(10)--> Body Count\n",
      "--starred_actors_reverse(10)--> Ride Along\n",
      "--starred_actors_reverse(10)--> The Take\n",
      "--starred_actors_reverse(10)--> Chef\n",
      "--starred_actors_reverse(10)--> Ice Age\n",
      "--starred_actors_reverse(10)--> What's the Worst That Could Happen?\n",
      "--starred_actors_reverse(10)--> Empire\n",
      "--starred_actors_reverse(10)--> Summer of Sam\n",
      "--starred_actors_reverse(10)--> Spun\n",
      "--starred_actors_reverse(10)--> Vanishing on 7th Street\n",
      "10\n",
      "what types are the movies starred by actors in What's the Worst That Could Happen?\n",
      "current entity: The Pest\n",
      "available moves:\n",
      "--has_tags(7)--> john leguizamo\n",
      "--starred_actors(3)--> John Leguizamo\n",
      "--release_year(16)--> 1997\n",
      "--has_genre(13)--> Comedy\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "def manual_play_in_env():\n",
    "    state = kg_env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        kg_env.render()        \n",
    "        action = int(input())\n",
    "        state, reward, done, _ = kg_env.step(action)\n",
    "        \n",
    "manual_play_in_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20b9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
